{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AP-1 Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### header ###\n",
    "__author__ = \"Jenhan Tao\"\n",
    "__license__ = \"BSD\"\n",
    "__email__ = \"jenhantao@gmail.com\"\n",
    "\n",
    "### imports ###\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib\n",
    "import itertools\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "import matplotlib_venn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from random import shuffle\n",
    "import ete3\n",
    "### notebook specific configuration ###\n",
    "%matplotlib inline\n",
    "matplotlib.pylab.rcParams['savefig.dpi'] = 200\n",
    "sys.setrecursionlimit(5000)\n",
    "os.chdir('/gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/')\n",
    "sns.set_context('notebook')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_GC_matched_split(features, labels, test_size, tolerance = 0.01):\n",
    "    '''\n",
    "    feature: 2D array (samples x features)\n",
    "    labels: 1D boolean array (samples x)\n",
    "    test_size: fraction of data to test on\n",
    "    tolerance: max difference in GC content between True and False labelled samples\n",
    "    '''\n",
    "    global _id_sequence_dict\n",
    "    \n",
    "    ### match GC content of samples labelled True with those labelled False by thowing out False samples\n",
    "    # retrieve sequences using index of labels\n",
    "    index_label_tuples = tuple(zip(labels.index.values, labels.values))\n",
    "    \n",
    "    true_sequences = [_id_sequence_dict[x[0]] for x in index_label_tuples if x[1]]\n",
    "    true_ids = [x[0] for x in index_label_tuples if x[1]]\n",
    "    \n",
    "    false_sequences = [_id_sequence_dict[x[0]] for x in index_label_tuples if not x[1]]\n",
    "    false_ids = [x[0] for x in index_label_tuples if not x[1]]\n",
    "    \n",
    "    # calculate GC content of True samples\n",
    "    true_gc_count = 0\n",
    "    true_length = 0\n",
    "    for s in true_sequences:\n",
    "        true_gc_count += s.count('G')\n",
    "        true_gc_count += s.count('C')\n",
    "        true_length += len(s)\n",
    "    true_gc_content = true_gc_count/(true_length+0.0000001)\n",
    "    \n",
    "    # calcuate GC content of False samples\n",
    "    false_gc_count = 0\n",
    "    false_length = 0\n",
    "    for s in false_sequences:\n",
    "        false_gc_count += s.count('G')\n",
    "        false_gc_count += s.count('C')\n",
    "        false_length += len(s)\n",
    "    false_gc_content = false_gc_count/(false_length+0.0000001)\n",
    "    \n",
    "    while abs(true_gc_content - false_gc_content) > tolerance:\n",
    "        # remove false GC sequences until GC content matches tolerance\n",
    "        selected_seq = False\n",
    "        \n",
    "        while not selected_seq:\n",
    "            rand_index = np.random.randint(len(false_sequences))\n",
    "            current_seq = false_sequences[rand_index]\n",
    "            current_gc_count = current_seq.count('G')+ current_seq.count('C')\n",
    "            current_length = len(current_seq)\n",
    "            current_gc = current_gc_count/current_length\n",
    "            if true_gc_content > false_gc_content:\n",
    "                # remove sequences that would increase overall GC content of False sequences\n",
    "                if current_gc < false_gc_content:\n",
    "                    selected_seq = True\n",
    "            else:\n",
    "                # remove sequences that would decrease overall GC content of False sequences\n",
    "                if current_gc > false_gc_content:\n",
    "                    selected_seq = True\n",
    "        false_gc_count -= current_gc_count\n",
    "        false_length -= current_length\n",
    "        false_gc_content = false_gc_count/false_length\n",
    "        \n",
    "        false_sequences.pop(rand_index)\n",
    "        false_ids.pop(rand_index)\n",
    "    \n",
    "    filtered_ids = true_ids + false_ids\n",
    "    filtered_features = features[features.index.isin(filtered_ids)]\n",
    "    filtered_labels = labels[labels.index.isin(filtered_ids)]\n",
    "\n",
    "    if test_size <= 0.5:\n",
    "        training_indices, test_indices = next(iter(\n",
    "                sklearn.cross_validation.StratifiedKFold(filtered_labels, int(1/test_size), shuffle=True)))\n",
    "    else:\n",
    "        test_indices, training_indices = next(\n",
    "            iter(sklearn.cross_validation.StratifiedKFold(filtered_labels, int(1/(1-test_size)), shuffle=True)))\n",
    "    training_ids = [filtered_ids[i] for i in training_indices]\n",
    "    test_ids = [filtered_ids[i] for i in test_indices]\n",
    "    \n",
    "    training_features = filtered_features[filtered_features.index.isin(training_ids)]\n",
    "    test_features = filtered_features[filtered_features.index.isin(test_ids)]\n",
    "    training_labels = filtered_labels[filtered_labels.index.isin(training_ids)]\n",
    "    test_labels = filtered_labels[filtered_labels.index.isin(test_ids)]\n",
    "    \n",
    "    return training_features, test_features, training_labels, test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into GC content matched training and test data\n",
    "def get_split(features, labels, test_size):\n",
    "    '''\n",
    "    feature: 2D array (samples x features)\n",
    "    labels: 1D boolean array (samples x)\n",
    "    test_size: fraction of data to test on\n",
    "    '''\n",
    "    \n",
    "    ### match GC content of samples labelled True with those labelled False by thowing out False samples\n",
    "    # retrieve sequences using index of labels\n",
    "    index_label_tuples = tuple(zip(labels.index.values, labels.values))\n",
    "    \n",
    "    true_ids = [x[0] for x in index_label_tuples if x[1]]\n",
    "    \n",
    "    false_ids = [x[0] for x in index_label_tuples if not x[1]]\n",
    "       \n",
    "    filtered_ids = true_ids + false_ids\n",
    "    filtered_features = features[features.index.isin(filtered_ids)]\n",
    "    filtered_labels = labels[labels.index.isin(filtered_ids)]\n",
    "\n",
    "    if test_size <= 0.5:\n",
    "        training_indices, test_indices = next(iter(\n",
    "                sklearn.cross_validation.StratifiedKFold(filtered_labels, int(1/test_size), shuffle=True)))\n",
    "    else:\n",
    "        test_indices, training_indices = next(\n",
    "            iter(sklearn.cross_validation.StratifiedKFold(filtered_labels, int(1/(1-test_size)), shuffle=True)))\n",
    "    training_ids = [filtered_ids[i] for i in training_indices]\n",
    "    test_ids = [filtered_ids[i] for i in test_indices]\n",
    "    \n",
    "    training_features = filtered_features[filtered_features.index.isin(training_ids)]\n",
    "    test_features = filtered_features[filtered_features.index.isin(test_ids)]\n",
    "    training_labels = filtered_labels[filtered_labels.index.isin(training_ids)]\n",
    "    test_labels = filtered_labels[filtered_labels.index.isin(test_ids)]\n",
    "    \n",
    "    return training_features, test_features, training_labels, test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def signmoid(x):\n",
    "    result = 1/(1 + np.exp(-x))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateVIF(features):\n",
    "    '''\n",
    "    calculates the VIF for each feature\n",
    "    inputs: features, n X m (numSamples x numFeatures) vector of features\n",
    "    output: VIFS, list of m VIFS\n",
    "    '''\n",
    "    vifs = []\n",
    "    all_motifs = features.columns.values\n",
    "    for motif in all_motifs:\n",
    "        current_motif_scores = features[[motif]]\n",
    "        other_motif_scores = features[[x for x in all_motifs if not x == motif]]\n",
    "        lr = sklearn.linear_model.LinearRegression(n_jobs=-1)\n",
    "        lr.fit(other_motif_scores, current_motif_scores)\n",
    "        \n",
    "        # calculate the coefficient of determination\n",
    "        coeff_det = lr.score(other_motif_scores, current_motif_scores)\n",
    "        # calculate VIF\n",
    "        vif = 1/(1-coeff_det)\n",
    "        vifs.append(vif)\n",
    "    toReturn = pd.Series(data = vifs, index = all_motifs)\n",
    "    return toReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Score Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# random background files\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/random_background_analysis/motif_count_background_frame_C57BL6J.pickle3 ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/random_background_analysis/motif_score_background_frame_C57BL6J.pickle3 ./  \n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/random_background_analysis/motif_start_background_frame_C57BL6J.pickle3 ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/random_background_analysis/motif_end_background_frame_C57BL6J.pickle3 ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/random_background_analysis/motif_sequence_background_frame_C57BL6J.pickle3 ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/random_background_analysis/motif_strand_background_frame_C57BL6J.pickle3 ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/random_background_analysis/C57BL6J_background.fa ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Score Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "motif_score_frame=pd.read_pickle('motif_score_frame_C57BL6J.pickle2')\n",
    "motif_sequence_frame = pd.read_pickle('motif_sequence_frame_C57BL6J.pickle2')\n",
    "motif_strand_frame = pd.read_pickle('motif_strand_frame_C57BL6J.pickle2')\n",
    "motif_start_frame = pd.read_pickle('motif_start_frame_C57BL6J.pickle2')\n",
    "motif_end_frame = pd.read_pickle('motif_end_frame_C57BL6J.pickle2')\n",
    "motif_count_frame=pd.read_pickle('motif_count_frame_C57BL6J.pickle2')\n",
    "summary_frame = pd.read_pickle('summary_frame.pickle')\n",
    "annotation_frame = pd.read_pickle('annotation_frame.pickle')\n",
    "\n",
    "_factors = sorted(list(set([x.split('_')[1] for x in summary_frame.columns if '_' in x])))\n",
    "_factors.remove('atac')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "motif_score_background_frame = pd.read_pickle('motif_score_background_frame_C57BL6J.pickle3')\n",
    "motif_sequence_background_frame=pd.read_pickle('motif_sequence_background_frame_C57BL6J.pickle3')\n",
    "motif_strand_background_frame=pd.read_pickle('motif_strand_background_frame_C57BL6J.pickle3')\n",
    "motif_start_background_frame=pd.read_pickle('motif_start_background_frame_C57BL6J.pickle3')\n",
    "motif_end_background_frame=pd.read_pickle('motif_end_background_frame_C57BL6J.pickle3')\n",
    "motif_count_background_frame=pd.read_pickle('motif_count_background_frame_C57BL6J.pickle3')\n",
    "\n",
    "# make sure background frames don't have IDs that overlap with target frame\n",
    "motif_score_background_frame = motif_score_background_frame[~motif_score_background_frame.index.isin(motif_score_frame.index.values)]\n",
    "motif_sequence_background_frame = motif_sequence_background_frame[~motif_sequence_background_frame.index.isin(motif_score_frame.index.values)]\n",
    "motif_strand_background_frame = motif_strand_background_frame[~motif_strand_background_frame.index.isin(motif_score_frame.index.values)]\n",
    "motif_start_background_frame = motif_start_background_frame[~motif_start_background_frame.index.isin(motif_score_frame.index.values)]\n",
    "motif_end_background_frame = motif_end_background_frame[~motif_end_background_frame.index.isin(motif_score_frame.index.values)]\n",
    "motif_count_background_frame = motif_count_background_frame[~motif_count_background_frame.index.isin(motif_score_frame.index.values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = list(motif_score_frame.columns.values)\n",
    "columns.remove('ID')\n",
    "columns.remove('chr')\n",
    "columns.remove('Factors')\n",
    "motifs = columns\n",
    "sorted_columns = ['ID', 'chr' , 'Factors'] + sorted(motifs)\n",
    "\n",
    "motif_score_frame = motif_score_frame[sorted_columns]\n",
    "motif_sequence_frame = motif_sequence_frame[sorted_columns]\n",
    "motif_strand_frame = motif_strand_frame[sorted_columns]\n",
    "motif_start_frame = motif_start_frame[sorted_columns]\n",
    "motif_end_frame = motif_end_frame[sorted_columns]\n",
    "motif_count_frame = motif_count_frame[sorted_columns]\n",
    "\n",
    "motif_score_background_frame = motif_score_background_frame[sorted_columns]\n",
    "motif_sequence_background_frame = motif_sequence_background_frame[sorted_columns]\n",
    "motif_strand_background_frame = motif_strand_background_frame[sorted_columns]\n",
    "motif_start_background_frame = motif_start_background_frame[sorted_columns]\n",
    "motif_end_background_frame = motif_end_background_frame[sorted_columns]\n",
    "motif_count_background_frame = motif_count_background_frame[sorted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatent target and background frames\n",
    "# scores\n",
    "all_score_frame = pd.concat([motif_score_frame, motif_score_background_frame])\n",
    "all_score_frame = all_score_frame[motif_score_frame.columns.values]\n",
    "all_score_frame = all_score_frame[sorted_columns]\n",
    "\n",
    "# counts\n",
    "all_count_frame = pd.concat([motif_count_frame, motif_count_background_frame])\n",
    "all_count_frame = all_count_frame[motif_count_frame.columns.values]\n",
    "all_count_frame = all_count_frame.ix[:,3:]\n",
    "all_count_frame = all_count_frame[sorted(all_count_frame.columns.values)]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "all_standardized_score_frame = pd.DataFrame(scaler.fit_transform(all_score_frame.ix[:,3:]))\n",
    "all_standardized_score_frame.columns = all_score_frame.columns.values[3:]\n",
    "all_standardized_score_frame.index = all_score_frame.index.values\n",
    "all_standardized_score_frame = all_standardized_score_frame[sorted(all_standardized_score_frame.columns.values)]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "all_normed_score_frame = pd.DataFrame(scaler.fit_transform(all_score_frame.ix[:,3:]))\n",
    "all_normed_score_frame.columns = all_score_frame.columns.values[3:]\n",
    "all_normed_score_frame.index = all_score_frame.index.values\n",
    "all_normed_score_frame = all_normed_score_frame[sorted(all_normed_score_frame.columns.values)]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "all_standardized_count_frame = pd.DataFrame(scaler.fit_transform(all_count_frame))\n",
    "all_standardized_count_frame.columns = all_count_frame.columns.values\n",
    "all_standardized_count_frame.index = all_count_frame.index.values\n",
    "all_standardized_count_frame = all_standardized_count_frame[sorted(all_standardized_count_frame.columns.values)]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "all_normed_count_frame = pd.DataFrame(scaler.fit_transform(all_count_frame))\n",
    "all_normed_count_frame.columns = all_count_frame.columns.values\n",
    "all_normed_count_frame.index = all_count_frame.index.values\n",
    "all_normed_count_frame = all_normed_count_frame[sorted(all_normed_count_frame.columns.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in peak sequence\n",
    "### read in target sequences as dictionary {peakID: sequence}\n",
    "with open('./C57BL6J.fa') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "_id_sequence_dict = {}\n",
    "for line in data:\n",
    "    if line[0] == '>':\n",
    "        sequenceName = line.strip()[1:]\n",
    "    else:\n",
    "        _id_sequence_dict[sequenceName] = line.strip().upper()  \n",
    "### read in background sequences\n",
    "with open('./C57BL6J_background.fa') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "for line in data:\n",
    "    if line[0] == '>':\n",
    "        sequenceName = line.strip()[1:]\n",
    "    else:\n",
    "        _id_sequence_dict[sequenceName] = line.strip().upper()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap1_members=['atf3', 'cjun', 'fos', 'junb', 'jund']\n",
    "contains_ap1 = summary_frame[['c57bl6_'+x+'_veh' for x in ap1_members]].sum(axis=1)>0\n",
    "contains_ap1_tuples = tuple(zip(contains_ap1.index.values, contains_ap1.values, summary_frame['Factors'].values))\n",
    "summary_frame['Factors'] = [x[2] + ',c57bl6_ap-1_veh' if x[1] == True else x[2] for x in contains_ap1_tuples]\n",
    "\n",
    "contains_ap1 = summary_frame[['c57bl6_'+x+'_kla' for x in ap1_members]].sum(axis=1)>0\n",
    "contains_ap1_tuples = tuple(zip(contains_ap1.index.values, contains_ap1.values, summary_frame['Factors'].values))\n",
    "summary_frame['Factors'] = [x[2] + ',c57bl6_ap-1_kla' if x[1] == True else x[2] for x in contains_ap1_tuples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1 - AP-1 Cistrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression of AP-1 monomers before and after KLA treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "analyzeRepeats.pl rna mm10 -count exons -condenseGenes -rpkm -d  ~/analysis/ap1_analysis/tag_directories_rna/*Veh*UT*CR*/ ~/analysis/ap1_analysis/tag_directories_rna/*Veh*UT*VML*/ ~/analysis/ap1_analysis/tag_directories_rna/*KLA-1h*UT*/> rpkm_untreated.tsv\n",
    "\n",
    "# python ~/code/seq_merge_pipe/run_idr_homerRNA.py rpkm_untreated.tsv ./rna_idr_untreated KLA KLA Veh Veh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# idr_rpkm_frame = pd.read_csv('./rna_idr_untreated/idr_union.tsv', sep='\\t')\n",
    "\n",
    "# columns = idr_rpkm_frame.columns.values\n",
    "# columns[0] = \"refseq\"\n",
    "# for i in range(len(columns)):\n",
    "#     if \"FPKM\" in columns[i]:\n",
    "#         columns[i] = '_'.join(columns[i].split('/')[-2].split('_')[3:5])\n",
    "# idr_rpkm_frame.columns = columns    \n",
    "# idr_rpkm_frame['gene'] = [x.split(\"|\")[0].upper() for x in idr_rpkm_frame['Annotation/Divergence'].values]\n",
    "# idr_rpkm_frame.index = idr_rpkm_frame['gene'].values\n",
    "\n",
    "# idr_rpkm_mean_frame = pd.DataFrame()\n",
    "\n",
    "# for treatment in idr_rpkm_frame.columns.values[8:-1]:\n",
    "#     idr_rpkm_mean_frame[treatment] = np.mean(idr_rpkm_frame[treatment].astype(float), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in rpkm values\n",
    "rpkm_frame = pd.read_csv('./rpkm_untreated.tsv', sep='\\t')\n",
    "\n",
    "rpkm_frame.index = [x.split('|')[0].upper() for x in rpkm_frame['Annotation/Divergence']]\n",
    "rpkm_frame = rpkm_frame.ix[:,8:]\n",
    "rpkm_frame.columns = [x.split('/')[-2].split('_')[3] for x in rpkm_frame.columns.values]\n",
    "\n",
    "# rotate frame for plotting\n",
    "rpkm_plotting_frame = pd.DataFrame(rpkm_frame.stack(), \n",
    "                                   columns=['RPKM'])\n",
    "rpkm_plotting_frame['Gene'] = [x[0] for x in rpkm_plotting_frame.index.values]\n",
    "rpkm_plotting_frame['Treatment'] = [x[1] for x in rpkm_plotting_frame.index.values]\n",
    "rpkm_plotting_frame['Log2 RPKM'] = np.log2(rpkm_plotting_frame['RPKM'].values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from AP-1 as a regulator of cell life and death\n",
    "# Jun (c-Jun, JunB, JunD), \n",
    "# Fos (c-Fos, FosB, Fra-1 and Fra2), \n",
    "# Maf (c-Maf, MafB, MafA, MafG/F/K and Nrl) and \n",
    "# ATF (ATF2, LRF1/ATF3, B-ATF, JDP1, JDP2) \n",
    "# BATF3 and JDP1 are the same thing\n",
    "gene_list = ['JUN' , 'JUNB', 'JUND',\n",
    "             'FOS', 'FOSL1', 'FOSL2', 'FOSB',\n",
    "             'MAF', 'MAFA','MAFB','MAFG', 'MAFF', 'MAFK', 'NRL',\n",
    "             'ATF2', 'ATF3','BATF','JDP2','BATF3'#'JDP1'\n",
    "             ]\n",
    "# gene_list = ['ATF3', 'FOS', \n",
    "#              'JUN' , 'JUNB', 'JUND']\n",
    "plotting_frame = rpkm_plotting_frame[rpkm_plotting_frame['Gene'].isin(gene_list)]\n",
    "gene_list_tuples = []\n",
    "for gene in set(plotting_frame['Gene'].values):\n",
    "    vals = plotting_frame[plotting_frame['Gene']==gene]['Log2 RPKM'].values\n",
    "    gene_list_tuples.append((gene, np.max(vals)))\n",
    "gene_list_tuples.sort(key=lambda x:x[1])\n",
    "ordered_genes = [x[0] for x in gene_list_tuples]\n",
    "with sns.axes_style('ticks'):\n",
    "    sns.factorplot(data = plotting_frame, \n",
    "                   x='Gene', \n",
    "                   y='Log2 RPKM', \n",
    "                   hue='Treatment', \n",
    "                   kind='bar', \n",
    "                   order = ordered_genes,\n",
    "                   hue_order=['Veh','KLA-1h'], \n",
    "                   ci=100,\n",
    "                  size=4)\n",
    "    plt.xlabel('AP-1 Monomer')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig('./figures/figure_01_a.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of Vehicle Cistrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### create tag matrix\n",
    "!annotatePeaks.pl ./merged_peaks_filtered_resized.tsv mm10 -size given -d ./tag_directories_ap1/* > merged_annotated_peaks_ap1.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average tag counts from both replicates\n",
    "ap1_tag_frame = pd.read_csv('merged_annotated_peaks_ap1.tsv', sep='\\t')\n",
    "ap1_tag_frame.index = ap1_tag_frame.ix[:,0].values\n",
    "ap1_tag_frame = ap1_tag_frame[[x for x in ap1_tag_frame.columns.values if 'Tag Count' in x]]\n",
    "columns = [x.split(' ')[0].split('/')[-1].lower() for x in ap1_tag_frame.columns.values]\n",
    "ap1_tag_frame.columns = columns\n",
    "\n",
    "factor_treatments = sorted(set(['_'.join(x.split('_')[3:5]).split('-')[0] for x in columns]))\n",
    "\n",
    "ap1_meanTag_dict = {}\n",
    "for ft in factor_treatments:\n",
    "    ap1_meanTag_dict[ft] = ap1_tag_frame[[x for x in ap1_tag_frame.columns if ft in x]].mean(axis=1).values\n",
    "ap1_meanTag_frame = pd.DataFrame(ap1_meanTag_dict)\n",
    "ap1_meanTag_frame = ap1_meanTag_frame[factor_treatments]\n",
    "ap1_meanTag_frame.index = ap1_tag_frame.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clustermap for Vehicle\n",
    "c57bl6_indices = summary_frame[summary_frame['Factors'].str.contains('c57bl6_ap-1_veh')].index.values\n",
    "data = ap1_meanTag_frame[ap1_meanTag_frame.index.isin(c57bl6_indices)]\\\n",
    "    [['ATF3_Veh','cJun_Veh', 'Fos_Veh', 'JunB_Veh', 'JunD_Veh','Input_Veh']]\n",
    "# normalize by input\n",
    "data = data.div((data['Input_Veh'] + 1), axis=0)\n",
    "data = data.ix[:,:-1]\n",
    "logged_data = np.log2(data+1)\n",
    "cg = sns.clustermap(logged_data,\n",
    "          yticklabels=False,\n",
    "          xticklabels=[x.split('_')[0] for x in data.columns],\n",
    "          cmap='Blues',\n",
    "          col_cluster=False,\n",
    "          vmax=4\n",
    "          )\n",
    "plt.savefig('./figures/figure_01_b.svg', bbox_inches='tight')\n",
    "plt.savefig('./figures/figure_01_b.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of KLA Cistrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clustermap for KLA\n",
    "c57bl6_indices = summary_frame[summary_frame['Factors'].str.contains('c57bl6_ap-1_kla')].index.values\n",
    "data = ap1_meanTag_frame[ap1_meanTag_frame.index.isin(c57bl6_indices)]\\\n",
    "    [['ATF3_KLA','cJun_KLA', 'Fos_KLA', 'JunB_KLA', 'JunD_KLA', 'p65_KLA','Input_KLA']]\n",
    "data = data.div((data['Input_KLA'] + 1), axis=0)\n",
    "data = data.ix[:,:-1]\n",
    "logged_data = np.log2(data+1)\n",
    "cg = sns.clustermap(logged_data,\n",
    "          yticklabels=False,\n",
    "          xticklabels=[x.split('_')[0] for x in data.columns],\n",
    "          cmap='Reds',\n",
    "          col_cluster=False,\n",
    "          vmax=4)\n",
    "plt.savefig('./figures/figure_01_c.svg', bbox_inches='tight')\n",
    "plt.savefig('./figures/figure_01_c.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap for both Vehicle and KLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clustermap for KLA\n",
    "c57bl6_indices = summary_frame[summary_frame['Factors'].str.contains('c57bl6_ap-1')].index.values\n",
    "ap1_normedTag_frame = ap1_meanTag_frame[ap1_meanTag_frame.index.isin(c57bl6_indices)][[]]\n",
    "for factor in ['ATF3','cJun', 'Fos', 'JunB', 'JunD', 'p65']:\n",
    "    for treatment in ['Veh','KLA']:\n",
    "        ft = factor + '_' + treatment\n",
    "        ap1_normedTag_frame[ft] = (ap1_meanTag_frame[ft] + 1)/(ap1_meanTag_frame['Input_'+treatment]+1)\n",
    "\n",
    "logged_data = np.log2(ap1_normedTag_frame+1)\n",
    "cg = sns.clustermap(logged_data,\n",
    "          yticklabels=False,\n",
    "          xticklabels=logged_data.columns,\n",
    "          cmap='Greens',\n",
    "          col_cluster=False,\n",
    "          vmax=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(cg.data2d,\n",
    "          yticklabels=False,\n",
    "          xticklabels=logged_data.columns,\n",
    "          cmap='Greens',\n",
    "          col_cluster=False,\n",
    "          row_cluster=False,\n",
    "          vmin=0,\n",
    "          vmax=6)\n",
    "\n",
    "plt.savefig('./figures/figure_01_b-c.svg', bbox_inches='tight')\n",
    "plt.savefig('./figures/figure_01_b-c.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_columns = []\n",
    "for treatment in ['Veh', 'KLA']:\n",
    "    for factor in ['ATF3','cJun', 'Fos', 'JunB', 'JunD', 'p65']:\n",
    "        sorted_columns.append(factor + '_' + treatment)\n",
    "    \n",
    "sns.clustermap(cg.data2d[sorted_columns],\n",
    "          yticklabels=False,\n",
    "          xticklabels=sorted_columns,\n",
    "          cmap='Greens',\n",
    "          col_cluster=False,\n",
    "          row_cluster=False,\n",
    "          vmin=0,\n",
    "          vmax=6)\n",
    "\n",
    "# plt.savefig('./figures/figure_01_b-c.svg', bbox_inches='tight')\n",
    "plt.savefig('./figures/figure_01_b-c_byTreatment.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked barplot summarizing overlap of peaks before and after KLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ap1_members = ['atf3', 'cjun', 'fos', 'fra1', 'fra2','jdp2', 'junb', 'jund']\n",
    "ap1_members = ['atf3', 'cjun', 'fos', 'junb', 'jund']\n",
    "factor_list = []\n",
    "count_list = []\n",
    "type_list = []\n",
    "\n",
    "veh_columns = ['c57bl6_' + x + '_veh' for x in ap1_members]\n",
    "kla_columns = ['c57bl6_' + x + '_kla' for x in ap1_members]\n",
    "\n",
    "for i in range(len(ap1_members)):\n",
    "    factor = ap1_members[i]\n",
    "    \n",
    "        \n",
    "    veh_indices = set(summary_frame[summary_frame['c57bl6_' + factor + '_veh'] > 0].index.values)\n",
    "    kla_indices = set(summary_frame[summary_frame['c57bl6_' + factor + '_kla'] > 0].index.values)\n",
    "        \n",
    "    veh_count = len(veh_indices.difference(kla_indices))\n",
    "    both_count = len(veh_indices.intersection(kla_indices))\n",
    "    kla_count = len(kla_indices.difference(veh_indices))\n",
    "\n",
    "    factor_list = factor_list + 3*[factor]\n",
    "    type_list = type_list + ['Veh Specific', 'Shared', 'KLA Specific']\n",
    "    count_list.append(veh_count)\n",
    "    count_list.append(both_count)\n",
    "    count_list.append(kla_count)\n",
    "    \n",
    "plotting_frame = pd.DataFrame({'Factor':factor_list,\n",
    "                              'Type':type_list,\n",
    "                              'Number of Peaks': count_list})\n",
    "with sns.axes_style('ticks'):\n",
    "    sns.factorplot(data=plotting_frame, \n",
    "                   x = 'Factor',\n",
    "                   y = 'Number of Peaks',\n",
    "                   hue = 'Type',\n",
    "                   hue_order = ['Veh Specific', 'Shared', 'KLA Specific'],\n",
    "                   kind = 'bar')\n",
    "\n",
    "    plt.savefig('./figures/figure_01_d.png', bbox_inches='tight')\n",
    "    plt.savefig('./figures/figure_01_d.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phylogeny of AP-1 Monomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# protein tree built with clustalW\n",
    "# run code on local machine with python 2.7 and et3 installed\n",
    "# import ete3\n",
    "# with open(\"/Users/jenhantao/Downloads/protein_tree.txt\") as f:\n",
    "#     data = f.readlines()\n",
    "# tree_string = ''.join([x.strip() for x in data])\n",
    "# tree = ete3.Tree(tree_string)\n",
    "# ts = ete3.TreeStyle()\n",
    "# ts.show_leaf_name = True\n",
    "# ts.mode = \"c\"\n",
    "# ts.arc_start = 0 \n",
    "# ts.arc_span = 180\n",
    "# # tree.show(tree_style=ts)\n",
    "# tree.render(\"/Users/jenhantao/Desktop/tree_round.pdf\", w=3,h=3, dpi=200, units=\"in\",tree_style=ts)\n",
    "# tree.render(\"/Users/jenhantao/Desktop/tree_default.pdf\", w=3,h=3, dpi=200, units=\"in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2 - De Novo Motif Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "### create motif analysis directories\n",
    "if [ ! -d ./denovo_motif_analysis ]; \n",
    "then \n",
    "    # make directories for peaks\n",
    "    mkdir ./denovo_motif_analysis;\n",
    "    mkdir ./denovo_motif_analysis/veh_peaks;\n",
    "    mkdir ./denovo_motif_analysis/kla_peaks;\n",
    "    mkdir ./denovo_motif_analysis/veh_nonoverlapping_peaks;\n",
    "    mkdir ./denovo_motif_analysis/kla_nonoverlapping_peaks;\n",
    "    mkdir ./denovo_motif_analysis/veh_monomers_peaks;\n",
    "    mkdir ./denovo_motif_analysis/kla_monomers_peaks;\n",
    "    \n",
    "    # make directories for motif analysis\n",
    "    mkdir ./denovo_motif_analysis/veh_motif_analysis_overlapping;\n",
    "    mkdir ./denovo_motif_analysis/kla_motif_analysis_overlapping;\n",
    "    mkdir ./denovo_motif_analysis/veh_motif_analysis_nonoverlapping;\n",
    "    mkdir ./denovo_motif_analysis/kla_motif_analysis_nonoverlapping;\n",
    "    mkdir ./denovo_motif_analysis/veh_motif_analysis_monomers;\n",
    "    mkdir ./denovo_motif_analysis/kla_motif_analysis_monomers;\n",
    "    \n",
    "    # make directories for top motifs\n",
    "    mkdir ./denovo_motif_analysis/top_motifs_kla_overlapping;\n",
    "    mkdir ./denovo_motif_analysis/top_motifs_veh_overlapping;\n",
    "    mkdir ./denovo_motif_analysis/top_motifs_veh_nonoverlapping;\n",
    "    mkdir ./denovo_motif_analysis/top_motifs_kla_nonoverlapping;\n",
    "    mkdir ./denovo_motif_analysis/top_motifs_veh_monomers;\n",
    "    mkdir ./denovo_motif_analysis/top_motifs_kla_monomers;\n",
    "else\n",
    "    rm -rf ./denovo_motif_analysis/*/*\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For overlapping dimer and monomer peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### create peak files for denovo motif\n",
    "peak_threshold = 50 # minimum number of peaks required for running motif analysis\n",
    "factors = ['atf3', 'cjun', 'fos','junb', 'jund']\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for i in range(len(factors)):\n",
    "        factor1 = 'c57bl6_'+factors[i] + '_' + treatment\n",
    "        for j in range(i, len(factors)):\n",
    "            factor2 = 'c57bl6_'+ factors[j] + '_' + treatment\n",
    "\n",
    "            if factor1 == factor2:\n",
    "                outputPath = './denovo_motif_analysis/' + treatment + '_monomers_peaks/' + factor1 + '_peaks.tsv'\n",
    "\n",
    "                current_frame = summary_frame[(summary_frame[factor1] > 0)]\n",
    "            else:\n",
    "                outputPath = './denovo_motif_analysis/' + treatment + '_peaks/' + factor1 + '_' + factor2 + '_peaks.tsv'\n",
    "                current_frame = summary_frame[(summary_frame[factor1]> 0) &\n",
    "                                             (summary_frame[factor2] > 0)]\n",
    "            current_peak_frame = current_frame[['ID', 'chr', 'start', 'end']]\n",
    "            current_peak_frame['strand'] = '+'\n",
    "            columns = current_peak_frame.columns.values\n",
    "            columns[0]='#PeakID'        \n",
    "            current_peak_frame.columns = columns\n",
    "            if current_peak_frame.shape[0]  > peak_threshold:\n",
    "                outputPath = outputPath.replace('c57bl6_','')\n",
    "                current_peak_frame.to_csv(outputPath,\n",
    "                                         index=False,\n",
    "                                         sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for peakFile in ./denovo_motif_analysis/veh_peaks/*_peaks.tsv\n",
    "do\n",
    "    peakName=${peakFile%_peaks.tsv}\n",
    "    peakName=${peakName##*/}\n",
    "    findMotifsGenome.pl $peakFile mm10 ./denovo_motif_analysis/veh_motif_analysis_overlapping/${peakName} -size 200 -len 8 -p 8 -S 10 &\n",
    "    \n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for peakFile in ./denovo_motif_analysis/kla_peaks/*_peaks.tsv\n",
    "do\n",
    "    peakName=${peakFile%_peaks.tsv}\n",
    "    peakName=${peakName##*/}\n",
    "    findMotifsGenome.pl $peakFile mm10 ./denovo_motif_analysis/kla_motif_analysis_overlapping/${peakName} -size 200 -len 8 -p 8 -S 10 &\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf ./denovo_motif_analysis/veh_motif_analysis_monomers/*\n",
    "for peakFile in ./denovo_motif_analysis/veh_monomers_peaks/*_peaks.tsv\n",
    "do\n",
    "    peakName=${peakFile%_peaks.tsv}\n",
    "    peakName=${peakName##*/}\n",
    "    findMotifsGenome.pl $peakFile mm10 ./denovo_motif_analysis/veh_motif_analysis_monomers/${peakName} -size 200 -len 8 -p 8 -S 25 &\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf ./denovo_motif_analysis/kla_motif_analysis_monomers/*\n",
    "for peakFile in ./denovo_motif_analysis/kla_monomers_peaks/*_peaks.tsv\n",
    "do\n",
    "    peakName=${peakFile%_peaks.tsv}\n",
    "    peakName=${peakName##*/}\n",
    "    findMotifsGenome.pl $peakFile mm10 ./denovo_motif_analysis/kla_motif_analysis_monomers/${peakName} -size 200 -len 8 -p 8 -S 25 &\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For nonoverlapping dimer peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### create peak files for denovo motif analysis \n",
    "peak_threshold = 50 # minimum number of peaks required for running motif analysis\n",
    "\n",
    "factorPairs = []\n",
    "# ap1_members = ['atf3','cjun', 'fos', 'fra1','fra2', 'jdp2', 'junb','jund']    \n",
    "ap1_members = ['atf3','cjun', 'fos', 'junb','jund']    \n",
    "\n",
    "\n",
    "for i in range(len(ap1_members)-1):\n",
    "    for j in range(i+1, len(ap1_members)):\n",
    "        factorPairs.append(('c57bl6_'+ap1_members[i],'c57bl6_'+ ap1_members[j]))\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    c57bl6_columns = ['c57bl6_' + x + '_' + treatment for x in ap1_members]\n",
    "    for i in range(len(factorPairs)):\n",
    "        monomer1 = factorPairs[i][0] + '_' + treatment\n",
    "        monomer2 = factorPairs[i][1] + '_' + treatment\n",
    "            \n",
    "        outputPath = './denovo_motif_analysis/' + treatment + '_nonoverlapping_peaks/' + \\\n",
    "            '-'.join(factorPairs[i]).replace('c57bl6_','') + '_nonoverlapping_peaks.tsv'\n",
    "            \n",
    "        current_frame = summary_frame[(summary_frame[[monomer1, monomer2]].sum(axis=1) == summary_frame[c57bl6_columns].sum(axis=1))\n",
    "                                     & (summary_frame[monomer1] > 0) & (summary_frame[monomer2] > 0)]\n",
    "        if current_frame.shape[0] >= peak_threshold:\n",
    "            print(factorPairs[i], current_frame.shape)\n",
    "            current_peak_frame = current_frame[['ID', 'chr', 'start', 'end']]\n",
    "            current_peak_frame['strand'] = '+'\n",
    "            columns = current_peak_frame.columns.values\n",
    "            columns[0]='#PeakID'        \n",
    "            current_peak_frame.columns = columns\n",
    "            if current_peak_frame.shape[0]  > peak_threshold:\n",
    "                current_peak_frame.to_csv(outputPath,\n",
    "                                         index=False,\n",
    "                                         sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for peakFile in ./denovo_motif_analysis/veh_nonoverlapping_peaks/*_peaks.tsv\n",
    "do\n",
    "    peakName=${peakFile%_peaks.tsv}\n",
    "    peakName=${peakName##*/}\n",
    "    findMotifsGenome.pl $peakFile mm10 ./denovo_motif_analysis/veh_motif_analysis_nonoverlapping/${peakName} -size 200 -len 8 -p 8 -S 10 &\n",
    "done\n",
    "\n",
    "for peakFile in ./denovo_motif_analysis/kla_nonoverlapping_peaks/*_peaks.tsv\n",
    "do\n",
    "    peakName=${peakFile%_peaks.tsv}\n",
    "    peakName=${peakName##*/}\n",
    "    findMotifsGenome.pl $peakFile mm10 ./denovo_motif_analysis/kla_motif_analysis_nonoverlapping/${peakName} -size 200 -len 8 -p 8 -S 10 &\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get top motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# get top motif for all heterodimers\n",
    "\n",
    "\n",
    "for i in ./denovo_motif_analysis/veh_motif_analysis_overlapping/*; \n",
    "do dimerName=${i##*/}\n",
    "cp $i/homerResults/motif1.motif ./denovo_motif_analysis/top_motifs_veh_overlapping/${dimerName}.motif\n",
    "done\n",
    "\n",
    "for i in ./denovo_motif_analysis/kla_motif_analysis_overlapping/*; \n",
    "do dimerName=${i##*/}\n",
    "cp $i/homerResults/motif1.motif ./denovo_motif_analysis/top_motifs_kla_overlapping/${dimerName}.motif\n",
    "done\n",
    "\n",
    "for i in ./denovo_motif_analysis/veh_motif_analysis_nonoverlapping/*; \n",
    "do dimerName=${i##*/}\n",
    "cp $i/homerResults/motif1.motif ./denovo_motif_analysis/top_motifs_veh_nonoverlapping/${dimerName}.motif\n",
    "done\n",
    "\n",
    "for i in ./denovo_motif_analysis/kla_motif_analysis_nonoverlapping/*; \n",
    "do dimerName=${i##*/}\n",
    "cp $i/homerResults/motif1.motif ./denovo_motif_analysis/top_motifs_kla_nonoverlapping/${dimerName}.motif\n",
    "done\n",
    "\n",
    "for i in ./denovo_motif_analysis/veh_motif_analysis_monomers/*; \n",
    "do dimerName=${i##*/}\n",
    "cp $i/homerResults/motif1.motif ./denovo_motif_analysis/top_motifs_veh_monomers/${dimerName}.motif\n",
    "done\n",
    "\n",
    "for i in ./denovo_motif_analysis/kla_motif_analysis_monomers/*; \n",
    "do dimerName=${i##*/}\n",
    "cp $i/homerResults/motif1.motif ./denovo_motif_analysis/top_motifs_kla_monomers/${dimerName}.motif\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#create sequence logos for each top motif\n",
    "mkdir ./denovo_motif_analysis/top_motifs_veh_overlapping_logos\n",
    "mkdir ./denovo_motif_analysis/top_motifs_kla_overlapping_logos\n",
    "mkdir ./denovo_motif_analysis/top_motifs_veh_nonoverlapping_logos\n",
    "mkdir ./denovo_motif_analysis/top_motifs_kla_nonoverlapping_logos\n",
    "mkdir ./denovo_motif_analysis/top_motifs_veh_monomers_logos\n",
    "mkdir ./denovo_motif_analysis/top_motifs_kla_monomers_logos\n",
    "\n",
    "for i in ./denovo_motif_analysis/top_motifs_veh_overlapping/*; \n",
    "do motif2Logo.pl $i\n",
    "done\n",
    "for i in ./denovo_motif_analysis/top_motifs_kla_overlapping/*; \n",
    "do motif2Logo.pl $i\n",
    "done\n",
    "for i in ./denovo_motif_analysis/top_motifs_veh_nonoverlapping/*; \n",
    "do motif2Logo.pl $i\n",
    "done\n",
    "for i in ./denovo_motif_analysis/top_motifs_kla_nonoverlapping/*; \n",
    "do motif2Logo.pl $i\n",
    "done\n",
    "for i in ./denovo_motif_analysis/top_motifs_veh_monomers/*; \n",
    "do motif2Logo.pl $i\n",
    "done\n",
    "for i in ./denovo_motif_analysis/top_motifs_kla_monomers/*; \n",
    "do motif2Logo.pl $i\n",
    "done\n",
    "mv ./denovo_motif_analysis/top_motifs_veh_overlapping/*png ./denovo_motif_analysis/top_motifs_veh_overlapping_logos\n",
    "mv ./denovo_motif_analysis/top_motifs_kla_overlapping/*png ./denovo_motif_analysis/top_motifs_kla_overlapping_logos\n",
    "mv ./denovo_motif_analysis/top_motifs_veh_nonoverlapping/*png ./denovo_motif_analysis/top_motifs_veh_nonoverlapping_logos\n",
    "mv ./denovo_motif_analysis/top_motifs_kla_nonoverlapping/*png ./denovo_motif_analysis/top_motifs_kla_nonoverlapping_logos\n",
    "mv ./denovo_motif_analysis/top_motifs_veh_monomers/*png ./denovo_motif_analysis/top_motifs_veh_monomers_logos\n",
    "mv ./denovo_motif_analysis/top_motifs_kla_monomers/*png ./denovo_motif_analysis/top_motifs_kla_monomers_logos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browser shot for overlapping dimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atf3_labels = summary_frame['Factors'].str.contains('c57bl6_atf3_veh')\n",
    "jund_labels = summary_frame['Factors'].str.contains('c57bl6_jund_veh')\n",
    "\n",
    "cjun_labels = summary_frame['Factors'].str.contains('c57bl6_cjun_veh')\n",
    "fos_labels = summary_frame['Factors'].str.contains('c57bl6_fos_veh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_frame[~cjun_labels & ~fos_labels & atf3_labels & jund_labels][['chr', 'start', 'end', \n",
    "                                         'c57bl6_atf3_veh', \n",
    "                                         'c57bl6_jund_veh', \n",
    "                                         'c57bl6_cjun_veh', \n",
    "                                         'c57bl6_fos_veh']].sort('c57bl6_atf3_veh', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary_frame[cjun_labels & fos_labels & ~atf3_labels & ~jund_labels][['chr', 'start', 'end', \n",
    "                                         'c57bl6_atf3_veh', \n",
    "                                         'c57bl6_jund_veh', \n",
    "                                         'c57bl6_cjun_veh', \n",
    "                                         'c57bl6_fos_veh']].sort_values(by='c57bl6_fos_veh', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browser shot for nonoverlapping dimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_frame[cjun_labels & fos_labels & atf3_labels & jund_labels][['chr', 'start', 'end', \n",
    "                                         'c57bl6_atf3_veh', \n",
    "                                         'c57bl6_jund_veh', \n",
    "                                         'c57bl6_cjun_veh', \n",
    "                                         'c57bl6_fos_veh']].sort('c57bl6_fos_veh', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schematic showing top motif analysis for all overlapping dimer sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical clustering of de-novo motifs from all heterodimers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlapping heterodimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python /home/jtao/code/motif_tools/scoreMotifs.py ./denovo_motif_analysis/top_motifs_veh_monomers/ ./denovo_motif_analysis/top_motifs_veh_monomers/scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimers = [x.replace('.motif','',) for x in os.listdir('./denovo_motif_analysis/top_motifs_veh_monomers/') if '.motif' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlations = np.load('./denovo_motif_analysis/top_motifs_veh_monomers/scores/correlation.npz')['arr_0']\n",
    "\n",
    "distances = []\n",
    "for i in range(correlations.shape[0] - 1):\n",
    "    for j in range(i + 1, correlations.shape[0]):\n",
    "        distances.append( 1 - correlations[i][j])\n",
    "distances = np.array(distances)\n",
    "\n",
    "linkage = scipy.cluster.hierarchy.linkage(distances)\n",
    "\n",
    "with sns.axes_style('ticks'):\n",
    "    scipy.cluster.hierarchy.dendrogram(linkage, labels = dimers);\n",
    "    sns.despine()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('Heterodimer')\n",
    "    plt.ylabel('Height')\n",
    "plt.savefig('./figures/supplementary - veh motif dendrogram.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonoverlapping Heterodimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python /home/jtao/code/motif_tools/scoreMotifs.py ./denovo_motif_analysis/top_motifs_kla_monomers/ ./denovo_motif_analysis/top_motifs_kla_monomers/scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dimers = [x.replace('.motif','',) for x in os.listdir('./denovo_motif_analysis/top_motifs_kla_monomers') if '.motif' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "correlations = np.load('./denovo_motif_analysis/top_motifs_kla_monomers/scores/correlation.npz')['arr_0']\n",
    "\n",
    "distances = []\n",
    "for i in range(correlations.shape[0] - 1):\n",
    "    for j in range(i + 1, correlations.shape[0]):\n",
    "        distances.append( 1 - correlations[i][j])\n",
    "distances = np.array(distances)\n",
    "\n",
    "linkage = scipy.cluster.hierarchy.linkage(distances)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "with sns.axes_style('ticks'):\n",
    "    scipy.cluster.hierarchy.dendrogram(linkage, labels = dimers);\n",
    "    sns.despine()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('Heterodimer')\n",
    "    plt.ylabel('Height')\n",
    "    plt.savefig('./figures/supplementary - kla motif dendrogram.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked bar plot of known motif ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motif_dir = './denovo_motif_analysis/veh_motif_analysis_overlapping/'\n",
    "p_threshold = 0.01\n",
    "numMotifs = 5\n",
    "motif_rank_count_dict = {} # {motif: {rank:count}}\n",
    "for p in os.listdir(motif_dir):\n",
    "    tokens = p.split('_')\n",
    "    if len(tokens) > 2:\n",
    "        current_frame = pd.read_csv(motif_dir + p + '/knownResults.txt', sep='\\t')\n",
    "        current_significant_frame = current_frame[current_frame['P-value'].astype(float) < p_threshold]\n",
    "        if current_frame.shape[0] >= numMotifs:\n",
    "            top_motifs = current_significant_frame.ix[:numMotifs-1,'Motif Name'].values\n",
    "            \n",
    "            for i in range(len(top_motifs)):\n",
    "                motif = top_motifs[i]\n",
    "                if not motif in motif_rank_count_dict:\n",
    "                    motif_rank_count_dict[motif] = {x+1:0 for x in range(numMotifs)} # initialize dictionary\n",
    "                motif_rank_count_dict[motif][i+1] += 1\n",
    "        else:\n",
    "            print(p, 'is missing motifs')\n",
    "sorted_motifs = sorted(motif_rank_count_dict.keys())\n",
    "\n",
    "rank_dict = {x+1:[] for x in range(numMotifs)} # {rank:count} create dictionary for creating data frame, sorted_motifs will be index\n",
    "for motif in sorted_motifs:\n",
    "    for i in range(numMotifs):\n",
    "        rank_dict[i + 1].append(motif_rank_count_dict[motif][i+1])\n",
    "motif_rank_frame = pd.DataFrame(rank_dict)\n",
    "motif_rank_frame.index = sorted_motifs\n",
    "# clean up motif names\n",
    "motif_rank_frame.index = [x.split('-ChIP')[0] for x in motif_rank_frame.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('ticks'):\n",
    "    motif_rank_frame.plot(kind='bar', stacked=True)\n",
    "    sns.despine()\n",
    "    plt.legend(title='Rank')\n",
    "    plt.ylabel('Number of Ocurrences')\n",
    "    plt.xlabel('Homer Motif')\n",
    "    plt.savefig('./figures/figure_02_b.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan each monomer for top denovo motifs taken from all monomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combineTopMotifs(numMotifs, denovo_result_dir, scanning_results_dir):\n",
    "    if not os.path.isdir(scanning_results_dir):\n",
    "        os.mkdir(scanning_results_dir)\n",
    "\n",
    "    combinedFile = open(scanning_results_dir + '/combined.motif', 'w')\n",
    "\n",
    "    # for each denovo motif analysis result for each monomer\n",
    "    for monomer_result_dir in os.listdir(denovo_result_dir):\n",
    "        for i in range(1, numMotifs+1):\n",
    "            # construct path to motifs 1 through numMotifs\n",
    "            motif_path = denovo_result_dir + '/' + monomer_result_dir + '/homerResults/motif' + str(i) + '.motif'\n",
    "            # read in motif file\n",
    "            if os.path.isfile(motif_path):\n",
    "                with open(motif_path) as f:\n",
    "                    data = f.readlines()\n",
    "\n",
    "                # change motif header\n",
    "                headerTokens = data[0].split('\\t')\n",
    "                newMotifName = monomer_result_dir + '_' + str(i) + ',' + headerTokens[1].split(',')[1]\n",
    "                headerTokens[1] = newMotifName\n",
    "\n",
    "                newHeader = '\\t'.join(headerTokens)\n",
    "\n",
    "                # write motif into combined file\n",
    "                combinedFile.write(newHeader)\n",
    "                for line in data[1:]: # skip header line\n",
    "                    combinedFile.write(line)\n",
    "    combinedFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numMotifs = 10 # number of motifs to include\n",
    "denovo_result_dir = './denovo_motif_analysis/veh_motif_analysis_monomers/'\n",
    "scanning_results_dir = './denovo_motif_analysis/veh_motif_scanning/'\n",
    "combineTopMotifs(numMotifs, denovo_result_dir, scanning_results_dir)\n",
    "\n",
    "numMotifs = 10 # number of motifs to include\n",
    "denovo_result_dir = './denovo_motif_analysis/kla_motif_analysis_monomers/'\n",
    "scanning_results_dir = './denovo_motif_analysis/kla_motif_scanning/'\n",
    "combineTopMotifs(numMotifs, denovo_result_dir, scanning_results_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "### scan for top denovo motifs\n",
    "rm -rf ./denovo_motif_analysis/veh_motif_scanning/*/\n",
    "for peakFile in ./denovo_motif_analysis/veh_monomers_peaks/*_peaks.tsv\n",
    "do\n",
    "    peakName=${peakFile%_peaks.tsv}\n",
    "    peakName=${peakName##*/}\n",
    "    findMotifsGenome.pl $peakFile mm10 ./denovo_motif_analysis/veh_motif_scanning/${peakName} -nomotif -mknown ./denovo_motif_analysis/veh_motif_scanning/combined.motif -size 200 -p 8 &\n",
    "    \n",
    "done\n",
    "\n",
    "rm -rf ./denovo_motif_analysis/kla_motif_scanning/*/\n",
    "for peakFile in ./denovo_motif_analysis/kla_monomers_peaks/*_peaks.tsv\n",
    "do\n",
    "    peakName=${peakFile%_peaks.tsv}\n",
    "    peakName=${peakName##*/}\n",
    "    findMotifsGenome.pl $peakFile mm10 ./denovo_motif_analysis/kla_motif_scanning/${peakName} -nomotif -mknown ./denovo_motif_analysis/kla_motif_scanning/combined.motif -size 200 -p 8 &\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combineKnownMotifResults(scanning_results_dir):\n",
    "    sorted_motif_names = None\n",
    "    monomer_fractions_dict = {}\n",
    "    for result_dir in os.listdir(scanning_results_dir):\n",
    "        if os.path.isdir(scanning_results_dir + '/' + result_dir):\n",
    "            knownResults_path = scanning_results_dir + '/' + result_dir + '/knownResults.txt'\n",
    "            knownResults_frame = pd.read_csv(knownResults_path, sep='\\t')\n",
    "            motif_names = knownResults_frame['Motif Name'].values\n",
    "            if sorted_motif_names == None:\n",
    "                sorted_motif_names = sorted(motif_names)\n",
    "\n",
    "            string_target_fractions = knownResults_frame['% of Target Sequences with Motif'].values\n",
    "            target_fractions = np.array([float(x[:-1]) for x in string_target_fractions])\n",
    "\n",
    "            string_background_fractions = knownResults_frame['% of Background Sequences with Motif'].values\n",
    "            background_fractions = np.array([float(x[:-1]) for x in string_background_fractions])\n",
    "\n",
    "            enrichment = target_fractions/background_fractions\n",
    "            # sort fractions by motif name\n",
    "            name_fraction_dict =  dict(zip(motif_names, target_fractions))\n",
    "            sorted_fractions = [name_fraction_dict[x] for x in sorted_motif_names]\n",
    "\n",
    "            monomer_fractions_dict[result_dir] = sorted_fractions\n",
    "    monomer_fractions_frame = pd.DataFrame(monomer_fractions_dict, index = [x.split(',')[0] for x in sorted_motif_names])\n",
    "    return monomer_fractions_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine motif scanning results into one table\n",
    "scanning_results_dir = './denovo_motif_analysis/veh_motif_scanning/'\n",
    "\n",
    "veh_monomer_fractions_frame = combineKnownMotifResults(scanning_results_dir)\n",
    "\n",
    "scanning_results_dir = './denovo_motif_analysis/kla_motif_scanning/'\n",
    "\n",
    "kla_monomer_fractions_frame = combineKnownMotifResults(scanning_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,4))\n",
    "data = veh_monomer_fractions_frame.ix[[x for x in veh_monomer_fractions_frame.index.values if not 'junb' in x and not 'fos' in x], \n",
    "                                      [x for x in veh_monomer_fractions_frame.columns.values if not 'junb' in x and not 'fos' in x]]\n",
    "sns.heatmap(data,\n",
    "           vmin =0,\n",
    "#            vmax = 100,\n",
    "           yticklabels=False,\n",
    "            square=True,\n",
    "           cmap = 'Blues')\n",
    "plt.yticks(size=6);\n",
    "plt.xticks(size=6);\n",
    "\n",
    "plt.savefig('./figures/figure_02_b.svg')\n",
    "plt.savefig('./figures/figure_02_b.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "atf3_indices = set(summary_frame[summary_frame['c57bl6_atf3_veh'] > 0].index.values)\n",
    "cjun_indices = set(summary_frame[summary_frame['c57bl6_cjun_veh'] > 0].index.values)\n",
    "jund_indices = set(summary_frame[summary_frame['c57bl6_jund_veh'] > 0].index.values)\n",
    "matplotlib_venn.venn3([atf3_indices, cjun_indices, jund_indices], set_labels=['atf3', 'cjun', 'jund'])\n",
    "plt.savefig('./figures/figure_02_c_venn.svg')\n",
    "plt.savefig('./figures/figure_02_c_venn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fraction_list = []\n",
    "threshold_list = []\n",
    "factor_list = []\n",
    "thresholds = np.arange(0,100,10)\n",
    "atf3_indices = set(summary_frame[summary_frame['c57bl6_atf3_veh'] > 0].index.values)\n",
    "cjun_indices = set(summary_frame[summary_frame['c57bl6_cjun_veh'] > 0].index.values)\n",
    "jund_indices = set(summary_frame[summary_frame['c57bl6_jund_veh'] > 0].index.values)\n",
    "\n",
    "atf3_tagCounts = ap1_meanTag_frame[ap1_meanTag_frame.index.isin(atf3_indices)]['atf3_veh']\n",
    "cjun_tagCounts = ap1_meanTag_frame[ap1_meanTag_frame.index.isin(cjun_indices)]['cjun_veh']\n",
    "jund_tagCounts = ap1_meanTag_frame[ap1_meanTag_frame.index.isin(jund_indices)]['jund_veh']\n",
    "for threshold in thresholds:\n",
    "    atf3_threshold = np.percentile(atf3_tagCounts, threshold)\n",
    "    atf3_filtered_indices = set(atf3_tagCounts[atf3_tagCounts >= atf3_threshold].index.values)\n",
    "    cjun_threshold = np.percentile(cjun_tagCounts, threshold)\n",
    "    cjun_filtered_indices = set(cjun_tagCounts[cjun_tagCounts >= cjun_threshold].index.values)\n",
    "    jund_threshold = np.percentile(jund_tagCounts, threshold)\n",
    "    jund_filtered_indices = set(jund_tagCounts[jund_tagCounts >= jund_threshold].index.values)\n",
    "    \n",
    "    atf3_unique_indices = atf3_filtered_indices - (cjun_filtered_indices.union(jund_filtered_indices))\n",
    "    cjun_unique_indices = cjun_filtered_indices - (atf3_filtered_indices.union(jund_filtered_indices))\n",
    "    jund_unique_indices = jund_filtered_indices - (atf3_filtered_indices.union(cjun_filtered_indices))\n",
    "#     print('atf3', threshold, atf3_threshold, len(atf3_filtered_indices), len(atf3_indices))\n",
    "#     print('cjun', threshold, cjun_threshold, len(cjun_filtered_indices), len(cjun_indices))    \n",
    "#     print('jund', threshold, jund_threshold, len(jund_filtered_indices), len(jund_indices))\n",
    "    \n",
    "    atf3_unique_fraction = len(atf3_unique_indices)/len(atf3_filtered_indices)\n",
    "    cjun_unique_fraction = len(cjun_unique_indices)/len(cjun_filtered_indices)\n",
    "    jund_unique_fraction = len(jund_unique_indices)/len(jund_filtered_indices)\n",
    "    \n",
    "    fraction_list.append(atf3_unique_fraction)\n",
    "    fraction_list.append(cjun_unique_fraction)\n",
    "    fraction_list.append(jund_unique_fraction)\n",
    "    threshold_list = threshold_list + 3*[threshold]\n",
    "    factor_list = factor_list + ['atf3', 'cjun', 'jund']\n",
    "#     print('****', threshold, atf3_threshold, cjun_threshold, jund_threshold)\n",
    "#     print(atf3_unique_fraction, cjun_unique_fraction, jund_unique_fraction)\n",
    "#     print(len(atf3_filtered_indices), len(cjun_filtered_indices), len(jund_filtered_indices))\n",
    "    \n",
    "\n",
    "frame = pd.DataFrame({'Unique Peaks (% of Total Peaks)':fraction_list,\n",
    "                      'Percentile Threshold':threshold_list,\n",
    "                      'Monomer':factor_list}, \n",
    "                     )\n",
    "with sns.axes_style('ticks'):\n",
    "    sns.factorplot(data=frame, x = 'Percentile Threshold', y='Unique Peaks (% of Total Peaks)', hue='Monomer')\n",
    "    plt.savefig('./figures/figure_02_c_fraction.png')\n",
    "    plt.savefig('./figures/figure_02_c_fraction.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atf3_indices = set(summary_frame[summary_frame['c57bl6_atf3_veh'] > 0].index.values)\n",
    "cjun_indices = set(summary_frame[summary_frame['c57bl6_cjun_veh'] > 0].index.values)\n",
    "jund_indices = set(summary_frame[summary_frame['c57bl6_jund_veh'] > 0].index.values)\n",
    "1\n",
    "atf3_unique_indices = atf3_indices - (cjun_indices.union(jund_indices))\n",
    "cjun_unique_indices = cjun_indices - (atf3_indices.union(jund_indices))\n",
    "jund_unique_indices = jund_indices - (atf3_indices.union(cjun_indices))\n",
    "\n",
    "atf3_tagCounts = list(ap1_meanTag_frame[ap1_meanTag_frame.index.isin(atf3_indices)]['atf3_veh'].values)\n",
    "cjun_tagCounts = list(ap1_meanTag_frame[ap1_meanTag_frame.index.isin(cjun_indices)]['cjun_veh'].values)\n",
    "jund_tagCounts = list(ap1_meanTag_frame[ap1_meanTag_frame.index.isin(jund_indices)]['jund_veh'].values)\n",
    "\n",
    "atf3_unique_tagCounts = list(ap1_meanTag_frame[ap1_meanTag_frame.index.isin(atf3_unique_indices)]['atf3_veh'].values)\n",
    "cjun_unique_tagCounts = list(ap1_meanTag_frame[ap1_meanTag_frame.index.isin(cjun_unique_indices)]['cjun_veh'].values)\n",
    "jund_unique_tagCounts = list(ap1_meanTag_frame[ap1_meanTag_frame.index.isin(jund_unique_indices)]['jund_veh'].values)\n",
    "\n",
    "tag_count_list = []\n",
    "monomer_list = []\n",
    "peakType_list = []\n",
    "\n",
    "tag_count_list = tag_count_list + atf3_tagCounts + atf3_unique_tagCounts\n",
    "monomer_list = monomer_list + (len(atf3_tagCounts) + len(atf3_unique_tagCounts)) * ['atf3']\n",
    "peakType_list = peakType_list + len(atf3_tagCounts) *['all'] + len(atf3_unique_tagCounts) * ['unique']\n",
    "tag_count_list = tag_count_list + cjun_tagCounts + cjun_unique_tagCounts\n",
    "monomer_list = monomer_list + (len(cjun_tagCounts) + len(cjun_unique_tagCounts)) * ['cjun']\n",
    "peakType_list = peakType_list + len(cjun_tagCounts) *['all'] + len(cjun_unique_tagCounts) * ['unique']\n",
    "tag_count_list = tag_count_list + jund_tagCounts + jund_unique_tagCounts\n",
    "monomer_list = monomer_list + (len(jund_tagCounts) + len(jund_unique_tagCounts)) * ['jund']\n",
    "peakType_list = peakType_list + len(jund_tagCounts) *['all'] + len(jund_unique_tagCounts) * ['unique']\n",
    "\n",
    "frame = pd.DataFrame({'Normalized Reads': tag_count_list,\n",
    "                      'Log Normalized Reads': np.log2(np.array(tag_count_list) + 1),\n",
    "                      'Monomer':monomer_list,\n",
    "                      'Peak Type':peakType_list})\n",
    "\n",
    "sns.factorplot(data = frame, \n",
    "               kind = 'violin', \n",
    "               x = 'Monomer', \n",
    "               y = 'Log Normalized Reads',\n",
    "               hue = 'Peak Type', \n",
    "               showfliers = False,\n",
    "               inner=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1,3))\n",
    "sns.heatmap(kla_monomer_fractions_frame,\n",
    "           vmin =0,\n",
    "           vmax = 100,\n",
    "           cmap='Blues',\n",
    "           yticklabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bed Files for Use with GREAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdir = './great_bed_files/'\n",
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)\n",
    "else:\n",
    "    for f in os.listdir(outdir):\n",
    "        os.remove(outdir + '/' + f)\n",
    "strain = 'c57bl6'\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ['atf3', 'cjun', 'fos', 'junb', 'jund']:\n",
    "        position_frame = summary_frame[summary_frame[strain + '_' + monomer + '_' + treatment] > 0][['chr', 'start', 'end']]\n",
    "        position_frame.to_csv(outdir + '/' + strain + '_' + monomer + '_' + treatment + '.bed', \n",
    "                              sep='\\t', \n",
    "                              header = False,\n",
    "                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atf3_indices = set(summary_frame[summary_frame['c57bl6_atf3_veh'] > 0].index.values)\n",
    "cjun_indices = set(summary_frame[summary_frame['c57bl6_cjun_veh'] > 0].index.values)\n",
    "jund_indices = set(summary_frame[summary_frame['c57bl6_jund_veh'] > 0].index.values)\n",
    "\n",
    "atf3_unique_indices = atf3_indices - (cjun_indices.union(jund_indices))\n",
    "cjun_unique_indices = cjun_indices - (atf3_indices.union(jund_indices))\n",
    "jund_unique_indices = jund_indices - (atf3_indices.union(cjun_indices))\n",
    "\n",
    "position_frame = summary_frame[summary_frame.index.isin(atf3_unique_indices)][['chr', 'start', 'end']]\n",
    "position_frame.to_csv(outdir + '/' + strain + '_unique_atf3_veh_' + treatment + '.bed', \n",
    "                      sep='\\t', \n",
    "                      header = False,\n",
    "                      index=False)\n",
    "position_frame = summary_frame[summary_frame.index.isin(cjun_unique_indices)][['chr', 'start', 'end']]\n",
    "position_frame.to_csv(outdir + '/' + strain + '_unique_cjun_veh_' + treatment + '.bed', \n",
    "                      sep='\\t', \n",
    "                      header = False,\n",
    "                      index=False)\n",
    "position_frame = summary_frame[summary_frame.index.isin(jund_unique_indices)][['chr', 'start', 'end']]\n",
    "position_frame.to_csv(outdir + '/' + strain + '_unique_jund_veh_' + treatment + '.bed', \n",
    "                      sep='\\t', \n",
    "                      header = False,\n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3 - Machine Learning Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schematic of classifier workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIF Analysis for Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateVIF(features):\n",
    "    '''\n",
    "    calculates the VIF for each feature\n",
    "    inputs: features, n X m (numSamples x numFeatures) vector of features\n",
    "    output: VIFS, list of m VIFS\n",
    "    '''\n",
    "    vifs = []\n",
    "    all_motifs = features.columns.values\n",
    "    for motif in all_motifs:\n",
    "        current_motif_scores = features[[motif]]\n",
    "        other_motif_scores = features[[x for x in all_motifs if not x == motif]]\n",
    "        lr = sklearn.linear_model.LinearRegression(n_jobs=-1)\n",
    "        lr.fit(other_motif_scores, current_motif_scores)\n",
    "        \n",
    "        # calculate the coefficient of determination\n",
    "        coeff_det = lr.score(other_motif_scores, current_motif_scores)\n",
    "        # calculate VIF\n",
    "        if coeff_det == 1:\n",
    "            vif = 10\n",
    "        else:\n",
    "            vif = 1/(1-coeff_det)\n",
    "        vifs.append(vif)\n",
    "    toReturn = pd.Series(data = vifs, index = all_motifs)\n",
    "    return toReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affinity_vifs = calculateVIF(all_score_frame[sorted(all_score_frame.columns.values[3:])])\n",
    "\n",
    "count_vifs  = calculateVIF(all_count_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vifs[count_vifs > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affinity_vifs[affinity_vifs > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vif_frame = pd.DataFrame({'Data Type':['Count'] * len(count_vifs) + ['Affinity'] * len(affinity_vifs),\n",
    "                          'VIF': np.concatenate([count_vifs.values, affinity_vifs.values]) \n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('ticks'):\n",
    "    sns.factorplot(data = vif_frame,\n",
    "                   x = 'Data Type',\n",
    "                   y = 'VIF',\n",
    "                   kind = 'box',\n",
    "                  size=3)\n",
    "plt.ylim(0,20)\n",
    "plt.plot([-1,3], [10,10], c = 'black', linestyle='--')\n",
    "plt.savefig('./figures/supplementary - VIF analysis.png')\n",
    "plt.savefig('./figures/supplementary - VIF analysis.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4 - Motifs for Vehicle Dimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_ensemble_classifier(affinity_features,\n",
    "                              count_features, \n",
    "                              labels,\n",
    "                              numIterations = 5,\n",
    "                              test_size = 0.5,\n",
    "                             ):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    all_rocs = []\n",
    "    all_affinity_rocs = []\n",
    "    all_count_rocs = []\n",
    "\n",
    "    all_precisions = []\n",
    "    all_affinity_precisions = []\n",
    "    all_count_precisions = []\n",
    "    \n",
    "    all_coefficients = []\n",
    "    all_affinity_coefficients = []\n",
    "    all_count_coefficients = []\n",
    "\n",
    "    for i in range(numIterations):  \n",
    "\n",
    "        # split data into training and test sets\n",
    "        training_affinity_features, test_affinity_features, training_labels, test_labels = get_split(\n",
    "            affinity_features, labels, test_size = test_size)\n",
    "        training_count_features = count_features[count_features.index.isin(training_affinity_features.index.values)]\n",
    "        test_count_features = count_features[count_features.index.isin(test_affinity_features.index.values)]\n",
    "        #  Train affinity classifier\n",
    "        affinity_classifier = sklearn.linear_model.LogisticRegression(penalty='l1', n_jobs=-1)\n",
    "        affinity_classifier.fit(training_affinity_features, training_labels)\n",
    "\n",
    "        # Train count classifier\n",
    "        count_classifier = sklearn.linear_model.LogisticRegression(penalty='l1', n_jobs=-1)\n",
    "        count_classifier.fit(training_count_features, training_labels)\n",
    "\n",
    "        # train combined classifier\n",
    "        training_affinity_scores = affinity_classifier.decision_function(training_affinity_features)\n",
    "        training_count_scores = count_classifier.decision_function(training_count_features)\n",
    "        training_combined_features = pd.DataFrame({'Affinity':training_affinity_scores,\n",
    "                                         'Count':training_count_scores})\n",
    "        combined_classifier = sklearn.linear_model.LogisticRegression(penalty='l1', n_jobs=-1)\n",
    "        combined_classifier.fit(training_combined_features, training_labels)\n",
    "\n",
    "        # retrieve test probabilities\n",
    "        test_affinity_scores = affinity_classifier.decision_function(test_affinity_features)\n",
    "        test_count_scores = count_classifier.decision_function(test_count_features)\n",
    "        test_combined_features = pd.DataFrame({'Affinity':test_affinity_scores,\n",
    "                                                   'Count':test_count_scores})\n",
    "\n",
    "        # score predictions\n",
    "        affinity_probas = affinity_classifier.predict_proba(test_affinity_features)\n",
    "        current_affinity_rocs = sklearn.metrics.roc_auc_score(test_labels, affinity_probas[:, 1], average = None)\n",
    "        current_affinity_precision = sklearn.metrics.average_precision_score(test_labels, affinity_probas[:, 1], average = None)\n",
    "        \n",
    "        count_probas = count_classifier.predict_proba(test_count_features)\n",
    "        current_count_rocs = sklearn.metrics.roc_auc_score(test_labels, count_probas[:, 1], average = None)\n",
    "        current_count_precision = sklearn.metrics.average_precision_score(test_labels, count_probas[:, 1], average = None)\n",
    "    \n",
    "        probas = combined_classifier.predict_proba(test_combined_features)\n",
    "        current_rocs = sklearn.metrics.roc_auc_score(test_labels, probas[:, 1], average = None)\n",
    "        current_precision = sklearn.metrics.average_precision_score(test_labels, probas[:, 1], average = None)\n",
    "\n",
    "         # retrieve coefficients\n",
    "        current_coefficients = combined_classifier.coef_.flatten()\n",
    "        current_affinity_coefficients = affinity_classifier.coef_.flatten()\n",
    "        current_count_coefficients = count_classifier.coef_.flatten()\n",
    "        \n",
    "        all_rocs.append(current_rocs)\n",
    "        all_affinity_rocs.append(current_affinity_rocs)\n",
    "        all_count_rocs.append(current_count_rocs)\n",
    "\n",
    "        all_precisions.append(current_precision)\n",
    "        all_affinity_precisions.append(current_affinity_precision)\n",
    "        all_count_precisions.append(current_count_precision)\n",
    "\n",
    "        all_coefficients.append(current_count_coefficients)\n",
    "        all_affinity_coefficients.append(current_affinity_coefficients)\n",
    "        all_count_coefficients.append(current_count_coefficients)      \n",
    "    \n",
    "#     mean_affinity_coefficients = np.mean(all_affinity_coefficients, axis=0)\n",
    "#     mean_count_coefficients = np.mean(all_count_coefficients, axis=0)\n",
    "        \n",
    "    results = (all_rocs, \n",
    "               all_affinity_rocs, \n",
    "               all_count_rocs, \n",
    "               all_precisions, \n",
    "               all_affinity_precisions, \n",
    "               all_count_precisions,\n",
    "               all_coefficients,\n",
    "               all_affinity_coefficients,\n",
    "               all_count_coefficients)\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numIterations = 5\n",
    "test_size = 0.5\n",
    "background_ratio = 1.0\n",
    "ap1_members = ['atf3','cjun', 'fos', 'junb','jund']    \n",
    "factors = ['atf3','cjun', 'fos', 'junb','jund', 'cebpa', 'pu1', 'p65']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for monomers using motif counts and best motif score \n",
    "strain = 'c57bl6'\n",
    "\n",
    "factor_coeff_dict = {}\n",
    "factor_affinityCoeff_dict = {}\n",
    "factor_countCoeff_dict = {}\n",
    "\n",
    "factor_roc_dict = {}\n",
    "factor_affinity_roc_dict = {}\n",
    "factor_count_roc_dict = {}\n",
    "\n",
    "factor_precision_dict = {}\n",
    "factor_affinity_precision_dict = {}\n",
    "factor_count_precision_dict = {}\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in factors:\n",
    "        target_indices = summary_frame[summary_frame[strain + '_' + monomer + '_' + treatment] > 0.0].index.values\n",
    "#         background_indices = motif_score_background_frame[\n",
    "#             motif_score_background_frame['Factors'] == strain + '_' + monomer + '_' + treatment + '-background'].index.values\n",
    "        background_indices = motif_score_background_frame.index.values\n",
    "        # select subset of background indices to use\n",
    "        shuffle(background_indices)\n",
    "        background_indices = background_indices[:np.ceil(background_ratio*len(target_indices))]\n",
    "        \n",
    "        target_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(target_indices)]\n",
    "        background_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(background_indices)]\n",
    "        \n",
    "        # merge target and background features together \n",
    "        affinity_features = pd.concat([target_affinity_features, background_affinity_features])\n",
    "        count_features = all_count_frame\n",
    "        labels = pd.Series(data = [True] * len(target_indices) + [False] * len(background_indices),\n",
    "                           index = affinity_features.index.values)\n",
    "        print(np.sum(labels), len(labels))\n",
    "                \n",
    "        results = train_ensemble_classifier(affinity_features, \n",
    "                                            count_features, \n",
    "                                            labels,\n",
    "                                            numIterations = numIterations,\n",
    "                                            test_size = test_size,\n",
    "                                            )\n",
    "        \n",
    "        # unpack result tuples\n",
    "        all_rocs = results[0]\n",
    "        all_affinity_rocs = results[1]\n",
    "        all_count_rocs = results[2]\n",
    "        all_precisions = results[3]\n",
    "        all_affinity_precisions = results[4]\n",
    "        all_count_precisions = results[5]\n",
    "        all_coefficients = results[6]\n",
    "        all_affinity_coefficients = results[7]\n",
    "        all_count_coefficients = results[8]\n",
    "        \n",
    "        factor_roc_dict[monomer + '_' + treatment] = all_rocs\n",
    "        factor_affinity_roc_dict[monomer + '_' + treatment] = all_affinity_rocs\n",
    "        factor_count_roc_dict[monomer + '_' + treatment] = all_count_rocs\n",
    "       \n",
    "        factor_precision_dict[monomer + '_' + treatment] = all_precisions\n",
    "        factor_affinity_precision_dict[monomer + '_' + treatment] = all_affinity_precisions\n",
    "        factor_count_precision_dict[monomer + '_' + treatment] = all_count_precisions\n",
    "    \n",
    "        factor_coeff_dict[monomer + '_' + treatment] = all_coefficients\n",
    "        factor_affinityCoeff_dict[monomer + '_' + treatment] = all_affinity_coefficients\n",
    "        factor_countCoeff_dict[monomer + '_' + treatment] = all_count_coefficients\n",
    "        \n",
    "        \n",
    "        print(monomer + '_' + treatment,\n",
    "              'roc:', np.mean(all_rocs), np.mean(all_affinity_rocs), np.mean(all_count_rocs),\n",
    "              'precision:', np.mean(all_precisions), np.mean(all_affinity_precisions), np.mean(all_count_precisions)\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP-1 Motif Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for monomers using motif counts and best motif score \n",
    "strain = 'c57bl6'\n",
    "\n",
    "factor_coeff_ap1Only_dict = {}\n",
    "factor_affinityCoeff_ap1Only_dict = {}\n",
    "factor_countCoeff_ap1Only_dict = {}\n",
    "\n",
    "factor_roc_ap1Only_dict = {}\n",
    "factor_affinity_roc_ap1Only_dict = {}\n",
    "factor_count_roc_ap1Only_dict = {}\n",
    "\n",
    "factor_precision_ap1Only_dict = {}\n",
    "factor_affinity_precision_ap1Only_dict = {}\n",
    "factor_count_precision_ap1Only_dict = {}\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in factors:\n",
    "        target_indices = summary_frame[summary_frame[strain + '_' + monomer + '_' + treatment] > 0.0].index.values\n",
    "#         background_indices = motif_score_background_frame[\n",
    "#             motif_score_background_frame['Factors'] == strain + '_' + monomer + '_' + treatment + '-background'].index.values\n",
    "        background_indices = motif_score_background_frame.index.values\n",
    "        # select subset of background indices to use\n",
    "        shuffle(background_indices)\n",
    "        background_indices = background_indices[:np.ceil(background_ratio*len(target_indices))]\n",
    "        \n",
    "        target_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(target_indices)]\n",
    "        background_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(background_indices)]\n",
    "        \n",
    "        # merge target and background features together \n",
    "        affinity_features = pd.concat([target_affinity_features, background_affinity_features])\n",
    "        count_features = all_count_frame\n",
    "        \n",
    "        affinity_features = affinity_features[['ap-1','atf7_batf3_creb5']]\n",
    "        count_features = all_count_frame[['ap-1','atf7_batf3_creb5']] \n",
    "        \n",
    "        labels = pd.Series(data = [True] * len(target_indices) + [False] * len(background_indices),\n",
    "                           index = affinity_features.index.values)\n",
    "        print(np.sum(labels), len(labels))\n",
    "                \n",
    "        results = train_ensemble_classifier(affinity_features, \n",
    "                                            count_features, \n",
    "                                            labels,\n",
    "                                            numIterations = numIterations,\n",
    "                                            test_size = test_size,\n",
    "                                            )\n",
    "        \n",
    "        # unpack result tuples\n",
    "        all_rocs = results[0]\n",
    "        all_affinity_rocs = results[1]\n",
    "        all_count_rocs = results[2]\n",
    "        all_precisions = results[3]\n",
    "        all_affinity_precisions = results[4]\n",
    "        all_count_precisions = results[5]\n",
    "        all_coefficients = results[6]\n",
    "        all_affinity_coefficients = results[7]\n",
    "        all_count_coefficients = results[8]\n",
    "        \n",
    "        factor_roc_ap1Only_dict[monomer + '_' + treatment] = all_rocs\n",
    "        factor_affinity_roc_ap1Only_dict[monomer + '_' + treatment] = all_affinity_rocs\n",
    "        factor_count_roc_ap1Only_dict[monomer + '_' + treatment] = all_count_rocs\n",
    "       \n",
    "        factor_precision_ap1Only_dict[monomer + '_' + treatment] = all_precisions\n",
    "        factor_affinity_precision_ap1Only_dict[monomer + '_' + treatment] = all_affinity_precisions\n",
    "        factor_count_precision_ap1Only_dict[monomer + '_' + treatment] = all_count_precisions\n",
    "    \n",
    "        factor_coeff_ap1Only_dict[monomer + '_' + treatment] = all_coefficients\n",
    "        factor_affinityCoeff_ap1Only_dict[monomer + '_' + treatment] = all_affinity_coefficients\n",
    "        factor_countCoeff_ap1Only_dict[monomer + '_' + treatment] = all_count_coefficients\n",
    "        \n",
    "        \n",
    "        print(monomer + '_' + treatment,\n",
    "              'roc:', np.mean(all_rocs), np.mean(all_affinity_rocs), np.mean(all_count_rocs),\n",
    "              'precision:', np.mean(all_precisions), np.mean(all_affinity_precisions), np.mean(all_count_precisions)\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability of Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factor_meanCoeff_affinity_dict = {}\n",
    "factor_meanCoeff_count_dict = {}\n",
    "\n",
    "treatment_list = []\n",
    "factor_list = []\n",
    "mad_list = []\n",
    "ratio_list = []\n",
    "weight_list = []\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        current_affinity_weights = factor_affinityCoeff_dict[monomer + '_' + treatment]\n",
    "        current_affinity_weight_frame = pd.DataFrame(current_affinity_weights, \n",
    "                                                     ).T\n",
    "        mean_affinity_weights = current_affinity_weight_frame.mean(axis=1).values\n",
    "        affinity_weight_mads = current_affinity_weight_frame.mad(axis=1).values\n",
    "        \n",
    "        ratios = np.abs(mean_affinity_weights)/ np.abs(affinity_weight_mads)\n",
    "        \n",
    "        factor_meanCoeff_affinity_dict[monomer + '_' + treatment] = mean_affinity_weights\n",
    "        \n",
    "        treatment_list = treatment_list + [treatment] * len(mean_affinity_weights)\n",
    "        factor_list = factor_list + [monomer] * len(mean_affinity_weights)\n",
    "        mad_list = mad_list + list(affinity_weight_mads)\n",
    "        ratio_list = ratio_list + list(ratios)\n",
    "        weight_list = weight_list + list(mean_affinity_weights)\n",
    "        \n",
    "frame = pd.DataFrame({'Factor':factor_list,\n",
    "                      'Treatment':treatment_list,\n",
    "                      'MAD':mad_list,\n",
    "                      'Weight/MAD Ratio': ratio_list,\n",
    "                      'Weight':weight_list})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients_zscore_veh_frame = coefficients_zscore_frame[['atf3_veh', 'cjun_veh', 'jund_veh']]\n",
    "# coefficients_zscore_veh_frame['variance'] = coefficients_zscore_veh_frame[['atf3_veh', 'cjun_veh', 'jund_veh']].var(axis=1)\n",
    "# coefficients_zscore_veh_frame['maxDist'] = coefficients_zscore_veh_frame[['atf3_veh', 'cjun_veh', 'jund_veh']].max(axis=1) - coefficients_zscore_veh_frame[['atf3_veh', 'cjun_veh', 'jund_veh']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### plot coefficents for vehicle\n",
    "weight_threshold = 1.0\n",
    "\n",
    "data = coefficients_zscore_veh_frame[(coefficients_zscore_veh_frame.max(axis=1) >= weight_threshold) |\n",
    "                                (coefficients_zscore_veh_frame.min(axis=1) < -1 * weight_threshold)\n",
    "                                ][['atf3_veh', 'cjun_veh', 'jund_veh']]\n",
    "# data = coefficients_zscore_frame[coefficients_zscore_frame.index.isin(veh_frame.sort('maxDist', ascending=False).index.values[:20])\n",
    "#                                 ][['atf3_veh', 'cjun_veh', 'jund_veh']]\n",
    "cg = sns.clustermap(data = data,\n",
    "#                    vmax=-1*weight_threshold,\n",
    "#                    vmin= 1* weight_threshold,\n",
    "                   center = 0.0,\n",
    "#                    annot=True,annot_kws={\"size\": 4},\n",
    "                   col_cluster = False,\n",
    "#                    yticklabels=False,\n",
    "                   figsize=(3,12),\n",
    "                   )\n",
    "plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), fontsize=10, rotation=0, );\n",
    "# plt.savefig('./figures/figure_04_e.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotting_data = pd.DataFrame(data.stack(), columns= ['Weight'])\n",
    "index = plotting_data.index.values\n",
    "plotting_data['Motif'] = [x[0] for x in index]\n",
    "plotting_data['Monomer'] = [x[1] for x in index]\n",
    "plotting_data.sort(['Weight'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data = plotting_data, \n",
    "               x = 'Motif', \n",
    "               y='Weight', \n",
    "               kind = 'bar',\n",
    "               hue = 'Monomer')\n",
    "plt.xticks(rotation = 90, size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients_affinity_frame = pd.DataFrame(factor_affinityCoeff_dict)\n",
    "coefficients_count_frame = pd.DataFrame(factor_countCoeff_dict)\n",
    "coefficients_affinity_frame = all_standardized_score_frame.columns.values\n",
    "coefficients_count_frame = all_standardized_score_frame.columns.values\n",
    "\n",
    "# transform_coffcients into z-scores\n",
    "coefficients_zscore_frame_veh = coefficients_frame_veh[[]]\n",
    "for col in coefficients_frame_veh:\n",
    "    coefficients_zscore_frame_veh[col] = scipy.stats.mstats.zscore(coefficients_frame_veh[col].values)\n",
    "\n",
    "coefficients_zscore_frame_veh.index = coefficients_frame_veh.index.values\n",
    "coefficients_zscore_frame_veh.columns = coefficients_frame_veh.columns.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for monomers using motif counts and best motif score for top motifs\n",
    "strain = 'c57bl6'\n",
    "weight_threshold = 1\n",
    "factor_coeff_top_dict = {}\n",
    "factor_affinityCoeff_top_dict = {}\n",
    "factor_countCoeff_top_dict = {}\n",
    "\n",
    "factor_roc_top_dict = {}\n",
    "factor_affinity_roc_top_dict = {}\n",
    "factor_count_roc_top_dict = {}\n",
    "\n",
    "factor_precision_top_dict = {}\n",
    "factor_affinity_precision_top_dict = {}\n",
    "factor_count_precision_top_dict = {}\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        # determine top motifs\n",
    "        data = coefficients_zscore_frame\n",
    "        top_motifs = data[(data[monomer + '_' + treatment] >= weight_threshold) |\n",
    "                    (data[monomer + '_' + treatment] < -1 * weight_threshold)\n",
    "                    ].index.values\n",
    "        print(len(top_motifs))\n",
    "        target_indices = summary_frame[summary_frame[strain + '_' + monomer + '_' + treatment] > 0.0].index.values\n",
    "        background_indices = motif_score_background_frame[\n",
    "            motif_score_background_frame['Factors'] == strain + '_' + monomer + '_' + treatment + '-background'].index.values\n",
    "        \n",
    "        # select subset of background indices to use\n",
    "        shuffle(background_indices)\n",
    "        background_indices = background_indices[:np.ceil(background_ratio*len(target_indices))]\n",
    "        \n",
    "        target_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(target_indices)]\n",
    "        background_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(background_indices)]\n",
    "        \n",
    "        # merge target and background features together \n",
    "        affinity_features = pd.concat([target_affinity_features, background_affinity_features])\n",
    "        \n",
    "        affinity_features = affinity_features[top_motifs]\n",
    "        count_features = all_count_frame[top_motifs] \n",
    "        \n",
    "        labels = pd.Series(data = [True] * len(target_indices) + [False] * len(background_indices),\n",
    "                           index = affinity_features.index.values)\n",
    "                \n",
    "        results = train_ensemble_classifier(affinity_features, \n",
    "                                            count_features, \n",
    "                                            labels,\n",
    "                                            numIterations = numIterations,\n",
    "                                            test_size = test_size,\n",
    "                                            )\n",
    "        \n",
    "        # unpack result tuples\n",
    "        # unpack result tuples\n",
    "        all_rocs = results[0]\n",
    "        all_affinity_rocs = results[1]\n",
    "        all_count_rocs = results[2]\n",
    "        all_precisions = results[3]\n",
    "        all_affinity_precisions = results[4]\n",
    "        all_count_precisions = results[5]\n",
    "        all_coefficients = results[6]\n",
    "        all_affinity_coefficients = results[7]\n",
    "        all_count_coefficients = results[8]\n",
    "\n",
    "        factor_roc_top_dict[monomer + '_' + treatment] = all_rocs\n",
    "        factor_affinity_roc_top_dict[monomer + '_' + treatment] = all_affinity_rocs\n",
    "        factor_count_roc_top_dict[monomer + '_' + treatment] = all_count_rocs\n",
    "       \n",
    "        factor_precision_top_dict[monomer + '_' + treatment] = all_precisions\n",
    "        factor_affinity_precision_top_dict[monomer + '_' + treatment] = all_affinity_precisions\n",
    "        factor_count_precision_top_dict[monomer + '_' + treatment] = all_count_precisions\n",
    "    \n",
    "        factor_coeff_top_dict[monomer + '_' + treatment] = all_coefficients\n",
    "        factor_affinityCoeff_top_dict[monomer + '_' + treatment] = all_affinity_coefficients\n",
    "        factor_countCoeff_top_dict[monomer + '_' + treatment] = all_count_coefficients\n",
    "        \n",
    "        \n",
    "        print(monomer + '_' + treatment,\n",
    "              'roc:', np.mean(all_rocs), np.mean(all_affinity_rocs), np.mean(all_count_rocs),\n",
    "              'precision:', np.mean(all_precisions), np.mean(all_affinity_precisions), np.mean(all_count_precisions)\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monomers = []\n",
    "rocs = []\n",
    "feature_set = []\n",
    "for factor in ['atf3_veh', 'cjun_veh', 'jund_veh']:\n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    rocs = rocs + factor_affinity_roc_ap1Only_dict[factor]\n",
    "    feature_set = feature_set + numIterations * ['Known Motif']\n",
    "    \n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    rocs = rocs + factor_affinity_roc_dict[factor]\n",
    "    feature_set = feature_set + numIterations * ['All Motifs']\n",
    "    \n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    rocs = rocs + factor_affinity_roc_top_dict[factor]\n",
    "    feature_set = feature_set + numIterations * ['Top Motifs']\n",
    "    \n",
    "data = pd.DataFrame({'Factor':monomers,\n",
    "                     'roc':rocs,\n",
    "                     'Feature Set': feature_set\n",
    "                     })\n",
    "\n",
    "for treatment in ['veh']:\n",
    "    factor_roc_tuples = [(x, np.mean(factor_roc_dict[x])) for x in factor_roc_dict if treatment in x]\n",
    "    sorted_monomers = [y[0] for y in sorted(factor_roc_tuples, key=lambda x:x[1])]\n",
    "    with sns.axes_style('ticks'):\n",
    "        plottingFrame = sns.factorplot(data = data[data['Factor'].str.contains(treatment)],\n",
    "                                    x='Factor',\n",
    "                                    y='roc',\n",
    "#                                     order = sorted_monomers,\n",
    "                                    palette='Set1',\n",
    "                                    size=3,\n",
    "                                    hue='Feature Set',\n",
    "                                    kind = 'bar')\n",
    "                                    #markers = '.', s='0.01')\n",
    "        sns.despine()\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('rocROC')\n",
    "        plt.xlabel('AP-1 Monomer')\n",
    "#         plt.ylim(0.0,1)\n",
    "        plt.title('Classifier Performance')\n",
    "        plt.savefig('./figures/figure_04_a.svg')\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Motif Weights (for cjun-fos, or all dimers?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('ticks'):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.distplot(coefficients_zscore_frame_veh['cjun_veh'])\n",
    "    sns.despine()\n",
    "    plt.xlabel('Motif Weight')\n",
    "    plt.ylabel('Frequency (KDE)')\n",
    "plt.savefig('./figures/figure_04_b.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot for similar dimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatterplot of weights\n",
    "factor1 = 'cjun_veh'\n",
    "factor2 = 'jund_veh'\n",
    "delta_threshold = 2.0\n",
    "targets = ['ap-1', 'cebp', 'spi1-c']\n",
    "plt.figure(figsize=(3,3))\n",
    "motifs = coefficients_zscore_frame_veh.index.values\n",
    "with sns.axes_style('ticks',{'axes.edgecolor': 'black',\n",
    "                         }):\n",
    "    x_vals = coefficients_zscore_frame_veh[factor1]\n",
    "    y_vals = coefficients_zscore_frame_veh[factor2]\n",
    "    # calculate colors\n",
    "    plt.scatter(x_vals,\n",
    "                y_vals,\n",
    "                marker = '.', \n",
    "                s=15)\n",
    "    plt.xlabel(factor1.replace('c57bl6_','') + ' Motif Weight')\n",
    "    plt.ylabel(factor2.replace('c57bl6_','') + ' Motif Weight')\n",
    "    sns.despine()\n",
    "    \n",
    "\n",
    "    # calculate labels\n",
    "    for i in range(len(x_vals)):\n",
    "        x = x_vals[i]\n",
    "        y = y_vals[i]\n",
    "        if (abs(x) >= 0.5) or (abs(y) >= 0.5)  or (motifs[i] in targets):\n",
    "            delta = np.max([y_vals[i], x_vals[i]]) - np.min([y_vals[i], x_vals[i]])\n",
    "            if (delta > delta_threshold) or (motifs[i] in targets):\n",
    "                plt.annotate(motifs[i], xy=(x,y) , size=10)\n",
    "                    \n",
    "    # Fix axes\n",
    "    ax = plt.gca()\n",
    "    x0,x1 = ax.get_xlim()\n",
    "    y0,y1 = ax.get_ylim()\n",
    "    ax.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "plt.savefig('./figures/figure_04_c.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot for dissimilar dimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatterplot of weights\n",
    "factor1 = 'fos_veh'\n",
    "factor2 = 'jund_veh'\n",
    "delta_threshold = 3.0\n",
    "targets = ['ap-1', 'cebp', 'spi1-c']\n",
    "plt.figure(figsize=(3,3))\n",
    "motifs = coefficients_zscore_frame_veh.index.values\n",
    "with sns.axes_style('ticks',{'axes.edgecolor': 'black',\n",
    "                         }):\n",
    "    x_vals = coefficients_zscore_frame_veh[factor1]\n",
    "    y_vals = coefficients_zscore_frame_veh[factor2]\n",
    "    # calculate colors\n",
    "    plt.scatter(x_vals,\n",
    "                y_vals,\n",
    "                marker = '.', \n",
    "                s=15)\n",
    "    plt.xlabel(factor1.replace('c57bl6_','') + ' Motif Weight')\n",
    "    plt.ylabel(factor2.replace('c57bl6_','') + ' Motif Weight')\n",
    "    sns.despine()\n",
    "    \n",
    "\n",
    "    # calculate labels\n",
    "    for i in range(len(x_vals)):\n",
    "        x = x_vals[i]\n",
    "        y = y_vals[i]\n",
    "        if abs(x) >= 0.5 or abs(y) >= 0.5:\n",
    "            delta = np.max([y_vals[i], x_vals[i]]) - np.min([y_vals[i], x_vals[i]])\n",
    "            if delta > delta_threshold or motifs[i] in targets:\n",
    "                plt.annotate(motifs[i], xy=(x,y) , size=10)\n",
    "                    \n",
    "    # Fix axes\n",
    "    ax = plt.gca()\n",
    "    x0,x1 = ax.get_xlim()\n",
    "    y0,y1 = ax.get_ylim()\n",
    "    ax.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "plt.savefig('./figures/figure_04_d.svg', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### plot coefficents for vehicle\n",
    "weight_threshold = 1.5\n",
    "\n",
    "cg = sns.clustermap(coefficients_zscore_frame_veh[(coefficients_zscore_frame_veh.max(axis=1) >= weight_threshold) |\n",
    "                                       (coefficients_zscore_frame_veh.min(axis=1) < -1 * weight_threshold)\n",
    "                                      ],\n",
    "                   vmax=-1*weight_threshold,\n",
    "                   vmin= 1* weight_threshold,\n",
    "                   center = 0.0,\n",
    "#                    annot=True,annot_kws={\"size\": 4},\n",
    "                   col_cluster = False,\n",
    "#                    yticklabels=False,\n",
    "                   figsize=(12,12),\n",
    "                   xticklabels=[x.replace('c57bl6_','') for x in coefficients_zscore_frame_veh.columns.values])\n",
    "plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), fontsize=10, rotation=0, );\n",
    "plt.savefig('./figures/figure_04_e.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to gkmSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!if [ ! -d ./gkmsvm_files ]; then mkdir ./gkmsvm_files; fi\n",
    "! rm ./gkmsvm_files/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### read in target sequences as dictionary {peakID: sequence}\n",
    "with open('./peak_sequences/C57BL6J.fa') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "_id_sequence_dict = {}\n",
    "for line in data:\n",
    "    if line[0] == '>':\n",
    "        sequenceName = line.strip()[1:]\n",
    "    else:\n",
    "        _id_sequence_dict[sequenceName] = line.strip().upper()  \n",
    "### read in background sequences\n",
    "with open('./C57BL6J_background.fa') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "for line in data:\n",
    "    if line[0] == '>':\n",
    "        sequenceName = line.strip()[1:]\n",
    "    else:\n",
    "        _id_sequence_dict[sequenceName] = line.strip().upper()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### for all peaks in vehicle using gapped k-mers on background data\n",
    "### write script\n",
    "background_ratio = 5.0\n",
    "numIterations = 5\n",
    "for treatment in ['veh', 'kla']:\n",
    "    script_file = open('gkmsvm_' + treatment + '.sh', 'w')\n",
    "    for monomer in factors:\n",
    "        target_indices = summary_frame[summary_frame[strain + '_' + monomer + '_' + treatment] > 0.0].index.values\n",
    "        background_indices = motif_score_background_frame.index.values\n",
    "        shuffle(background_indices)\n",
    "        background_indices = background_indices[:np.ceil(background_ratio*len(target_indices))]\n",
    "        \n",
    "        target_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(target_indices)]\n",
    "        background_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(background_indices)]\n",
    "        \n",
    "        # merge target and background features together \n",
    "        features = pd.concat([target_affinity_features, background_affinity_features])\n",
    "        labels = pd.Series(data = [True] * len(target_indices) + [False] * len(background_indices),\n",
    "                           index = features.index.values)\n",
    "\n",
    "        if np.sum(labels) > 100:\n",
    "            print(monomer + '_' + treatment)\n",
    "            all_aucs = []\n",
    "            all_precisions = []\n",
    "            for iteration in range(numIterations):  \n",
    "                # split data into training and test sets\n",
    "                training_features, test_features, training_labels, test_labels = get_split(\n",
    "                    features, labels, test_size = test_size)\n",
    "\n",
    "                # create fasta files for positive and negative sequences\n",
    "                training_positive_path = './gkmsvm_files/' + monomer + '_' + treatment+ '_training_positive_' +str(iteration) + '.fa'\n",
    "                training_negative_path = './gkmsvm_files/' + monomer + '_' + treatment+ '_training_negative_' +str(iteration) + '.fa'\n",
    "\n",
    "                training_positive_file = open(training_positive_path,'w' )\n",
    "                training_negative_file = open(training_negative_path,'w' )\n",
    "                test_path = './gkmsvm_files/' + monomer + '_' + treatment+ '_test_' + str(iteration) + '.fa'\n",
    "\n",
    "                test_file = open(test_path,'w')\n",
    "\n",
    "                numPositiveSeqs = np.sum(training_labels)\n",
    "                count=0\n",
    "                for i in range(len(training_labels)):\n",
    "                    index = training_labels.index[i]\n",
    "                    label = training_labels[i]\n",
    "                    seq = _id_sequence_dict[index]\n",
    "\n",
    "                    if label == True:\n",
    "                        training_positive_file.write('>' + index + '\\n')\n",
    "                        training_positive_file.write(seq + '\\n')\n",
    "                    else:\n",
    "                        training_negative_file.write('>' + index + '\\n')\n",
    "                        training_negative_file.write(seq + '\\n')\n",
    "                        count+=1\n",
    "\n",
    "                for i in range(len(test_labels)):\n",
    "                    index = test_labels.index[i]\n",
    "                    label = test_labels[i]\n",
    "                    seq = _id_sequence_dict[index]\n",
    "                    test_file.write('>' + index + '\\n')\n",
    "                    test_file.write(seq + '\\n')\n",
    "\n",
    "                training_positive_file.close()\n",
    "                training_negative_file.close()\n",
    "                test_file.close()\n",
    "\n",
    "                #  Run classifier\n",
    "                model_prefix = './gkmsvm_files/' + monomer + '_' + treatment + '_' +str(iteration)\n",
    "                model_path = model_prefix + '.model.txt'\n",
    "                results_path = model_prefix + '_results.txt'\n",
    "\n",
    "                script_file.write('(gkmtrain '+ training_positive_path + ' ' + training_negative_path + ' ' + model_prefix +\n",
    "                          ' -T 16 -m 64000;')\n",
    "                if iteration == (numIterations - 1):\n",
    "                    script_file.write('gkmpredict '+ test_path + ' ' + model_path + ' ' +  results_path + ' -T 4)\\n')\n",
    "                else:\n",
    "                    script_file.write('gkmpredict '+ test_path + ' ' + model_path + ' ' +  results_path + ' -T 4)&\\n')\n",
    "                \n",
    "\n",
    "    script_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod a+x ./gkmsvm_veh_background.sh \n",
    "./gkmsvm_veh.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod a+x ./gkmsvm_kla_background.sh \n",
    "./gkmsvm_kla.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### for all peaks in vehicle using gapped k-mers on background data\n",
    "### read performance\n",
    "factor_auc_dict_gkmSVM = {}\n",
    "factor_precision_dict_gkmSVM = {}\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in factors:\n",
    "        target_indices = summary_frame[summary_frame[strain + '_' + monomer + '_' + treatment] > 0.0].index.values\n",
    "        background_indices = motif_score_background_frame.index.values\n",
    "\n",
    "        target_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(target_indices)]\n",
    "        background_affinity_features = all_standardized_score_frame[all_standardized_score_frame.index.isin(background_indices)]\n",
    "        \n",
    "        # merge target and background features together \n",
    "        features = pd.concat([target_affinity_features, background_affinity_features])\n",
    "        labels = pd.Series(data = [True] * len(target_indices) + [False] * len(background_indices),\n",
    "                           index = features.index.values)\n",
    "\n",
    "        if np.sum(labels) > 100:\n",
    "            print(monomer + '_' + treatment)\n",
    "            all_aucs = []\n",
    "            all_precisions = []\n",
    "            for iteration in range(numIterations):  \n",
    "                model_prefix = './gkmsvm_files/' + monomer  + '_' + treatment+ '_' +str(iteration)\n",
    "                results_path = model_prefix + '_results.txt'\n",
    "\n",
    "\n",
    "                index_score_dict = {} #{peakID: gkmSVM score}\n",
    "                with open(results_path) as f:\n",
    "                    data = f.readlines()\n",
    "                for line in data:\n",
    "                    tokens=line.strip().split()\n",
    "                    score = float(tokens[1])\n",
    "                    index = tokens[0]\n",
    "                    index_score_dict[index] = score\n",
    "                # define true labels\n",
    "                index_label_dict = dict(zip(labels.index.values, labels.values))\n",
    "\n",
    "                sorted_indices = sorted(index_score_dict.keys())\n",
    "\n",
    "                sorted_scores = np.array([index_score_dict[x] for x in sorted_indices])\n",
    "                test_labels = np.array([index_label_dict[x] for x in sorted_indices])\n",
    "\n",
    "                min_score = np.min(sorted_scores)\n",
    "                if min_score < 0:\n",
    "                    normalized_scores = sorted_scores + abs(min_score)\n",
    "                normalized_scores = normalized_scores/np.max(normalized_scores)\n",
    "\n",
    "                # score predictions          \n",
    "                current_roc_auc = sklearn.metrics.roc_auc_score(test_labels, normalized_scores, average = None)\n",
    "                current_precision = sklearn.metrics.average_precision_score(test_labels, normalized_scores, average = None)\n",
    "                all_precisions.append(current_precision)\n",
    "                all_aucs.append(current_roc_auc)\n",
    "\n",
    "            # average scoring metrics \n",
    "\n",
    "            mean_roc_auc = np.mean(all_aucs) \n",
    "            mean_precision = np.mean(all_precisions)\n",
    "\n",
    "            factor_auc_dict_gkmSVM[monomer + '_' + treatment]= all_aucs\n",
    "            factor_precision_dict_gkmSVM[monomer + '_' + treatment]= all_precisions\n",
    "\n",
    "            print(monomer + '_' + treatment,\n",
    "                  'roc:', mean_roc_auc, \n",
    "                  'precision:', mean_precision,\n",
    "                  'numTestPositives:', np.sum(test_labels)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5 - Context Change after KLA treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numIterations = 5\n",
    "test_size = 0.5\n",
    "background_ratio = 1.0\n",
    "ap1_members = ['atf3','cjun', 'fos', 'junb','jund']    \n",
    "factors = ['atf3','cjun', 'fos', 'junb','jund', 'atac', 'cebpa', 'pu1', 'p65']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients_zscore_kla_frame = coefficients_zscore_frame[['atf3_kla', 'cjun_kla', 'fos_kla', 'junb_kla', 'jund_kla']]\n",
    "# coefficients_zscore_kla_frame['variance'] = coefficients_zscore_kla_frame.var(axis=1)\n",
    "# coefficients_zscore_kla_frame['maxDist'] = coefficients_zscore_kla_frame.max(axis=1) - coefficients_zscore_kla_frame.min(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monomers = []\n",
    "aucs = []\n",
    "feature_set = []\n",
    "for factor in sorted(factor_auc_dict_kla.keys()):\n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    aucs = aucs + factor_auc_dict_kla_ap1[factor]\n",
    "    feature_set = feature_set + numIterations * ['Known Motif']\n",
    "    \n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    aucs = aucs + factor_auc_dict_kla[factor]\n",
    "    feature_set = feature_set + numIterations * ['All Motifs']\n",
    "    \n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    aucs = aucs + factor_auc_dict_kla_top[factor]\n",
    "    feature_set = feature_set + numIterations * ['Top Motifs']\n",
    "    \n",
    "data = pd.DataFrame({'Factor':monomers,\n",
    "                     'AUC':aucs,\n",
    "                     'Feature Set': feature_set\n",
    "                     })\n",
    "\n",
    "for treatment in ['kla']:\n",
    "    factor_auc_tuples = [(x, np.mean(factor_auc_dict_kla[x])) for x in factor_auc_dict_kla if treatment in x]\n",
    "    sorted_monomers = [y[0] for y in sorted(factor_auc_tuples, key=lambda x:x[1])]\n",
    "    with sns.axes_style('ticks'):\n",
    "        plottingFrame = sns.factorplot(data = data[data['Factor'].str.contains(treatment)],\n",
    "                                    x='Factor',\n",
    "                                    y='AUC',\n",
    "                                    order = sorted_monomers,\n",
    "                                    palette='Set1',\n",
    "                                    size=6,\n",
    "                                    hue='Feature Set',\n",
    "                                    kind = 'point')\n",
    "                                    #markers = '.', s='0.01')\n",
    "        sns.despine()\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('aucROC')\n",
    "        plt.xlabel('AP-1 Monomer')\n",
    "        plt.ylim(0.0,1)\n",
    "        plt.title('Classifier Performance')\n",
    "        plt.savefig('./figures/figure_05_a.svg')\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot for all cjun-jund motif weights before and after Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatterplot of weights\n",
    "factor1 = 'cjun_veh'\n",
    "factor2 = 'cjun_kla'\n",
    "delta_threshold = 1.0\n",
    "targets = ['ap-1', 'cebp', 'rel']\n",
    "# targets = []\n",
    "plt.figure(figsize=(3,3))\n",
    "motifs = coefficients_zscore_veh_frame.index.values\n",
    "with sns.axes_style('ticks',{'axes.edgecolor': 'black',\n",
    "                         }):\n",
    "    x_vals = coefficients_zscore_veh_frame[factor1]\n",
    "    y_vals = coefficients_zscore_kla_frame[factor2]\n",
    "    # calculate colors\n",
    "    plt.scatter(x_vals,\n",
    "                y_vals,\n",
    "                marker = '.', \n",
    "                s=15)\n",
    "    plt.xlabel(factor1.replace('c57bl6_','') + ' Vehicle Motif Weight')\n",
    "    plt.ylabel(factor2.replace('c57bl6_','') + ' KLA Motif Weight')\n",
    "    sns.despine()\n",
    "    \n",
    "\n",
    "    # calculate labels\n",
    "    for i in range(len(x_vals)):\n",
    "        x = x_vals[i]\n",
    "        y = y_vals[i]\n",
    "        if abs(x) >= 0.5 or abs(y) >= 0.5:\n",
    "            delta = np.max([y_vals[i], x_vals[i]]) - np.min([y_vals[i], x_vals[i]])\n",
    "            if delta > delta_threshold or motifs[i] in targets:\n",
    "                plt.annotate(motifs[i], xy=(x,y) , size=10)\n",
    "                    \n",
    "    # Fix axes\n",
    "    ax = plt.gca()\n",
    "    x0,x1 = ax.get_xlim()\n",
    "    y0,y1 = ax.get_ylim()\n",
    "    ax.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "plt.savefig('./figures/figure_05_b.svg', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap for all KLA dimer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### plot coefficents for kla\n",
    "weight_threshold = 1.0\n",
    "\n",
    "cg = sns.clustermap(coefficients_zscore_kla_frame[(coefficients_zscore_kla_frame.max(axis=1) >= weight_threshold) |\n",
    "                                       (coefficients_zscore_kla_frame.min(axis=1) < -1 * weight_threshold)\n",
    "                                      ],\n",
    "#                    vmax= -1 * weight_threshold,\n",
    "#                    vmin= 1 * weight_threshold,\n",
    "                    col_cluster=False,\n",
    "                   center = 0.0,\n",
    "#                    annot=True,annot_kws={\"size\": 4},\n",
    "                   figsize=(12,12),\n",
    "                   xticklabels=[x.replace('c57bl6_','') for x in coefficients_zscore_kla_frame.columns.values])\n",
    "plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), fontsize=10, rotation=0);\n",
    "# plt.savefig('./figures/figure_05_c.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barplots showing inducible RNA-seq expression for significant motifs that are different between vehicle and KLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in rpkm values\n",
    "rpkm_frame = pd.read_csv('./rpkm_untreated.tsv', sep='\\t')\n",
    "\n",
    "rpkm_frame.index = [x.split('|')[0].upper() for x in rpkm_frame['Annotation/Divergence']]\n",
    "rpkm_frame = rpkm_frame.ix[:,8:]\n",
    "rpkm_frame.columns = [x.split('/')[-2].split('_')[3] for x in rpkm_frame.columns.values]\n",
    "\n",
    "# rotate frame for plotting\n",
    "rpkm_plotting_frame = pd.DataFrame(rpkm_frame.stack(), \n",
    "                                   columns=['RPKM'])\n",
    "rpkm_plotting_frame['Gene'] = [x[0] for x in rpkm_plotting_frame.index.values]\n",
    "rpkm_plotting_frame['Treatment'] = [x[1] for x in rpkm_plotting_frame.index.values]\n",
    "rpkm_plotting_frame['Log2 RPKM'] = np.log2(rpkm_plotting_frame['RPKM'].values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_threshold = 2.0\n",
    "motifs = coefficients_zscore_frame_veh.index.values\n",
    "for fp in coefficients_zscore_frame_veh.columns.values:\n",
    "    differences = coefficients_zscore_frame_kla[fp.replace('veh','kla')] - coefficients_zscore_frame_veh[fp]\n",
    "    signs = coefficients_zscore_frame_kla[fp.replace('veh','kla')] * coefficients_zscore_frame_veh[fp]\n",
    "    print('***', fp.replace('c57bl6_',''))\n",
    "    for i in range(len(differences)):\n",
    "        if abs(differences[i]) > difference_threshold:\n",
    "            print('   ',motifs[i], differences[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_list = ['REL', 'EGR1', 'ESR1', 'ESR2', 'RXRA', 'RXRB', 'IRF1', 'IRF7', 'IRF8', 'IRF9']\n",
    "gene_list = ['IRF1', 'EGR1', 'REL']#, 'RXRA', 'RXRB','PPARG','NR1H2']\n",
    "\n",
    "\n",
    "plottingFrame = rpkm_plotting_frame[rpkm_plotting_frame['Gene'].isin(gene_list)]\n",
    "\n",
    "with sns.axes_style('ticks'):\n",
    "    sns.factorplot(data = plottingFrame, x='Gene', y='Log2 RPKM', hue='Treatment', kind='bar', \n",
    "                   order = gene_list,\n",
    "                   hue_order=['Veh','KLA-1h'], \n",
    "                   ci=100,\n",
    "                  size=4)\n",
    "\n",
    "plt.xticks(rotation=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6 - Strains Based Confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run Verena's scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! if [ ! -d ./marge_files ]; then mkdir ./marge_files; fi\n",
    "! if [ ! -d ./marge_output ]; then mkdir ./marge_output; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in best samples for use with annotation\n",
    "# for c57bl6 samples\n",
    "with open ('/home/jtao/analysis/ap1_analysis/best_samples.tsv') as f:\n",
    "    data = f.readlines()\n",
    "condition_samples_dict = {}\n",
    "for line in data:\n",
    "    tokens = line.strip().split('\\t')\n",
    "    condition = '_'.join(tokens[:3])\n",
    "    samples = tokens[3:-1]\n",
    "    condition_samples_dict[condition] = samples\n",
    "    \n",
    "# for nod and balbc\n",
    "with open ('/home/jtao/analysis/ap1_analysis/best_samples_strains.tsv') as f:\n",
    "    data = f.readlines()\n",
    "for line in data:\n",
    "    tokens = line.strip().split('\\t')\n",
    "    condition = '_'.join(tokens[:3])\n",
    "    samples = tokens[3:-1]\n",
    "    condition_samples_dict[condition] = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strain_fullStrain_dict ={'balbc':'BALBCJ','c57bl6':'C57BL6J', 'nod':'NODSHILTJ'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairs of Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c57bl6_path = '/gpfs/data01/glasslab/home/jtao/analysis/ap1_analysis/tag_directories/'\n",
    "strains_path = '/gpfs/data01/glasslab/home/jtao/analysis/ap1_analysis/tag_directories_strains/'\n",
    "# create peak files for each dimer\n",
    "### create peak files for denovo motif\n",
    "peak_threshold = 50 # minimum number of peaks required for running motif analysis\n",
    "factors = ['atf3', 'cjun', 'fos','junb', 'jund']\n",
    "strains = ['balbc','c57bl6']\n",
    "for strain in strains:\n",
    "    for treatment in ['veh', 'kla']:\n",
    "        for i in range(len(factors) - 1):\n",
    "            factor1 = strain + '_'+factors[i] + '_' + treatment\n",
    "            for j in range(i + 1, len(factors)):\n",
    "                factor2 = strain + '_'+ factors[j] + '_' + treatment\n",
    "                if factor1 in summary_frame.columns and factor2 in summary_frame.columns:\n",
    "                    outputPath = './marge_files/' + strain + '_' + factors[i] + '_' + factors[j] +'_' +treatment+ '_peaks.tsv'\n",
    "\n",
    "                    current_frame = summary_frame[(summary_frame[factor1]> 0) &\n",
    "                                                     (summary_frame[factor2] > 0)]\n",
    "\n",
    "                    current_peak_frame = current_frame[['ID', 'chr', 'start', 'end']]\n",
    "                    current_peak_frame['strand'] = '+'\n",
    "                    columns = current_peak_frame.columns.values\n",
    "                    columns[0]='#PeakID'\n",
    "                    current_peak_frame.columns = columns\n",
    "                    if not os.path.isfile(outputPath):\n",
    "                        if current_peak_frame.shape[0]  > peak_threshold:\n",
    "                            current_peak_frame.to_csv(outputPath,\n",
    "                                                     index=False,\n",
    "                                                     sep='\\t')\n",
    "# create merged peak files for each pair of strains\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for i in range(len(factors) - 1):\n",
    "        factor1 = factors[i]\n",
    "        for j in range(i + 1, len(factors)):\n",
    "            factor2 = factors[j]\n",
    "            for k in range(len(strains)-1):\n",
    "                strain1 = strains[k]\n",
    "                for l in range(k+1, len(strains)):\n",
    "                    strain2 = strains[l]\n",
    "                    strain1_path = './marge_files/' + '_'.join([strain1, factor1, factor2, treatment, 'peaks.tsv'])\n",
    "                    strain2_path = './marge_files/' + '_'.join([strain2, factor1, factor2, treatment, 'peaks.tsv'])\n",
    "\n",
    "                    if os.path.isfile(strain1_path) and os.path.isfile(strain2_path):\n",
    "                        merged_file_path = './marge_files/' + '_'.join([strain1, strain2, factor1, factor2, treatment, 'mergedPeaks.tsv'])\n",
    "                        if not os.path.isfile(merged_file_path):\n",
    "                            print('mergePeaks -d given ' + strain1_path + ' ' + strain2_path + '>' + merged_file_path)\n",
    "                            os.system('mergePeaks -d given ' + strain1_path + ' ' + strain2_path + '>' + merged_file_path)\n",
    "\n",
    "                        # annotate merged peak files with best tag directories\n",
    "                        strain1_samples = condition_samples_dict[strain1 + '_' + factor1 + '_'+treatment] + \\\n",
    "                                          condition_samples_dict[strain1 + '_' + factor2 + '_'+treatment]\n",
    "                        strain2_samples = condition_samples_dict[strain2 + '_' + factor1 + '_'+treatment] + \\\n",
    "                                          condition_samples_dict[strain2 + '_' + factor2 + '_'+treatment]\n",
    "\n",
    "                        strain1_samples = [c57bl6_path + x if 'C57' in x else strains_path + x for x in strain1_samples]\n",
    "                        strain2_samples = [c57bl6_path + x if 'C57' in x else strains_path + x for x in strain2_samples]\n",
    "                        annotated_file_path = merged_file_path.replace('merged','annotated')\n",
    "                        if not os.path.isfile(annotated_file_path):\n",
    "                            print('annotatePeaks.pl '+ merged_file_path + ' mm10 -noann -nogene -d ' + \n",
    "                                  ' '.join(strain1_samples + strain2_samples) + '>' + annotated_file_path)\n",
    "                            os.system('annotatePeaks.pl '+ merged_file_path + ' mm10 -noann -nogene -d ' + \n",
    "                                  ' '.join(strain1_samples + strain2_samples) + '>' + annotated_file_path)\n",
    "                        strain1_conditions = [strain1 + '_' + x.split('/')[-1].split('_')[3] for x in strain1_samples]\n",
    "                        strain2_conditions = [strain2 + '_' + x.split('/')[-1].split('_')[3] for x in strain2_samples]\n",
    "\n",
    "                        \n",
    "                        # average tag counts from tag directories\n",
    "                        averaged_file_path = annotated_file_path.replace(strain1, 'avg_'+strain1)\n",
    "                        if not os.path.isfile(averaged_file_path):\n",
    "                            print('/gpfs/data01/glasslab/home/vlink/code/average_tag_counts.pl ' +\n",
    "                                     annotated_file_path + ' ' + ' '.join(strain1_conditions + strain2_conditions))\n",
    "                            os.system('/gpfs/data01/glasslab/home/vlink/code/average_tag_counts.pl ' +\n",
    "                                     annotated_file_path + ' ' + ' '.join(strain1_conditions + strain2_conditions))\n",
    "                            \n",
    "                        # sum up tag counts from both monomers\n",
    "                        summed_file_path = annotated_file_path.replace('annotated','summed')\n",
    "                        if not os.path.isfile(summed_file_path):\n",
    "                            averaged_frame = pd.read_csv(averaged_file_path,sep='\\t')\n",
    "                            summed_frame = averaged_frame.ix[:,:7]\n",
    "                            summed_frame[strain1] = np.sum(averaged_frame[[x for x in averaged_frame.columns if strain1 in x and 'avg'in x]], axis=1)\n",
    "                            summed_frame[strain2] = np.sum(averaged_frame[[x for x in averaged_frame.columns if strain2 in x and 'avg'in x]], axis=1)\n",
    "                            summed_frame.to_csv(summed_file_path, sep='\\t', index=False)\n",
    "#                         # call mutation analysis script\n",
    "                        print('/home/vlink/mouse_strains/marge/analysis/analyze_ChIP_mutations_tree.pl '+\n",
    "                              '-genome mm10 -strains ' + strain_fullStrain_dict[strain1] + ', ' + strain_fullStrain_dict[strain2] +\n",
    "                              ' -file ' + summed_file_path + ' -AB ap-1 -output ' + '_'.join([strain1, strain2, factor1, factor2, treatment]) +\n",
    "                              ' -plots plot_' + '_'.join([strain1, strain2, factor1, factor2, treatment]))\n",
    "                              \n",
    "                        os.system('/home/vlink/mouse_strains/marge/analysis/analyze_ChIP_mutations_tree.pl '+\n",
    "                              '-genome mm10 -strains ' + strain_fullStrain_dict[strain1] + ', ' + strain_fullStrain_dict[strain2] +\n",
    "                              ' -file ' + summed_file_path + ' -AB ap-1 -output ./marge_output/' + '_'.join([strain1, strain2, factor1, factor2, treatment]) +\n",
    "                              ' -plots ./marge_output/plot_' + '_'.join([strain1, strain2, factor1, factor2, treatment]))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### individual factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c57bl6_path = '/gpfs/data01/glasslab/home/jtao/analysis/ap1_analysis/tag_directories/'\n",
    "strains_path = '/gpfs/data01/glasslab/home/jtao/analysis/ap1_analysis/tag_directories_strains/'\n",
    "# create peak files for each dimer\n",
    "### create peak files for denovo motif\n",
    "peak_threshold = 50 # minimum number of peaks required for running motif analysis\n",
    "factors = ['atf3', 'cjun', 'fos','junb', 'jund']\n",
    "strains = ['balbc','c57bl6']\n",
    "for strain in strains:\n",
    "    for treatment in ['veh', 'kla']:\n",
    "        for i in range(len(factors) - 1):\n",
    "            factor1 = strain + '_'+factors[i] + '_' + treatment\n",
    "\n",
    "            if factor1 in summary_frame.columns:\n",
    "                outputPath = './marge_files/' + strain + '_' + factors[i] +'_' +treatment+ '_peaks.tsv'\n",
    "\n",
    "                current_frame = summary_frame[(summary_frame[factor1]> 0)]\n",
    "\n",
    "                current_peak_frame = current_frame[['ID', 'chr', 'start', 'end']]\n",
    "                current_peak_frame['strand'] = '+'\n",
    "                columns = current_peak_frame.columns.values\n",
    "                columns[0]='#PeakID'\n",
    "                current_peak_frame.columns = columns\n",
    "                if not os.path.isfile(outputPath):\n",
    "                    if current_peak_frame.shape[0]  > peak_threshold:\n",
    "                        current_peak_frame.to_csv(outputPath,\n",
    "                                                 index=False,\n",
    "                                                 sep='\\t')\n",
    "# create merged peak files for each pair of strains\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for i in range(len(factors) - 1):\n",
    "        factor1 = factors[i]\n",
    "\n",
    "        for k in range(len(strains)-1):\n",
    "            strain1 = strains[k]\n",
    "            for l in range(k+1, len(strains)):\n",
    "                strain2 = strains[l]\n",
    "                strain1_path = './marge_files/' + '_'.join([strain1, factor1, treatment, 'peaks.tsv'])\n",
    "                strain2_path = './marge_files/' + '_'.join([strain2, factor1, treatment, 'peaks.tsv'])\n",
    "\n",
    "                if os.path.isfile(strain1_path) and os.path.isfile(strain2_path):\n",
    "                    merged_file_path = './marge_files/' + '_'.join([strain1, strain2, factor1, treatment, 'mergedPeaks.tsv'])\n",
    "                    if not os.path.isfile(merged_file_path):\n",
    "                        print('mergePeaks -d given ' + strain1_path + ' ' + strain2_path + '>' + merged_file_path)\n",
    "                        os.system('mergePeaks -d given ' + strain1_path + ' ' + strain2_path + '>' + merged_file_path)\n",
    "\n",
    "                    # annotate merged peak files with best tag directories\n",
    "                    strain1_samples = condition_samples_dict[strain1 + '_' + factor1 + '_'+treatment]\n",
    "                    strain2_samples = condition_samples_dict[strain2 + '_' + factor1 + '_'+treatment]\n",
    "\n",
    "                    strain1_samples = [c57bl6_path + x if 'C57' in x else strains_path + x for x in strain1_samples]\n",
    "                    strain2_samples = [c57bl6_path + x if 'C57' in x else strains_path + x for x in strain2_samples]\n",
    "                    annotated_file_path = merged_file_path.replace('merged','annotated')\n",
    "                    if not os.path.isfile(annotated_file_path):\n",
    "                        print('annotatePeaks.pl '+ merged_file_path + ' mm10 -noann -nogene -d ' + \n",
    "                              ' '.join(strain1_samples + strain2_samples) + '>' + annotated_file_path)\n",
    "                        os.system('annotatePeaks.pl '+ merged_file_path + ' mm10 -noann -nogene -d ' + \n",
    "                              ' '.join(strain1_samples + strain2_samples) + '>' + annotated_file_path)\n",
    "                    strain1_conditions = [strain1 + '_' + x.split('/')[-1].split('_')[3] for x in strain1_samples]\n",
    "                    strain2_conditions = [strain2 + '_' + x.split('/')[-1].split('_')[3] for x in strain2_samples]\n",
    "\n",
    "\n",
    "                    # average tag counts from tag directories\n",
    "                    averaged_file_path = annotated_file_path.replace(strain1, 'avg_'+strain1)\n",
    "                    if not os.path.isfile(averaged_file_path):\n",
    "                        print('/gpfs/data01/glasslab/home/vlink/code/average_tag_counts.pl ' +\n",
    "                                 annotated_file_path + ' ' + ' '.join(strain1_conditions + strain2_conditions))\n",
    "                        os.system('/gpfs/data01/glasslab/home/vlink/code/average_tag_counts.pl ' +\n",
    "                                 annotated_file_path + ' ' + ' '.join(strain1_conditions + strain2_conditions))\n",
    "\n",
    "                    # sum up tag counts from both monomers\n",
    "                    summed_file_path = annotated_file_path.replace('annotated','summed')\n",
    "                    if not os.path.isfile(summed_file_path):\n",
    "                        averaged_frame = pd.read_csv(averaged_file_path,sep='\\t')\n",
    "                        summed_frame = averaged_frame.ix[:,:7]\n",
    "                        summed_frame[strain1] = np.sum(averaged_frame[[x for x in averaged_frame.columns if strain1 in x and 'avg'in x]], axis=1)\n",
    "                        summed_frame[strain2] = np.sum(averaged_frame[[x for x in averaged_frame.columns if strain2 in x and 'avg'in x]], axis=1)\n",
    "                        summed_frame.to_csv(summed_file_path, sep='\\t', index=False)\n",
    "#                         # call mutation analysis script\n",
    "                    print('/home/vlink/mouse_strains/marge/analysis/analyze_ChIP_mutations_tree.pl '+\n",
    "                          '-genome mm10 -strains ' + strain_fullStrain_dict[strain1] + ', ' + strain_fullStrain_dict[strain2] +\n",
    "                          ' -file ' + summed_file_path + ' -AB ap-1 -output ' + '_'.join([strain1, strain2, factor1, treatment]) +\n",
    "                          ' -plots plot_' + '_'.join([strain1, strain2, factor1,  treatment]))\n",
    "\n",
    "                    os.system('/home/vlink/mouse_strains/marge/analysis/analyze_ChIP_mutations_tree.pl '+\n",
    "                          '-genome mm10 -strains ' + strain_fullStrain_dict[strain1] + ', ' + strain_fullStrain_dict[strain2] +\n",
    "                          ' -file ' + summed_file_path + ' -AB ap-1 -output ./marge_output/' + '_'.join([strain1, strain2, factor1, treatment]) +\n",
    "                          ' -plots ./marge_output/plot_' + '_'.join([strain1, strain2, factor1,  treatment]))\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 7 - Validation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 8 - RNA-seq and GRO-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot for jun knockdown (wt-veh vs siJun-veh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot for jun knockdown (wt-KLA vs siJun-KLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot comparing two knockdowns (siATF3 vs siJun veh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO analysis for knockdowns as a heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRO-seq fold change plot for AP-1 dimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap1_members = ['atf3','cjun', 'fos', 'junb','jund']    \n",
    "factorPairs = []\n",
    "# ap1_members = ['atf3','cjun', 'fos', 'fra1','fra2', 'jdp2', 'junb','jund']    \n",
    "ap1_members = ['atf3','cjun', 'fos', 'junb','jund']    \n",
    "\n",
    "\n",
    "for i in range(len(ap1_members)-1):\n",
    "    for j in range(i+1, len(ap1_members)):\n",
    "        factorPairs.append(('c57bl6_'+ap1_members[i],'c57bl6_'+ ap1_members[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get peak IDS for peaks\n",
    "\n",
    "reads = []\n",
    "factors = []\n",
    "treatments = []\n",
    "fold_changes = []\n",
    "for treatment in ['Veh','KLA', 'Both']:\n",
    "    for fp in factorPairs:\n",
    "        factor_auc_dict = {}\n",
    "        factor1 = fp[0] + '_' + treatment.lower()\n",
    "        factor2 = fp[1] + '_' + treatment.lower()\n",
    "        \n",
    "        if treatment == 'Veh':\n",
    "            indices1 = set(intergenic_summary_frame[(intergenic_summary_frame[factor1] > 0) &\n",
    "                                                   (intergenic_summary_frame[factor1.replace('veh','kla')] == 0)].index.values)\n",
    "            indices2 = set(intergenic_summary_frame[(intergenic_summary_frame[factor2] > 0) &\n",
    "                                                   (intergenic_summary_frame[factor2.replace('veh','kla')] == 0)].index.values)\n",
    "        elif treatment == 'KLA':\n",
    "            indices1 = set(intergenic_summary_frame[(intergenic_summary_frame[factor1] > 0) &\n",
    "                                                   (intergenic_summary_frame[factor1.replace('kla','veh')] == 0)].index.values)\n",
    "            indices2 = set(intergenic_summary_frame[(intergenic_summary_frame[factor2] > 0) &\n",
    "                                                   (intergenic_summary_frame[factor2.replace('kla','veh')] == 0)].index.values)\n",
    "\n",
    "\n",
    "        else:\n",
    "            indices1 = set(intergenic_summary_frame[(intergenic_summary_frame[factor1.replace('both','veh')] > 0) &\n",
    "                                                   (intergenic_summary_frame[factor1.replace('both','kla')] > 0)].index.values)\n",
    "            indices2 = set(intergenic_summary_frame[(intergenic_summary_frame[factor2.replace('both','veh')] > 0) &\n",
    "                                                   (intergenic_summary_frame[factor2.replace('both','kla')] > 0)].index.values)\n",
    "\n",
    "            \n",
    "        indices = indices1.intersection(indices2)\n",
    "        if not treatment == 'Both':\n",
    "            gro_reads = intergenic_annotation_frame[intergenic_annotation_frame.index.isin(indices)]\\\n",
    "                [['Gro_'+ treatment +' +', 'Gro_'+treatment+ ' -']].sum(axis=1)\n",
    "        else:\n",
    "            gro_reads = intergenic_annotation_frame[intergenic_annotation_frame.index.isin(indices)]\\\n",
    "                [['Gro_Veh +', 'Gro_Veh -', 'Gro_KLA +', 'Gro_KLA -']].sum(axis=1)\n",
    "        veh_reads = intergenic_annotation_frame[intergenic_annotation_frame.index.isin(indices)]\\\n",
    "            [['Gro_Veh +', 'Gro_Veh -']].sum(axis=1)\n",
    "        kla_reads = intergenic_annotation_frame[intergenic_annotation_frame.index.isin(indices)]\\\n",
    "            [['Gro_KLA +', 'Gro_KLA -']].sum(axis=1)\n",
    "        \n",
    "        factors = factors + [' '.join(fp).replace('c57bl6_','')] * len(gro_reads)\n",
    "        treatments = treatments + [treatment] * len(gro_reads)\n",
    "        reads = reads + list(gro_reads)\n",
    "        fold_changes = fold_changes + list((kla_reads + 0.1)/(veh_reads + 0.1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # get peak IDS for peaks\n",
    "\n",
    "# reads = []\n",
    "# factors = []\n",
    "# treatments = []\n",
    "# fold_changes = []\n",
    "# for treatment in ['Veh','KLA', 'Both']:\n",
    "#     for monomer in ap1_members:       \n",
    "#         if treatment == 'Veh':\n",
    "#             indices = set(intergenic_summary_frame[(intergenic_summary_frame['c57bl6_' + monomer + '_veh'] > 0) &\n",
    "#                                                    (intergenic_summary_frame['c57bl6_' + monomer + '_kla'] == 0)].index.values)\n",
    "#         elif treatment == 'KLA':\n",
    "#             indices = set(intergenic_summary_frame[(intergenic_summary_frame['c57bl6_' + monomer + '_kla'] > 0) &\n",
    "#                                                    (intergenic_summary_frame['c57bl6_' + monomer + '_veh'] == 0)].index.values)\n",
    "\n",
    "#         else:\n",
    "#             indices = set(intergenic_summary_frame[(intergenic_summary_frame['c57bl6_' + monomer + '_veh'] > 0) &\n",
    "#                                                    (intergenic_summary_frame['c57bl6_' + monomer + '_kla'] > 0)].index.values)\n",
    "#         if not treatment == 'Both':\n",
    "#             gro_reads = intergenic_annotation_frame[intergenic_annotation_frame.index.isin(indices)]\\\n",
    "#                 [['Gro_'+ treatment +' +', 'Gro_'+treatment+ ' -']].sum(axis=1)\n",
    "#         else:\n",
    "#             gro_reads = intergenic_annotation_frame[intergenic_annotation_frame.index.isin(indices)]\\\n",
    "#                 [['Gro_Veh +', 'Gro_Veh -', 'Gro_KLA +', 'Gro_KLA -']].sum(axis=1)\n",
    "#         veh_reads = intergenic_annotation_frame[intergenic_annotation_frame.index.isin(indices)]\\\n",
    "#             [['Gro_Veh +', 'Gro_Veh -']].sum(axis=1)\n",
    "#         kla_reads = intergenic_annotation_frame[intergenic_annotation_frame.index.isin(indices)]\\\n",
    "#             [['Gro_KLA +', 'Gro_KLA -']].sum(axis=1)\n",
    "        \n",
    "#         factors = factors + [monomer] * len(gro_reads)\n",
    "#         treatments = treatments + [treatment] * len(gro_reads)\n",
    "#         reads = reads + list(gro_reads)\n",
    "#         fold_changes = fold_changes + list((kla_reads + 0.01)/(veh_reads + 0.01))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gro_frame = pd.DataFrame({'Dimer':factors,\n",
    "                          'Treatment':treatments,\n",
    "                          'GRO-seq Tags':reads,\n",
    "                          'Log2 GRO-seq Tags': np.log2(np.array(reads)+1),\n",
    "                          'Fold Change':fold_changes,\n",
    "                          'Log2 Fold Change': np.log2(np.array(fold_changes))\n",
    "                          })\n",
    "\n",
    "gro_frame['Treatment'] = ['Lost After Treatment' if x == 'Veh' else 'Unchanged' if x=='Both' else 'Gained After Treatment' for x in gro_frame['Treatment'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('ticks'):\n",
    "    sns.factorplot( data = gro_frame,\n",
    "                x='Dimer',\n",
    "                y= 'Log2 Fold Change',\n",
    "                hue='Treatment',\n",
    "                size=4,\n",
    "                ci=100)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig('./figures/figure_08_e.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO analysis for nearest gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 9 - Graphical abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplemental Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier performance on different test fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De novo motifs for all dimers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif compression stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
