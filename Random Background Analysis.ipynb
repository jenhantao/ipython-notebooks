{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Background Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "### header ###\n",
    "__author__ = \"Jenhan Tao\"\n",
    "__license__ = \"BSD\"\n",
    "__email__ = \"jenhantao@gmail.com\"\n",
    "\n",
    "### imports ###\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib\n",
    "import itertools\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "import matplotlib_venn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from random import shuffle\n",
    "\n",
    "### notebook specific configuration ###\n",
    "%matplotlib inline\n",
    "matplotlib.pylab.rcParams['savefig.dpi'] = 200\n",
    "sys.setrecursionlimit(5000)\n",
    "os.chdir('/gpfs/data01/glasslab/home/jtao/analysis/random_background_analysis/')\n",
    "sns.set_context('notebook')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into GC content matched training and test data\n",
    "def get_GC_matched_split(features, labels, test_size, tolerance = 0.01):\n",
    "    '''\n",
    "    feature: 2D array (samples x features)\n",
    "    labels: 1D boolean array (samples x)\n",
    "    test_size: fraction of data to test on\n",
    "    tolerance: max difference in GC content between True and False labelled samples\n",
    "    '''\n",
    "    global _id_sequence_dict\n",
    "    \n",
    "    ### match GC content of samples labelled True with those labelled False by thowing out False samples\n",
    "    # retrieve sequences using index of labels\n",
    "    index_label_tuples = tuple(zip(labels.index.values, labels.values))\n",
    "    \n",
    "    true_sequences = [_id_sequence_dict[x[0]] for x in index_label_tuples if x[1]]\n",
    "    true_ids = [x[0] for x in index_label_tuples if x[1]]\n",
    "    \n",
    "    false_sequences = [_id_sequence_dict[x[0]] for x in index_label_tuples if not x[1]]\n",
    "    false_ids = [x[0] for x in index_label_tuples if not x[1]]\n",
    "    \n",
    "    # calculate GC content of True samples\n",
    "    true_gc_count = 0\n",
    "    true_length = 0\n",
    "    for s in true_sequences:\n",
    "        true_gc_count += s.count('G')\n",
    "        true_gc_count += s.count('C')\n",
    "        true_length += len(s)\n",
    "    true_gc_content = true_gc_count/(true_length+0.0000001)\n",
    "    \n",
    "    # calcuate GC content of False samples\n",
    "    false_gc_count = 0\n",
    "    false_length = 0\n",
    "    for s in false_sequences:\n",
    "        false_gc_count += s.count('G')\n",
    "        false_gc_count += s.count('C')\n",
    "        false_length += len(s)\n",
    "    false_gc_content = false_gc_count/(false_length+0.0000001)\n",
    "    \n",
    "    while abs(true_gc_content - false_gc_content) > tolerance:\n",
    "        # remove false GC sequences until GC content matches tolerance\n",
    "        selected_seq = False\n",
    "        \n",
    "        while not selected_seq:\n",
    "            rand_index = np.random.randint(len(false_sequences))\n",
    "            current_seq = false_sequences[rand_index]\n",
    "            current_gc_count = current_seq.count('G')+ current_seq.count('C')\n",
    "            current_length = len(current_seq)\n",
    "            current_gc = current_gc_count/current_length\n",
    "            if true_gc_content > false_gc_content:\n",
    "                # remove sequences that would increase overall GC content of False sequences\n",
    "                if current_gc < false_gc_content:\n",
    "                    selected_seq = True\n",
    "            else:\n",
    "                # remove sequences that would decrease overall GC content of False sequences\n",
    "                if current_gc > false_gc_content:\n",
    "                    selected_seq = True\n",
    "        false_gc_count -= current_gc_count\n",
    "        false_length -= current_length\n",
    "        false_gc_content = false_gc_count/false_length\n",
    "        \n",
    "        false_sequences.pop(rand_index)\n",
    "        false_ids.pop(rand_index)\n",
    "    \n",
    "    filtered_ids = true_ids + false_ids\n",
    "    filtered_features = features[features.index.isin(filtered_ids)]\n",
    "    filtered_labels = labels[labels.index.isin(filtered_ids)]\n",
    "\n",
    "    if test_size <= 0.5:\n",
    "        training_indices, test_indices = next(iter(\n",
    "                sklearn.cross_validation.StratifiedKFold(filtered_labels, int(1/test_size), shuffle=True)))\n",
    "    else:\n",
    "        test_indices, training_indices = next(\n",
    "            iter(sklearn.cross_validation.StratifiedKFold(filtered_labels, int(1/(1-test_size)), shuffle=True)))\n",
    "    training_ids = [filtered_ids[i] for i in training_indices]\n",
    "    test_ids = [filtered_ids[i] for i in test_indices]\n",
    "    \n",
    "    training_features = filtered_features[filtered_features.index.isin(training_ids)]\n",
    "    test_features = filtered_features[filtered_features.index.isin(test_ids)]\n",
    "    training_labels = filtered_labels[filtered_labels.index.isin(training_ids)]\n",
    "    test_labels = filtered_labels[filtered_labels.index.isin(test_ids)]\n",
    "    \n",
    "    return training_features, test_features, training_labels, test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Score Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_score_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_sequence_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_strand_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_start_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_end_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/summary_frame.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/annotation_frame.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/peak_sequences/C57BL6J.fa ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Score Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "motif_score_frame=pd.read_pickle('motif_score_frame_C57BL6J.pickle')\n",
    "motif_sequence_frame = pd.read_pickle('motif_sequence_frame_C57BL6J.pickle')\n",
    "motif_strand_frame = pd.read_pickle('motif_strand_frame_C57BL6J.pickle')\n",
    "motif_start_frame = pd.read_pickle('motif_start_frame_C57BL6J.pickle')\n",
    "motif_end_frame = pd.read_pickle('motif_end_frame_C57BL6J.pickle')\n",
    "summary_frame = pd.read_pickle('summary_frame.pickle')\n",
    "annotation_frame = pd.read_pickle('annotation_frame.pickle')\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "normed_motif_frame = pd.DataFrame(scaler.fit_transform(motif_score_frame.ix[:,3:]))\n",
    "normed_motif_frame.columns = motif_score_frame.columns.values[3:]\n",
    "normed_motif_frame.index = motif_score_frame.index.values\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standardized_motif_frame = pd.DataFrame(scaler.fit_transform(motif_score_frame.ix[:,3:]))\n",
    "standardized_motif_frame.columns = motif_score_frame.columns.values[3:]\n",
    "standardized_motif_frame.index = motif_score_frame.index.values\n",
    "\n",
    "_factors = sorted(list(set([x.split('_')[1] for x in summary_frame.columns if '_' in x])))\n",
    "_factors.remove('atac')\n",
    "\n",
    "### read in sequences as dictionary {peakID: sequence}\n",
    "with open('./C57BL6J.fa') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "_id_sequence_dict = {}\n",
    "for line in data:\n",
    "    if line[0] == '>':\n",
    "        sequenceName = line.strip()[1:]\n",
    "    else:\n",
    "        _id_sequence_dict[sequenceName] = line.strip().upper()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classifier using Open Chromatin Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numIterations = 5\n",
    "ap1_members = ['atf3','cjun', 'fos', 'junb','jund']    \n",
    "test_size = 0.5\n",
    "factors = ['atf3','cjun', 'fos', 'junb','jund', 'atac', 'cebpa', 'pu1', 'p65']\n",
    "# c57bl6_indices = summary_frame[summary_frame['Factors'].str.contains('c57bl6')].index.values  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data01/glasslab/home/jtao/software/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:49: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atf3_veh roc: 0.836974709714 5.61270208208e-06 precision: 0.711601594732 3.53410618648e-06 numTestPositives: 10991\n",
      "cjun_veh roc: 0.812956501449 3.90929117893e-06 precision: 0.470326834035 6.15164296518e-06 numTestPositives: 6346\n",
      "fos_veh roc: 0.85820935437 9.32261322104e-06 precision: 0.354988988947 4.44600984708e-05 numTestPositives: 971\n",
      "junb_veh roc: 0.685413905353 8.2720549774e-05 precision: 0.0214656931746 2.62037146045e-07 numTestPositives: 244\n",
      "jund_veh roc: 0.806430962408 3.85320637865e-06 precision: 0.56506012027 2.15782634439e-05 numTestPositives: 9146\n",
      "atf3_kla roc: 0.831525390212 4.86761024132e-07 precision: 0.802433251593 3.69917466276e-06 numTestPositives: 17245\n",
      "cjun_kla roc: 0.807262952194 1.08763770612e-06 precision: 0.480549590428 4.3931060878e-06 numTestPositives: 8022\n",
      "fos_kla roc: 0.832284162804 1.86405547115e-06 precision: 0.661452757926 1.67635553822e-05 numTestPositives: 10670\n",
      "junb_kla roc: 0.829456310449 2.86007019466e-06 precision: 0.480705564122 1.51660288731e-05 numTestPositives: 7071\n",
      "jund_kla roc: 0.816022942104 2.52666953236e-06 precision: 0.708676688008 9.36877713894e-06 numTestPositives: 14925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for monomers using all motifs\n",
    "strain = 'c57bl6'\n",
    "factor_auc_dict = {}\n",
    "factor_precision_dict = {}\n",
    "factor_coeff_dict = {}\n",
    "factor_prob_dict = {}\n",
    "factor_meanCoeff_dict = {}\n",
    "factor_intercept_dict = {}\n",
    "factor_meanIntercept_dict = {}\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        c57bl6_indices = summary_frame[summary_frame[['c57bl6_' + x + '_' + treatment for x in factors]].sum(axis=1) > 0].index.values  \n",
    "        features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)]\n",
    "        labels = summary_frame[summary_frame.index.isin(c57bl6_indices)][strain + '_' + monomer + '_' + treatment] > 0.0\n",
    "        if np.sum(labels) >= 100:\n",
    "            all_aucs = []\n",
    "            all_coefficients = []\n",
    "            all_probs = None\n",
    "            all_precisions = []\n",
    "            all_intercepts = []\n",
    "            for i in range(numIterations):  \n",
    "\n",
    "                # split data into training and test sets\n",
    "                training_features, test_features, training_labels, test_labels = get_GC_matched_split(\n",
    "                    features, labels, test_size = test_size, tolerance = 0.01)\n",
    "\n",
    "                #  Run classifier\n",
    "                lr_classifier = sklearn.linear_model.LogisticRegression(penalty='l1', n_jobs=-1)\n",
    "\n",
    "                lr_classifier.fit(training_features, training_labels)\n",
    "                # retrieve probabilities\n",
    "                probas_lr = lr_classifier.predict_proba(test_features)\n",
    "\n",
    "                # score predictions\n",
    "                current_roc_auc = sklearn.metrics.roc_auc_score(test_labels, probas_lr[:, 1], average = None)\n",
    "                current_precision = sklearn.metrics.average_precision_score(test_labels, probas_lr[:, 1], average = None)\n",
    "\n",
    "                all_aucs.append(current_roc_auc)\n",
    "                all_precisions.append(current_precision)\n",
    "\n",
    "                # score all sequences\n",
    "                probs = lr_classifier.predict_proba(features)[:, 1]\n",
    "\n",
    "                current_coefficients = lr_classifier.coef_.flatten()\n",
    "                all_coefficients.append(current_coefficients)\n",
    "                all_intercepts.append(lr_classifier.intercept_[0])\n",
    "                \n",
    "                if all_probs == None:\n",
    "                    all_probs = probs\n",
    "                else:\n",
    "                    all_probs = all_probs + probs\n",
    "            mean_coefficients = np.mean(all_coefficients, axis=0)\n",
    "            \n",
    "            factor_auc_dict[monomer + '_' + treatment]= all_aucs\n",
    "            factor_precision_dict[monomer + '_' + treatment] = all_precisions\n",
    "            factor_coeff_dict[monomer + '_' + treatment] = all_coefficients\n",
    "            factor_prob_dict[monomer + '_' + treatment] = all_probs\n",
    "            factor_meanCoeff_dict[monomer + '_' + treatment] = mean_coefficients\n",
    "            factor_intercept_dict[monomer + '_' + treatment] = all_intercepts\n",
    "            factor_meanIntercept_dict[monomer + '_' + treatment] = np.mean(all_intercepts)\n",
    "            print(monomer + '_' + treatment,\n",
    "                  'roc:', np.mean(all_aucs), np.var(all_aucs),\n",
    "                  'precision:', np.mean(all_precisions), np.var(all_precisions),  \n",
    "                  'numTestPositives:', np.sum(test_labels)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create background peaks from genomic sequences from each chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRandomBackgroundSwitch(target_positions, \n",
    "                        size_ratio = 1.0, \n",
    "                        tolerance = 0.05, \n",
    "                        N_threshold = 0.5 ):\n",
    "    '''\n",
    "    target_sequences: 2D numpy array, list of genomic coordinates for target sequences [[chr,start,end],...]\n",
    "    size_ratio: float, number of background sequences relative to target sequences\n",
    "    tolerance: float, max difference in GC content between True and background labelled samples\n",
    "    *** Uses mm10 genome taken from Homer ***\n",
    "    '''\n",
    "    \n",
    "    ###load mm10 genome into memory\n",
    "    \n",
    "    # index target positions\n",
    "    # {chr:[]}, value is chromosome length boolean array\n",
    "    # largest chromosome has 200 million bps \n",
    "    _chromosomes = ['chr1' , 'chr2' , 'chr3' , 'chr4' , 'chr5' , \n",
    "                    'chr6' , 'chr7' , 'chr8' , 'chr9' , 'chr10', \n",
    "                    'chr11', 'chr12', 'chr13', 'chr14', 'chr15', \n",
    "                    'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
    "    _chrom_size_dict = {}\n",
    "    _chrom_seq_dict = {}\n",
    "    for chrom in _chromosomes:\n",
    "        with open('./mm10_genome/' + chrom + '.fa') as f:\n",
    "            data = f.readlines()\n",
    "        seq = ''.join(x.upper().strip() for x in data[1:])\n",
    "        size = len(seq)\n",
    "        _chrom_size_dict[chrom] = size\n",
    "        _chrom_seq_dict[chrom] = seq\n",
    "    _numChromosomes = len(_chromosomes)\n",
    "    \n",
    "    target_chr_position_dict = {x:np.zeros(200000000) for x in _chromosomes} \n",
    "    ### initialize target_chr_position_dict using target positions\n",
    "    ### retreive target sequences\n",
    "    target_sequences = []\n",
    "    for pos in target_positions:\n",
    "        chrom = pos[0]        \n",
    "        start = pos[1]\n",
    "        end = pos[2]\n",
    "        target_chr_position_dict[chrom][start-1:end] = 1 # use 0 indexing of position, versus 1 indexing used in fasta\n",
    "        seq = _chrom_seq_dict[chrom][start:(end+1)]\n",
    "        target_sequences.append(seq)\n",
    "    ### calculate GC content and average length of the target sequences\n",
    "    target_gc_count = 0\n",
    "    target_length_count = 0\n",
    "    for s in target_sequences:\n",
    "        target_gc_count += s.count('G')\n",
    "        target_gc_count += s.count('C')\n",
    "        target_length_count += len(s)\n",
    "    target_gc_content = target_gc_count/(target_length_count+0.0000001) # GC content of target sequences\n",
    "    mean_target_length = target_length_count/len(target_sequences) # average length of target sequences\n",
    "    mean_target_length = int(mean_target_length)\n",
    "    \n",
    "    ### select random genomic loci such that they do no overlap target sequences\n",
    "    numSelected = 0\n",
    "    numToSelect = len(target_positions) * size_ratio * 2 # candidate pool of background seqs is 2X larger\n",
    "    candidate_positions = []\n",
    "    while numSelected < numToSelect:\n",
    "        # select random chromsome\n",
    "        chromIndex = np.random.randint(_numChromosomes)\n",
    "        randChrom = _chromosomes[chromIndex]\n",
    "        randChromSize = _chrom_size_dict[randChrom]\n",
    "        # must find non overlapping segment on this chromosome before moving on\n",
    "        selectedSequence = False\n",
    "        while not selectedSequence:\n",
    "            randStart = np.random.randint(randChromSize)\n",
    "            randEnd = randStart + mean_target_length\n",
    "            overlap_sum = np.sum(target_chr_position_dict[randChrom][randStart:(randEnd + 1)])\n",
    "            if not overlap_sum > 0:\n",
    "                selectedSequence = True\n",
    "                numSelected+=1\n",
    "                candidate_positions.append([randChrom, randStart, randEnd])\n",
    "\n",
    "    ### retrieve sequences of random genomic loci\n",
    "    numFiltered=0\n",
    "    filtered_candidate_positions = []\n",
    "    numNallowed = int(N_threshold * mean_target_length)\n",
    "    for cp in candidate_positions:\n",
    "        chrom = cp[0]\n",
    "        start = cp[1]\n",
    "        end = cp[2]\n",
    "        candidate_seq = _chrom_seq_dict[chrom][start:(end+1)]\n",
    "        numN = candidate_seq.count('N')\n",
    "        # throw away background peaks containing greater than this fraction of N\n",
    "        if numN <= numNallowed:\n",
    "            filtered_candidate_positions.append((chrom, start, end,candidate_seq))\n",
    "\n",
    "    if len(filtered_candidate_positions) < len(target_positions):\n",
    "        print('The genome is vast and empty and filled with Ns')\n",
    "        return None\n",
    "       \n",
    "    ### select random set of candidate background loci\n",
    "    random.shuffle(filtered_candidate_positions)\n",
    "    \n",
    "    toReturn_positions = filtered_candidate_positions[:len(target_positions)]\n",
    "    remaining_positions = filtered_candidate_positions[len(target_positions):]\n",
    "    # calcuate GC content of background samples\n",
    "    background_gc_count = 0\n",
    "    background_length = 0\n",
    "    for trp in toReturn_positions:\n",
    "        s = trp[3]\n",
    "        background_gc_count += s.count('G')\n",
    "        background_gc_count += s.count('C')\n",
    "        background_length += len(s)\n",
    "    background_gc_content = background_gc_count/(background_length+0.0000001)\n",
    "        \n",
    "    numToReturn = len(toReturn_positions)\n",
    "    numRemaining = len(remaining_positions)\n",
    "    counter = 0\n",
    "    while abs(target_gc_content - background_gc_content) > tolerance:\n",
    "        # swith background GC sequences until GC content matches tolerance\n",
    "        switched_seq = False       \n",
    "        while not switched_seq:\n",
    "            # sequence to be switched out\n",
    "            rand_index = np.random.randint(numToReturn)\n",
    "            current_seq = toReturn_positions[rand_index][3]\n",
    "            current_gc_count = current_seq.count('G')+ current_seq.count('C')\n",
    "            current_length = len(current_seq)\n",
    "            current_gc = current_gc_count/current_length\n",
    "            \n",
    "            # sequence to be switched out\n",
    "            switch_index = np.random.randint(numRemaining)\n",
    "            switch_seq = remaining_positions[switch_index][3]\n",
    "            switch_gc_count = switch_seq.count('G')+ switch_seq.count('C')\n",
    "            switch_length = len(switch_seq)\n",
    "            switch_gc = switch_gc_count/switch_length\n",
    "            if target_gc_content > background_gc_content:\n",
    "                # switch sequences that would increase overall GC content of background sequences\n",
    "                if switch_gc > current_gc:\n",
    "                    switched_seq = True\n",
    "            else:\n",
    "                # switch sequences that would decrease overall GC content of background sequences\n",
    "                if switch_gc < current_gc:\n",
    "                    switched_seq = True\n",
    "        counter +=1\n",
    "        if counter % 1000 == 0:\n",
    "            print(background_gc_content, target_gc_content, tolerance)\n",
    "        # switch sequences\n",
    "        temp_pos = toReturn_positions[rand_index]\n",
    "        toReturn_positions[rand_index] = remaining_positions[switch_index]\n",
    "        remaining_positions[switch_index] = temp_pos\n",
    "\n",
    "        # update background GC content\n",
    "        background_gc_count -= current_gc_count\n",
    "        background_length -= current_length\n",
    "        background_gc_count += switch_gc_count\n",
    "        background_length += switch_length\n",
    "        \n",
    "        background_gc_content = background_gc_count/background_length\n",
    "          \n",
    "        \n",
    "    print(target_gc_content, background_gc_content)\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRandomBackground(target_positions, \n",
    "                        size_ratio = 1.0, \n",
    "                        tolerance = 0.01, \n",
    "                        N_threshold = 0.5 ):\n",
    "    '''\n",
    "    target_sequences: 2D numpy array, list of genomic coordinates for target sequences [[chr,start,end],...]\n",
    "    size_ratio: float, number of background sequences relative to target sequences\n",
    "    tolerance: float, max difference in GC content between True and background labelled samples\n",
    "    *** Uses mm10 genome taken from Homer ***\n",
    "    '''\n",
    "    \n",
    "    ###load mm10 genome into memory\n",
    "    \n",
    "    # index target positions\n",
    "    # {chr:[]}, value is chromosome length boolean array\n",
    "    # largest chromosome has 200 million bps \n",
    "    _chromosomes = ['chr1' , 'chr2' , 'chr3' , 'chr4' , 'chr5' , \n",
    "                    'chr6' , 'chr7' , 'chr8' , 'chr9' , 'chr10', \n",
    "                    'chr11', 'chr12', 'chr13', 'chr14', 'chr15', \n",
    "                    'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
    "    _chrom_size_dict = {}\n",
    "    _chrom_seq_dict = {}\n",
    "    for chrom in _chromosomes:\n",
    "        with open('./mm10_genome/' + chrom + '.fa') as f:\n",
    "            data = f.readlines()\n",
    "        seq = ''.join(x.upper().strip() for x in data[1:])\n",
    "        size = len(seq)\n",
    "        _chrom_size_dict[chrom] = size\n",
    "        _chrom_seq_dict[chrom] = seq\n",
    "    _numChromosomes = len(_chromosomes)\n",
    "    \n",
    "    target_chr_position_dict = {x:np.zeros(200000000) for x in _chromosomes} \n",
    "    ### initialize target_chr_position_dict using target positions\n",
    "    ### retreive target sequences\n",
    "    target_sequences = []\n",
    "    for pos in target_positions:\n",
    "        chrom = pos[0]        \n",
    "        start = pos[1]\n",
    "        end = pos[2]\n",
    "        target_chr_position_dict[chrom][start-1:end] = 1 # use 0 indexing of position, versus 1 indexing used in fasta\n",
    "        seq = _chrom_seq_dict[chrom][start:(end+1)]\n",
    "        target_sequences.append(seq)\n",
    "    ### calculate GC content and average length of the target sequences\n",
    "    target_gc_count = 0\n",
    "    target_length_count = 0\n",
    "    for s in target_sequences:\n",
    "        target_gc_count += s.count('G')\n",
    "        target_gc_count += s.count('C')\n",
    "        target_length_count += len(s)\n",
    "    target_gc_content = target_gc_count/(target_length_count+0.0000001) # GC content of target sequences\n",
    "    mean_target_length = target_length_count/len(target_sequences) # average length of target sequences\n",
    "    mean_target_length = int(mean_target_length)\n",
    "    \n",
    "    ### select random genomic loci such that they do no overlap target sequences\n",
    "    numSelected = 0\n",
    "    numToSelect = len(target_positions) * size_ratio * 2 # candidate pool of background seqs is 2X larger\n",
    "    candidate_positions = []\n",
    "    numNallowed = int(N_threshold * mean_target_length) # number of allowable Ns\n",
    "    counter = 0\n",
    "    while numSelected < numToSelect:\n",
    "        if counter % 100000 == 0:\n",
    "            print(counter, numSelected)\n",
    "        # select random chromsome\n",
    "        chromIndex = np.random.randint(_numChromosomes)\n",
    "        randChrom = _chromosomes[chromIndex]\n",
    "        randChromSize = _chrom_size_dict[randChrom]\n",
    "        # must find non overlapping segment on this chromosome before moving on\n",
    "        selectedSequence = False\n",
    "        while not selectedSequence:\n",
    "            counter += 1\n",
    "            randStart = np.random.randint(randChromSize)\n",
    "            randEnd = randStart + mean_target_length\n",
    "            overlap_sum = np.sum(target_chr_position_dict[randChrom][randStart:(randEnd + 1)])\n",
    "            \n",
    "            if not overlap_sum > 0:\n",
    "                randSeq = _chrom_seq_dict[randChrom][randStart:(randEnd+1)]\n",
    "                numN = randSeq.count('N')\n",
    "                if numN <= numNallowed:\n",
    "                    rand_gc_count = randSeq.count('G')+ randSeq.count('C')\n",
    "                    rand_gc = rand_gc_count/mean_target_length\n",
    "                    if abs(target_gc_content - rand_gc) <= tolerance:\n",
    "                        selectedSequence = True\n",
    "                        numSelected+=1\n",
    "                        candidate_positions.append([randChrom, randStart, randEnd, randSeq])\n",
    "    # calcuate GC content of background samples\n",
    "    background_gc_count = 0\n",
    "    background_length = 0\n",
    "    for cp in candidate_positions:\n",
    "        s = cp[3]\n",
    "        background_gc_count += s.count('G')\n",
    "        background_gc_count += s.count('C')\n",
    "        background_length += len(s)\n",
    "    background_gc_content = background_gc_count/(background_length+0.0000001)\n",
    "    print(target_gc_content,background_gc_content)\n",
    "    return candidate_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate random genomic background for all monomers\n",
    "strain = 'c57bl6'\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        target_indices = summary_frame[summary_frame[strain + '_' + monomer + '_' + treatment] > 0.0].index.values\n",
    "        target_positions = summary_frame[summary_frame.index.isin(target_indices)][['chr', 'start', 'end']].values\n",
    "        start = time.time()\n",
    "        backgroundPositions = getRandomBackground(target_positions, N_threshold =1.0, tolerance=0.05, size_ratio=5)\n",
    "        end = time.time()\n",
    "        print(monomer, treatment, end - start)\n",
    "        pickle.dump(backgroundPositions,open('./background_pickles/' + monomer + '_' + treatment + '_background.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background positions to create peak files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strain = 'c57bl6'\n",
    "! if [ ! -d ./background_peak_files ]; mkdir ./background_peak_files\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        backgroundPositions = pickle.load(open('./background_pickles/' + monomer + '_' + treatment + '_background.pickle', 'rb'))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a script to scan for motifs using FIMO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! if [ ! -d ./fimo_results/ ]; then mkdir ./fimo_results/; fi\n",
    "! if [ ! -d ./fimo_out/ ]; then mkdir ./fimo_out/; fi\n",
    "\n",
    "\n",
    "pthresh = 0.01\n",
    "motif_dir = '/home/jenhan/analysis/cobinding_motif_analysis/fimo_motifs/'\n",
    "fimo_results_dir = './fimo_results'\n",
    "\n",
    "\n",
    "peakDirectory =  './group_by_chromosome/'\n",
    "for chrom in os.listdir(peakDirectory):\n",
    "    scriptFile = open('scanMotifs_' + chrom + '.sh','w')\n",
    "    for m in os.listdir(motif_dir):\n",
    "        fimo_out_dir = './fimo_out/' + chrom + '_' + m.replace('.fimo','')\n",
    "\n",
    "        if 'fimo' in m:\n",
    "            outPath = fimo_results_dir + '/' +chrom + '_'+ m.replace('.fimo','') +'.txt'\n",
    "            scriptFile.write(\n",
    "                'fimo --text --max-stored-scores 2000000 --output-pthresh ' + \n",
    "                str(pthresh)  + ' ' +\n",
    "                motif_dir + '/' + m + ' ./group_by_chromosome/' + chrom + '/' + chrom + '_tile.fa ' +\n",
    "                '> ' + outPath + ' & \\n')\n",
    "    scriptFile.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod a+x ./scanMotifs*.sh\n",
    "for i in ./scanMotifs*sh; \n",
    "    do echo 'sleeping...';\n",
    "    echo $i;\n",
    "    $i;\n",
    "    sleep 5m;\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Motif Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Create background summary frame"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
