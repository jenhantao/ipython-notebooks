{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Background Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: PATH=/gpfs/data01/glasslab/home/jtao/perl5/bin:/gpfs/data01/glasslab/home/jtao/software/anaconda3/bin:/home/jtao/software/bin:/usr/local/sbin:/usr/sbin:/usr/bin:/usr/local/bin:/usr/bin:/gpfs/data01/glasslab/home/jtao/software/homer/bin:/gpfs/data01/glasslab/home/jtao/software/weblogo:/home/jtao/code/seq_merge_pipe:/home/vlink/mouse_strains/marge/shifting:/bioinformatics/glassutils/scripts:/bioinformatics/software/meme/bin:/home/jtao/software/lsgkm/bin\n"
     ]
    }
   ],
   "source": [
    "### header ###\n",
    "__author__ = \"Jenhan Tao\"\n",
    "__license__ = \"BSD\"\n",
    "__email__ = \"jenhantao@gmail.com\"\n",
    "\n",
    "### imports ###\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import itertools\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib_venn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from random import shuffle\n",
    "import threading\n",
    "import time\n",
    "from collections import Counter\n",
    "### notebook specific configuration ###\n",
    "%matplotlib inline\n",
    "matplotlib.pylab.rcParams['savefig.dpi'] = 200\n",
    "sys.setrecursionlimit(5000)\n",
    "os.chdir('/gpfs/data01/glasslab/home/jtao/analysis/random_background_analysis/')\n",
    "sns.set_context('notebook')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env PATH=/gpfs/data01/glasslab/home/jtao/perl5/bin:/gpfs/data01/glasslab/home/jtao/software/anaconda3/bin:/home/jtao/software/bin:/usr/local/sbin:/usr/sbin:/usr/bin:/usr/local/bin:/usr/bin:/gpfs/data01/glasslab/home/jtao/software/homer/bin:/gpfs/data01/glasslab/home/jtao/software/weblogo:/home/jtao/code/seq_merge_pipe:/home/vlink/mouse_strains/marge/shifting:/bioinformatics/glassutils/scripts:/bioinformatics/software/meme/bin:/home/jtao/software/lsgkm/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_score_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_sequence_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_strand_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_start_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_end_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/summary_frame.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/annotation_frame.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/peak_sequences/C57BL6J.fa ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_count_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_summedScore_frame_C57BL6J.pickle ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_score_frame_BALBCJ.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_sequence_frame_BALBCJ.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_strand_frame_BALBCJ.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_start_frame_BALBCJ.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_end_frame_BALBCJ.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/peak_sequences/BALBCJ.fa ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_count_frame_BALBCJ.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_summedScore_frame_BALBCJ.pickle ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Score Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C57Bl6 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_frame = pd.read_pickle('summary_frame.pickle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create background peaks from genomic sequences from each chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRandomBackground(target_positions, \n",
    "                        size_ratio = 1.0, \n",
    "                        tolerance = 0.01, \n",
    "                        N_threshold = 0.5 ):\n",
    "    '''\n",
    "    target_sequences: 2D numpy array, list of genomic coordinates for target sequences [[chr,start,end],...]\n",
    "    size_ratio: float, number of background sequences relative to target sequences\n",
    "    tolerance: float, max difference in GC content between True and background labelled samples\n",
    "    *** Uses mm10 genome taken from Homer ***\n",
    "    '''\n",
    "    \n",
    "    ###load mm10 genome into memory\n",
    "    \n",
    "    # index target positions\n",
    "    # {chr:[]}, value is chromosome length boolean array\n",
    "    # largest chromosome has 200 million bps \n",
    "    _chromosomes = ['chr1' , 'chr2' , 'chr3' , 'chr4' , 'chr5' , \n",
    "                    'chr6' , 'chr7' , 'chr8' , 'chr9' , 'chr10', \n",
    "                    'chr11', 'chr12', 'chr13', 'chr14', 'chr15', \n",
    "                    'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
    "    _chrom_size_dict = {}\n",
    "    _chrom_seq_dict = {}\n",
    "    for chrom in _chromosomes:\n",
    "        with open('./mm10_genome/' + chrom + '.fa') as f:\n",
    "            data = f.readlines()\n",
    "        seq = ''.join(x.upper().strip() for x in data[1:])\n",
    "        size = len(seq)\n",
    "        _chrom_size_dict[chrom] = size\n",
    "        _chrom_seq_dict[chrom] = seq\n",
    "    _numChromosomes = len(_chromosomes)\n",
    "    \n",
    "    target_chr_position_dict = {x:np.zeros(200000000) for x in _chromosomes} \n",
    "    ### initialize target_chr_position_dict using target positions\n",
    "    ### retreive target sequences\n",
    "    target_sequences = []\n",
    "    for pos in target_positions:\n",
    "        chrom = pos[0]        \n",
    "        start = pos[1]\n",
    "        end = pos[2]\n",
    "        target_chr_position_dict[chrom][start-1:end] = 1 # use 0 indexing of position, versus 1 indexing used in fasta\n",
    "        seq = _chrom_seq_dict[chrom][start:(end)]\n",
    "        target_sequences.append(seq)\n",
    "    ### calculate GC content and average length of the target sequences\n",
    "    target_gc_count = 0\n",
    "    target_length_count = 0\n",
    "    for s in target_sequences:\n",
    "        target_gc_count += s.count('G')\n",
    "        target_gc_count += s.count('C')\n",
    "        target_length_count += len(s)\n",
    "    target_gc_content = target_gc_count/(target_length_count+0.0000001) # GC content of target sequences\n",
    "    mean_target_length = target_length_count/len(target_sequences) # average length of target sequences\n",
    "    mean_target_length = int(np.floor(mean_target_length))\n",
    "    ### select random genomic loci such that they do no overlap target sequences\n",
    "    numSelected = 0\n",
    "    numToSelect = len(target_positions) * size_ratio # candidate pool of background seqs is size_ratio X larger\n",
    "    candidate_positions = []\n",
    "    numNallowed = int(N_threshold * mean_target_length) # number of allowable Ns\n",
    "    counter = 0\n",
    "    while numSelected < numToSelect:\n",
    "        if counter % 100000 == 0:\n",
    "            print(counter, numSelected)\n",
    "        # select random chromsome\n",
    "        chromIndex = np.random.randint(_numChromosomes)\n",
    "        randChrom = _chromosomes[chromIndex]\n",
    "        randChromSize = _chrom_size_dict[randChrom]\n",
    "        # must find non overlapping segment on this chromosome before moving on\n",
    "        selectedSequence = False\n",
    "        while not selectedSequence:\n",
    "            counter += 1\n",
    "            randStart = np.random.randint(randChromSize)\n",
    "            randEnd = randStart + mean_target_length\n",
    "            overlap_sum = np.sum(target_chr_position_dict[randChrom][randStart:(randEnd + 1)])\n",
    "            \n",
    "            if not overlap_sum > 0:\n",
    "                randSeq = _chrom_seq_dict[randChrom][randStart:(randEnd+1)]\n",
    "                numN = randSeq.count('N')\n",
    "                if numN <= numNallowed:\n",
    "                    rand_gc_count = randSeq.count('G')+ randSeq.count('C')\n",
    "                    rand_gc = rand_gc_count/mean_target_length\n",
    "                    if abs(target_gc_content - rand_gc) <= tolerance:\n",
    "                        selectedSequence = True\n",
    "                        numSelected+=1\n",
    "                        candidate_positions.append([randChrom, randStart, randEnd, randSeq])\n",
    "    # calcuate GC content of background samples\n",
    "    background_gc_count = 0\n",
    "    background_length = 0\n",
    "    for cp in candidate_positions:\n",
    "        s = cp[3]\n",
    "        background_gc_count += s.count('G')\n",
    "        background_gc_count += s.count('C')\n",
    "        background_length += len(s)\n",
    "    background_gc_content = background_gc_count/(background_length+0.0000001)\n",
    "    print('target GC:', target_gc_content, \n",
    "          'background GC:', background_gc_content, \n",
    "          'target length:', mean_target_length,\n",
    "          'numTargetPositions',len(target_positions),\n",
    "          'backgroundPositions', len(candidate_positions))\n",
    "    return candidate_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "target GC: 0.4925952895419081 background GC: 0.4817145044010695 target length: 200 numTargetPositions 23140 backgroundPositions 115700\n",
      "atf3 veh 35.86300587654114\n",
      "0 0\n",
      "100000 31875\n",
      "target GC: 0.4936398738657412 background GC: 0.4817101185622151 target length: 200 numTargetPositions 15539 backgroundPositions 77695\n",
      "cjun veh 30.41100239753723\n",
      "0 0\n",
      "target GC: 0.5973989569748387 background GC: 0.573518327527866 target length: 200 numTargetPositions 767 backgroundPositions 3835\n",
      "fos veh 27.855791807174683\n",
      "0 0\n",
      "target GC: 0.49717002237080854 background GC: 0.48624439324618823 target length: 200 numTargetPositions 447 backgroundPositions 2235\n",
      "junb veh 27.6730477809906\n",
      "0 0\n",
      "target GC: 0.5091324503311129 background GC: 0.4939045475627441 target length: 200 numTargetPositions 19630 backgroundPositions 98150\n",
      "jund veh 32.09514307975769\n",
      "0 0\n",
      "100000 34722\n",
      "200000 69353\n",
      "target GC: 0.4801782310331616 background GC: 0.4734733283097056 target length: 200 numTargetPositions 36722 backgroundPositions 183610\n",
      "atf3 kla 34.09777069091797\n",
      "0 0\n",
      "100000 31862\n",
      "target GC: 0.49073215410153725 background GC: 0.48166472007698363 target length: 200 numTargetPositions 17469 backgroundPositions 87345\n",
      "cjun kla 30.8685200214386\n",
      "0 0\n",
      "100000 33294\n",
      "target GC: 0.48934068416080473 background GC: 0.47745482680637924 target length: 200 numTargetPositions 24351 backgroundPositions 121755\n",
      "fos kla 31.680745124816895\n",
      "0 0\n",
      "target GC: 0.4949569932684931 background GC: 0.48159836568838316 target length: 200 numTargetPositions 13370 backgroundPositions 66850\n",
      "junb kla 30.029738664627075\n",
      "0 0\n",
      "target GC: 0.48878131722130064 background GC: 0.4775397024745925 target length: 200 numTargetPositions 31612 backgroundPositions 158060\n",
      "jund kla 33.10901379585266\n"
     ]
    }
   ],
   "source": [
    "# generate random genomic background for all monomers\n",
    "import time\n",
    "strain = 'c57bl6'\n",
    "ap1_members = ['atf3','cjun', 'fos', 'junb','jund']    \n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        target_indices = summary_frame[summary_frame[strain + '_' + monomer + '_' + treatment] > 0.0].index.values\n",
    "        target_positions = summary_frame[summary_frame.index.isin(target_indices)][['chr', 'start', 'end']].values\n",
    "        start = time.time()\n",
    "        backgroundPositions = getRandomBackground(target_positions, \n",
    "                                                  N_threshold =1.0, \n",
    "                                                  tolerance=0.05, \n",
    "                                                  size_ratio=5)\n",
    "        end = time.time()\n",
    "        print(monomer, treatment, end - start)\n",
    "        pickle.dump(backgroundPositions,open('./background_pickles/' + monomer + '_' + treatment + '_background.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Background positions to create peak files and Merge Peak Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strain = 'c57bl6'\n",
    "! if [ ! -d ./background_peak_files ]; then mkdir ./background_peak_files; fi\n",
    "ap1_members = ['atf3','cjun', 'fos', 'junb','jund']    \n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        backgroundPositions = pickle.load(open('./background_pickles/' + monomer + '_' + treatment + '_background.pickle', 'rb'))\n",
    "        outFile = open('./background_peak_files/' + strain + '_' + monomer + '_' + treatment + '-background_peaks.tsv' , 'w')\n",
    "        outFile.write('\\t'.join(['#PeakID','chr','start','end','strand','idrScore', 'count','\\n']))\n",
    "        counter = 0\n",
    "        for pos in backgroundPositions:\n",
    "            chrom = pos[0]\n",
    "            start = str(pos[1])\n",
    "            end = str(pos[2])\n",
    "            strand = '+' # arbitrary - for compatibility with downstream scripts\n",
    "            score = '1' # arbitrary - for compatibility with downstream scripts\n",
    "            randID = 'background_' + str(np.random.randint(10000)) + '_' + str(counter)\n",
    "            counter += 1\n",
    "            outFile.write('\\t'.join([randID, chrom, start, end, strand, score, score, '\\n']))\n",
    "        outFile.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! mergePeaks -d 0 ./background_peak_files/*tsv > ./background_merged_peaks.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no peaks will be merged and so merged peak files will have peak center for both start/end coordinates\n",
    "merged_frame = pd.read_csv('./background_merged_peaks.tsv', sep='\\t', low_memory=False)\n",
    "sizes = [x[2]-x[1] for x in backgroundPositions]\n",
    "mean_peak_size = np.mean(sizes)\n",
    "adj_distance = int(mean_peak_size/2)\n",
    "merged_frame['start'] = merged_frame['start'] - adj_distance\n",
    "merged_frame['end'] = merged_frame['end'] + adj_distance\n",
    "merged_frame.to_csv('./background_merged_fixed_peaks.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! makeSummaryFile.py ./background_merged_fixed_peaks.tsv ./background_group_summary.tsv ./background_peak_files/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data01/glasslab/home/jtao/software/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (5,6,7,8,9,11,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read in peak data data\n",
    "summary_background_frame = pd.read_csv('./background_group_summary.tsv' , sep='\\t')\n",
    "summary_background_frame = summary_background_frame.fillna('0')\n",
    "for col in summary_background_frame.columns[5:]:\n",
    "    floatValues = []\n",
    "    for val in summary_background_frame[col].values.astype(str):\n",
    "        if ',' in val:\n",
    "            maxVal = np.mean([float(x) for x in val.split(',')])\n",
    "            floatValues.append(maxVal)\n",
    "        else:\n",
    "            floatValues.append(float(val))\n",
    "    summary_background_frame[col] = floatValues\n",
    "summary_background_frame.index = summary_background_frame['ID'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a script to scan for motifs using FIMO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d ./peak_sequences ] ;\n",
    "    then mkdir ./peak_sequences\n",
    "else\n",
    "    rm ./peak_sequences/*\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving peaks\n",
      "Loading shift vectors\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "perl /home/vlink/mouse_strains/marge/analysis/extract_seq_from_peakfiles.pl -strains C57BL6J -file ./background_merged_fixed_peaks.tsv -output ./peak_sequences/C57BL6J_marge.fa\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reformat fastq files to use homer peak IDs\n",
    "\n",
    "coordinate_peakID_dict = {} # {chr_start_end:homerID}\n",
    "with open ('./background_merged_fixed_peaks.tsv') as f:\n",
    "    data = f.readlines()\n",
    "for line in data[1:]:\n",
    "    tokens = line.split('\\t')\n",
    "    coordinate = '_'.join(tokens[1:4])\n",
    "    peakID = tokens[0].strip()\n",
    "    coordinate_peakID_dict[coordinate] = tokens[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C57BL6J_marge.fa\n"
     ]
    }
   ],
   "source": [
    "for fastaFile in os.listdir('./peak_sequences/'):\n",
    "    if 'marge' in fastaFile:\n",
    "        strain = fastaFile.split('_')[0]\n",
    "        outFile = open('./peak_sequences/' + fastaFile.replace('_marge',''), 'w')\n",
    "        print(fastaFile)\n",
    "        with open('./peak_sequences/' + fastaFile) as f:\n",
    "            data = f.readlines()\n",
    "        for line in data:\n",
    "            if '>' in line:\n",
    "                coordinate = line[1:].replace('_'+strain,'').strip()\n",
    "                \n",
    "                peakID = coordinate_peakID_dict[coordinate]\n",
    "                outFile.write('>' + peakID + '\\n')\n",
    "               \n",
    "            else:\n",
    "                outFile.write(line)\n",
    "        outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp ./peak_sequences/C57BL6J.fa ./C57BL6J_background.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C57BL6J.fa\n"
     ]
    }
   ],
   "source": [
    "# create a script to scan for motifs using FIMO\n",
    "! if [ ! -d /home/jtao/analysis/random_background_analysis/fimo_results/ ]; then mkdir /home/jtao/analysis/random_background_analysis/fimo_results/; fi\n",
    "! if [ ! -d /home/jtao/analysis/random_background_analysis/fimo_out/ ]; then mkdir /home/jtao/analysis/random_background_analysis/fimo_out/; fi\n",
    "! rm -rf ./fimo_out/*\n",
    "! rm -rf ./fimo_result/*\n",
    "\n",
    "\n",
    "pthresh = 0.01\n",
    "motif_dir = '/home/jtao/analysis/cobinding_motif_analysis/fimo_motifs/'\n",
    "\n",
    "fimo_results_dir = './fimo_results'\n",
    "\n",
    "for fastaFile in os.listdir('./peak_sequences/'):\n",
    "    if not 'marge' in fastaFile:\n",
    "        print(fastaFile)\n",
    "        strain = fastaFile.split('.')[0]\n",
    "        count = 0\n",
    "        scriptFile = open('scanMotifs_background_'+ strain +'.sh','w')\n",
    "        for m in os.listdir(motif_dir):\n",
    "            if 'fimo' in m:\n",
    "                fimo_out_dir = './fimo_out/' + strain + '_' +m.replace('.fimo','')\n",
    "                outPath = fimo_results_dir + '/' +strain + '_' + m.replace('.fimo','') +'.txt'\n",
    "                scriptFile.write(\n",
    "                    '(sleep ' + str(15 * count) + \n",
    "                    's; fimo --text --max-stored-scores 2000000 --output-pthresh ' + \n",
    "                    str(pthresh) +' --oc ' + fimo_out_dir + ' ' +\n",
    "                    motif_dir + '/' + m + ' ./peak_sequences/' + fastaFile +\n",
    "                    '> ' + outPath + ' ) & \\n')\n",
    "                count+=1\n",
    "        scriptFile.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod a+x ./scanMotifs*.sh\n",
    "for i in ./scanMotifs*sh; \n",
    "    do echo 'sleeping...';\n",
    "    echo $i;\n",
    "    $i;\n",
    "#     sleep 5m;\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Motif Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fimo_file(thread_lock, motif_results_path, \n",
    "                   all_peak_ids,\n",
    "                   motif_score_dict,\n",
    "                   motif_sequence_dict,\n",
    "                   motif_strand_dict,\n",
    "                   motif_start_dict,\n",
    "                   motif_end_dict,\n",
    "                   motif_count_dict,\n",
    "                  ):\n",
    "    \n",
    "    # read in fimo result as data frame\n",
    "    fimo_result_frame=pd.read_csv(motif_results_path, \n",
    "                                  skiprows=1,\n",
    "                                  names=['motif_name', \n",
    "                                         'peak_id', \n",
    "                                         'start', \n",
    "                                         'stop', \n",
    "                                         'strand', \n",
    "                                         'score', \n",
    "                                         'pvalue', \n",
    "                                         'sequence'],\n",
    "                                  sep='\\t')\n",
    "    motif_name = fimo_result_frame['motif_name'].values[0]\n",
    "    print('reading', motif_name)\n",
    "    \n",
    "    id_values_dict = {} # {PeakID:(motifScore, motifSequence, motifStrand, motifStart, motifEnd)}\n",
    "    # drop all motif instances that has less than the maximum score\n",
    "    sorted_fimo_result_frame = fimo_result_frame.sort_values(by='score', ascending=False)\n",
    "    top_fimo_result_frame = sorted_fimo_result_frame.drop_duplicates(subset='peak_id')\n",
    "    \n",
    "    # convert data frame to a dictionary \n",
    "    unique_peak_ids = top_fimo_result_frame['peak_id'].values\n",
    "    scores = top_fimo_result_frame['score'].values\n",
    "    strands = top_fimo_result_frame['strand'].values\n",
    "    sequences = top_fimo_result_frame['sequence'].values\n",
    "    starts = top_fimo_result_frame['start'].values\n",
    "    ends = top_fimo_result_frame['stop'].values\n",
    "    \n",
    "    for i in range(len(unique_peak_ids)):\n",
    "        currentPeakID = unique_peak_ids[i]\n",
    "        currentScore = float(scores[i])\n",
    "        currentSequence = sequences[i]\n",
    "        currentStrand = strands[i]\n",
    "        currentStart = int(starts[i])\n",
    "        currentEnd = int(ends[i])\n",
    "        # bundle values\n",
    "        \n",
    "        if currentScore < 0.0:\n",
    "            currentScore = 0.0\n",
    "        \n",
    "        newValues = (currentScore, \n",
    "                     currentSequence, \n",
    "                     currentStrand, \n",
    "                     currentStart, \n",
    "                     currentEnd, \n",
    "                     )\n",
    "        id_values_dict[currentPeakID] = newValues\n",
    "    \n",
    "    # sort values according to all peak IDs\n",
    "    sorted_values = [id_values_dict[x] if x in id_values_dict else (0,'','?',-1,-1) for x in  all_peak_ids]\n",
    "    sorted_scores = [x[0] for x in sorted_values]\n",
    "    sorted_sequences = [x[1] for x in sorted_values]\n",
    "    sorted_strands = [x[2] for x in sorted_values]\n",
    "    sorted_starts = [x[3] for x in sorted_values]\n",
    "    sorted_ends = [x[4] for x in sorted_values]\n",
    "    \n",
    "    # count the number of motif instances\n",
    "    peak_ids = fimo_result_frame['peak_id'].values\n",
    "    id_count_dict = Counter(peak_ids)\n",
    "    \n",
    "    sorted_counts = [id_count_dict[x] if x in id_count_dict else 0 for x in all_peak_ids]\n",
    "    \n",
    "    while thread_lock.locked_lock():\n",
    "        time.sleep(1)\n",
    "    thread_lock.acquire()\n",
    "        \n",
    "    motif_score_dict[motif_name] = sorted_scores\n",
    "    motif_sequence_dict[motif_name] = sorted_sequences\n",
    "    motif_strand_dict[motif_name] = sorted_strands\n",
    "    motif_start_dict[motif_name] = sorted_starts\n",
    "    motif_end_dict[motif_name] = sorted_ends\n",
    "    motif_count_dict[motif_name] = sorted_counts\n",
    "    # release lock\n",
    "    print('finished reading', motif_name )\n",
    "    if thread_lock.locked_lock():\n",
    "        thread_lock.release()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C57BL6J.fa\n",
      "reading gmeb2\n",
      "reading cux\n",
      "reading arid5a\n",
      "reading hnf1\n",
      "reading homeobox-4\n",
      "reading e2f2\n",
      "reading crem\n",
      "reading homeobox-2\n",
      "reading hoxa11\n",
      "reading gsc\n",
      "reading dbp_hlf_tef\n",
      "reading creb3-l1\n",
      "reading duxa\n",
      "reading alx1_alx4_arx\n",
      "reading arid3a\n",
      "reading arid3b\n",
      "reading mef2a-b-d\n",
      "reading hoxc13\n",
      "reading lhx3\n",
      "reading pax3_pax7\n",
      "reading homeobox-3\n",
      "reading e2f1\n",
      "reading homeobox-1\n",
      "reading hoxd8\n",
      "reading atf7_batf3_creb5\n",
      "reading nfil3\n",
      "reading hoxb5_hoxd3\n",
      "reading lin54\n",
      "reading hoxc9\n",
      "reading mybl1\n",
      "reading cenpb\n",
      "reading mybl2\n",
      "reading zbed1\n",
      "reading pou4\n",
      "reading homeobox-5\n",
      "reading nkx2-5\n",
      "reading grhl1\n",
      "readingreading onecut\n",
      " dmbx1\n",
      "reading hoxa5\n",
      "reading dmrt3\n",
      "readingreading ventx\n",
      " cebp\n",
      "reading phox2_prop\n",
      "reading ebox\n",
      "reading cdx\n",
      "reading xbp1\n",
      "reading tcfl5\n",
      "reading dux4\n",
      "reading e2f7\n",
      "reading hsf\n",
      "reading id2_mlxip\n",
      "reading bhlhe23\n",
      "reading fox\n",
      "reading pou1f1\n",
      "reading ap-1\n",
      "reading arntl_mitf\n",
      "reading gfi1\n",
      "reading zbtb33\n",
      "reading mef2c\n",
      "reading pou2-3-5\n",
      "reading dux\n",
      "reading rhox11\n",
      "reading hoxa9\n",
      "reading pou6f2\n",
      "reading nrf1\n",
      "reading mafg\n",
      "reading bcl6b\n",
      "reading pax6\n",
      "reading six3\n",
      "reading mecom\n",
      "reading pax1_pax9\n",
      "reading irf2\n",
      "reading tp63\n",
      "reading hes\n",
      "reading prox1\n",
      "reading esr1\n",
      "reading mtf1\n",
      "reading arnt_mycn\n",
      "reading elf\n",
      "reading ar_nr3c1_nr3c2\n",
      "reading pax2\n",
      "reading maf_nrl\n",
      "reading irf7-8-9\n",
      "reading sox5_sox9_sry\n",
      "reading tbp\n",
      "reading sox8\n",
      "reading srf\n",
      "reading roravar\n",
      "reading sox1-l1-21-4\n",
      "reading e2f8\n",
      "reading t\n",
      "reading bhlh\n",
      "reading isl2_nkx3-1_nkx3-2\n",
      "reading nfyb\n",
      "reading hinfp\n",
      "reading nr2e3\n",
      "reading hnf4a\n",
      "reading tfcp2\n",
      "reading hltf\n",
      "reading bcl6\n",
      "reading rfx\n",
      "reading esrr\n",
      "reading pbx1\n",
      "reading rxravdr\n",
      "reading nr2e1\n",
      "readingreading nfya\n",
      " znf410\n",
      "reading smad3\n",
      "reading elk_etv\n",
      "reading e2f4_e2f6\n",
      "reading nkx2-3_nkx2-8\n",
      "reading tp73\n",
      "reading tbx\n",
      "reading egr\n",
      "reading gli2\n",
      "reading gfi1b\n",
      "readingreading mga_tbx\n",
      " yy2\n",
      "reading gata\n",
      "reading sox17\n",
      "reading pparg\n",
      "readingreading nfat\n",
      " scrt\n",
      "reading lef1\n",
      "reading hic\n",
      "reading tead\n",
      "reading tp53\n",
      "reading stat6\n",
      "reading pax5\n",
      "reading nfkb\n",
      "reading myc\n",
      "reading rora\n",
      "reading nr4a2\n",
      "readingreading nr2f1\n",
      " bhlha15\n",
      "reading rel\n",
      "reading mzf1var\n",
      "finished reading gmeb2\n",
      "reading srebpf\n",
      "reading ctcf\n",
      "reading rar\n",
      "reading pknox_tgif\n",
      "reading tcf21\n",
      "reading stat1-3\n",
      "finished reading cux\n",
      "reading spi1-c\n",
      "reading rargvar\n",
      "reading yy1\n",
      "reading gcm\n",
      "reading hnf4g\n",
      "reading meis\n",
      "reading spib\n",
      "reading esr2\n",
      "reading usf\n",
      "reading insm1\n",
      "reading nr5a2\n",
      "reading ebf1\n",
      "reading nfi\n",
      "reading spz1\n",
      "reading rest\n",
      "reading rar_rxr\n",
      "reading myb\n",
      "reading zic\n",
      "reading tcf7\n",
      "finished reading homeobox-2\n",
      "reading msc_myf6_tfap4\n",
      "reading sox2\n",
      "finished reading hnf1\n",
      "finished reading e2f2\n",
      "reading zbtb7\n",
      "reading znf143\n",
      "finished reading crem\n",
      "reading tfap1\n",
      "reading glis\n",
      "finished reading arid5a\n",
      "reading nkx2-5var\n",
      "finished reading tcfl5\n",
      "finished reading dbp_hlf_tef\n",
      "finished reading pax3_pax7\n",
      "reading figla_id4_snai2_tcf3_tcf4\n",
      "finished reading arid3a\n",
      "finished reading alx1_alx4_arx\n",
      "finished reading homeobox-1\n",
      "finished reading lhx3\n",
      "finished reading arid3b\n",
      "finished reading e2f1\n",
      "reading znf423\n",
      "readingreading ascl2_nhlh1\n",
      " zeb1\n",
      "finished reading zbed1\n",
      "reading irf1\n",
      "reading znf354c\n",
      "finished reading gsc\n",
      "finished reading ventx\n",
      "finished reading homeobox-4\n",
      "readingreading zbtb18\n",
      "reading myog_tcf12\n",
      " thap1\n",
      "finished reading mef2a-b-d\n",
      "reading sp4\n",
      "finished reading mybl1\n",
      "finished reading cebp\n",
      "reading zfx\n",
      "finished reading mybl2\n",
      "reading mzf1\n",
      "finished reading homeobox-3\n",
      "finished reading hoxd8\n",
      "finished reading creb3-l1\n",
      "finished reading nfil3\n",
      "finished reading lin54\n",
      "finished reading hoxc13\n",
      "reading sox10\n",
      "finished reading hoxb5_hoxd3\n",
      "reading tfap2-3\n",
      "finished reading atf7_batf3_creb5\n",
      "finished reading hoxa11\n",
      "finished reading cenpb\n",
      "reading klf\n",
      "finished reading nkx2-5\n",
      "finished reading duxa\n",
      "finished reading phox2_prop\n",
      "finished reading pou4\n",
      "finished reading fox\n",
      "finished reading hoxa5\n",
      "reading runx\n",
      "finished reading dmbx1\n",
      "finished reading grhl1\n",
      "finished reading pou2-3-5\n",
      "reading nr2_rxr\n",
      "finished reading zbtb33\n",
      "finished reading ap-1\n",
      "finished reading id2_mlxip\n",
      "finished reading dmrt3\n",
      "finished reading hes\n",
      "finished reading irf2\n",
      "finished reading homeobox-5\n",
      "finished reading hoxc9\n",
      "reading plag1\n",
      "reading prdm1\n",
      "reading sox3_sox6\n",
      "finished reading arntl_mitf\n",
      "finished reading arnt_mycn\n",
      "finished reading pou6f2\n",
      "finished reading pax2\n",
      "finished reading cdx\n",
      "finished reading bhlhe23\n",
      "finished reading sox5_sox9_sry\n",
      "finished reading ebox\n",
      "finished reading xbp1\n",
      "finished reading hsf\n",
      "finished reading gfi1\n",
      "finished reading nrf1\n",
      "finished reading pou1f1\n",
      "finished reading smad3\n",
      "finished reading tfcp2\n",
      "finished reading tbp\n",
      "finished reading prox1\n",
      "reading pparg_rxra\n",
      "finished reading dux4\n",
      "finished reading tead\n",
      "finished reading esrr\n",
      "finished reading dux\n",
      "finished reading t\n",
      "finished reading nr2e3\n",
      "finished reading onecut\n",
      "finished reading egr\n",
      "finished reading nfat\n",
      "finished reading bhlha15\n",
      "finished reading hoxa9\n",
      "finished reading sox17\n",
      "finished reading mafg\n",
      "finished reading hnf4a\n",
      "finished reading isl2_nkx3-1_nkx3-2\n",
      "finished reading six3\n",
      "finished reading rel\n",
      "finished reading maf_nrl\n",
      "finished reading gata\n",
      "finished reading mtf1\n",
      "finished reading tp63\n",
      "finished reading hinfp\n",
      "finished reading bhlh\n",
      "finished reading rhox11\n",
      "finished reading nr2e1\n",
      "finished reading e2f7\n",
      "finished reading rora\n",
      "finished reading srebpf\n",
      "finished reading bcl6\n",
      "finished reading roravar\n",
      "finished reading hic\n",
      "finished reading srf\n",
      "finished reading nfya\n",
      "finished reading hltf\n",
      "finished reading mga_tbx\n",
      "finished reading pax6\n",
      "finished reading rxravdr\n",
      "reading rreb1\n",
      "finished reading e2f8\n",
      "finished reading elk_etv\n",
      "finished reading bcl6b\n",
      "finished reading gfi1b\n",
      "finished reading irf7-8-9\n",
      "finished reading pax1_pax9\n",
      "reading sp1\n",
      "finished reading ar_nr3c1_nr3c2\n",
      "finished reading mef2c\n",
      "reading ewsr1-fli1\n",
      "finished reading lef1\n",
      "finished reading nkx2-3_nkx2-8\n",
      "finished reading stat1-3\n",
      "finished reading nr4a2\n",
      "finished reading rfx\n",
      "finished reading esr1\n",
      "finished reading elf\n",
      "reading znf740\n",
      "finished reading znf410\n",
      "finished reading pbx1\n",
      "finished reading nfi\n",
      "finished reading spib\n",
      "finished reading nfyb\n",
      "finished reading mecom\n",
      "finished reading meis\n",
      "finished reading myc\n",
      "finished reading e2f4_e2f6\n",
      "finished reading msc_myf6_tfap4\n",
      "finished reading scrt\n",
      "finished reading tbx\n",
      "finished reading nfkb\n",
      "finished reading yy2\n",
      "finished reading myb\n",
      "finished reading mzf1var\n",
      "finished reading gli2\n",
      "finished reading pknox_tgif\n",
      "finished reading sox2\n",
      "finished reading usf\n",
      "finished reading sox8\n",
      "finished reading nr5a2\n",
      "finished reading sox1-l1-21-4\n",
      "finished reading tp53\n",
      "finished reading yy1\n",
      "finished reading tp73\n",
      "finished reading tfap1\n",
      "finished reading ebf1\n",
      "finished reading nr2f1\n",
      "finished reading zeb1\n",
      "finished reading ctcf\n",
      "finished reading spz1\n",
      "finished reading rargvar\n",
      "finished reading thap1\n",
      "finished reading gcm\n",
      "finished reading irf1\n",
      "finished reading stat6\n",
      "finished reading tcf21\n",
      "finished reading pparg\n",
      "finished reading insm1\n",
      "finished reading zic\n",
      "finished reading znf354c\n",
      "finished reading pax5\n",
      "finished reading zbtb7\n",
      "finished reading spi1-c\n",
      "finished reading figla_id4_snai2_tcf3_tcf4\n",
      "finished reading rar\n",
      "finished reading zbtb18\n",
      "finished reading tcf7\n",
      "finished reading rest\n",
      "finished reading esr2\n",
      "finished reading glis\n",
      "finished reading ascl2_nhlh1\n",
      "finished reading hnf4g\n",
      "finished reading sox10\n",
      "finished reading rar_rxr\n",
      "finished reading nkx2-5var\n",
      "finished reading znf143\n",
      "finished reading sp4\n",
      "finished reading sox3_sox6\n",
      "finished reading mzf1\n",
      "finished reading runx\n",
      "finished reading tfap2-3\n",
      "finished reading klf\n",
      "finished reading myog_tcf12\n",
      "finished reading znf423\n",
      "reading znf263\n",
      "finished reading zfx\n",
      "finished reading prdm1\n",
      "finished reading plag1\n",
      "finished reading nr2_rxr\n",
      "finished reading pparg_rxra\n",
      "finished reading znf740\n",
      "finished reading rreb1\n",
      "finished reading sp1\n",
      "finished reading ewsr1-fli1\n",
      "finished reading znf263\n",
      "total time 3264.927617788315\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fimo_result_path = './fimo_results/'\n",
    "for fastaFile in os.listdir('./peak_sequences/'):\n",
    "    if not 'marge' in fastaFile:\n",
    "        print(fastaFile)\n",
    "        strain = fastaFile.split('.')[0]\n",
    "\n",
    "        motif_score_dict = {}\n",
    "        motif_sequence_dict ={}\n",
    "        motif_strand_dict = {}\n",
    "        motif_start_dict = {}\n",
    "        motif_end_dict = {}\n",
    "        motif_count_dict = {}\n",
    "        thread_list = []\n",
    "        all_peak_ids = summary_background_frame.index.values\n",
    "        lock = threading.Lock()\n",
    "        for m in sorted(os.listdir('./fimo_results')):\n",
    "            try:\n",
    "                current_thread = threading.Thread(target = read_fimo_file,\n",
    "                                 args =(lock,\n",
    "                                        fimo_result_path + '/' + m, \n",
    "                                        all_peak_ids,\n",
    "                                        motif_score_dict,\n",
    "                                        motif_sequence_dict,\n",
    "                                        motif_strand_dict,\n",
    "                                        motif_start_dict,\n",
    "                                        motif_end_dict,\n",
    "                                        motif_count_dict,\n",
    "                                        ))\n",
    "                thread_list.append(current_thread)\n",
    "                current_thread.start()\n",
    "            finally:\n",
    "                if lock.locked_lock():\n",
    "                    lock.release()\n",
    "        for current_thread in thread_list:\n",
    "            current_thread.join()\n",
    "\n",
    "        # convert dictionaries to data frames\n",
    "        motif_score_background_frame = pd.DataFrame(motif_score_dict , index = summary_background_frame['ID'].values)\n",
    "        motif_sequence_background_frame = pd.DataFrame(motif_sequence_dict , index = summary_background_frame['ID'].values)\n",
    "        motif_strand_background_frame = pd.DataFrame(motif_strand_dict , index = summary_background_frame['ID'].values)\n",
    "        motif_start_background_frame = pd.DataFrame(motif_start_dict , index = summary_background_frame['ID'].values)\n",
    "        motif_end_background_frame = pd.DataFrame(motif_end_dict , index = summary_background_frame['ID'].values)\n",
    "        motif_count_background_frame = pd.DataFrame(motif_count_dict , index = summary_background_frame['ID'].values)\n",
    "\n",
    "        for frame in [motif_score_background_frame, \n",
    "                      motif_sequence_background_frame, \n",
    "                      motif_strand_background_frame, \n",
    "                      motif_start_background_frame, \n",
    "                      motif_end_background_frame, \n",
    "                      motif_count_background_frame]:\n",
    "            motif_cols = frame.columns.values\n",
    "            frame['ID'] = summary_background_frame['ID'].values\n",
    "            frame['Factors'] = summary_background_frame['Factors'].values\n",
    "            frame['chr'] = summary_background_frame['chr'].values\n",
    "\n",
    "        motif_score_background_frame.to_pickle('motif_score_background_frame_'+  strain + '.pickle3')\n",
    "\n",
    "        motif_sequence_background_frame.to_pickle('motif_sequence_background_frame_'+  strain + '.pickle3')\n",
    "\n",
    "        motif_strand_background_frame.to_pickle('motif_strand_background_frame_'+  strain + '.pickle3')\n",
    "\n",
    "        motif_start_background_frame.to_pickle('motif_start_background_frame_'+  strain + '.pickle3')\n",
    "\n",
    "        motif_end_background_frame.to_pickle('motif_end_background_frame_'+  strain + '.pickle3')\n",
    "\n",
    "        motif_count_background_frame.to_pickle('motif_count_background_frame_'+  strain + '.pickle3')\n",
    "\n",
    "end = time.time()\n",
    "print('total time', end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
