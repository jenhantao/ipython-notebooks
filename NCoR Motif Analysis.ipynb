{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-binding Motif Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### header ###\n",
    "__author__ = \"Jenhan Tao\"\n",
    "__license__ = \"BSD\"\n",
    "__email__ = \"jenhantao@gmail.com\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "### imports ###\n",
    "import sys\n",
    "%matplotlib inline\n",
    "sys.path.append(\"/home/jenhan/code/seq_merge_pipe/\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib\n",
    "import itertools\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import scipy\n",
    "matplotlib.pylab.rcParams['savefig.dpi'] = 200\n",
    "sys.setrecursionlimit(3000)\n",
    "os.chdir('/home/jenhan/analysis/ncor_analysis/')\n",
    "import pickle\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Score Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert motif files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create group summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create group summary file\n",
    "!bash /home/jenhan/code/seq_merge_pipe/makeSummaryFile.sh /home/jenhan/analysis/ncor_analysis/peak_files/* > /home/jenhan/analysis/ncor_analysis/output/group_summary.tsv\n",
    "! cp merged.tsv /home/jenhan/analysis/ncor_analysis/group/merged_peaks.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve sequences under peaks for finding motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# get sequences to scan for motifsx`\n",
    "!/home/jenhan/code/motif_tools/getTargetSequencesWrapper.sh /home/jenhan/analysis/ncor_analysis/group/ /home/jenhan/analysis/ncor_analysis/group 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate with GRO-seq, H3K27Ac, and PolII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!annotatePeaks.pl /home/jenhan/analysis/ncor_analysis/group/merged_peaks.tsv mm10 -size 1000 -d /data/mm10/ThioMac/ChIP/PolII/Thio-C57BL6-siCtl-PolII-KLA-Josh /data/mm10/ThioMac/ChIP/PolII/Thio-C57BL6-siCtl-PolII-Veh-Josh /data/mm10/ThioMac/ChIP/PolII/WT-ThioMac-PolII-KLA-Josh /data/mm10/ThioMac/ChIP/PolII/WT-ThioMac-PolII-Veh-Josh /data/mm10/ThioMac/ChIP/H3K27Ac/C57BL6-Thio-H3K27Ac-KLA-1h-CR-12-07-06 /data/mm10/ThioMac/ChIP/H3K27Ac/C57BL6-Thio-H3K27Ac-notx-CR-12-07-06 /data/mm10/ThioMac/GRO/ThioMac-GroSeq-notx-1h_NJS_10-08-13 /data/mm10/ThioMac/GRO/ThioMac-GroSeq-notx-1h_NJS_10-09-01 /data/mm10/ThioMac/GRO/ThioMac-GroSeq-KLA-1h_NJS_10-08-13 /data/mm10/ThioMac/GRO/ThioMac-GroSeq-KLA-1h_NJS_10-09-01 > merged_annotated_peaks.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan for motifs using FIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a script to scan for motifs using FIMO\n",
    "! if [ ! -d /home/jenhan/analysis/cobinding_motif_analysis/fimo_out/ ]; then mkdir /home/jenhan/analysis/cobinding_motif_analysis/fimo_out/; fi\n",
    "pthresh = 0.01\n",
    "motif_dir = '/home/jenhan/analysis/ncor_analysis/fimo_motifs/'\n",
    "\n",
    "fimo_results_dir = '/home/jenhan/analysis/ncor_analysis/fimo_results'\n",
    "p='/home/jenhan/analysis/ncor_analysis/group/merged.fa'\n",
    "count = 0\n",
    "scriptFile = open('scanMotifs.sh','w')\n",
    "for m in os.listdir(motif_dir):\n",
    "    if 'fimo' in m:\n",
    "        fimo_out_dir = '/home/jenhan/analysis/ncor_analysis/fimo_out/' + m.replace('.fimo','')\n",
    "        outPath = fimo_results_dir + '/merged_'+ m.replace('.fimo','') +'.txt'\n",
    "        scriptFile.write(\n",
    "            '(sleep ' + str(30 * 0) + \n",
    "            's; fimo --max-stored-scores 2000000 --output-pthresh ' + \n",
    "            str(pthresh) +' --oc ' + fimo_out_dir + ' ' +\n",
    "            motif_dir + '/' + m + ' /home/jenhan/analysis/ncor_analysis/group/merged.fa; '+\n",
    "            'mv ' + fimo_out_dir + '/fimo.txt ' + \n",
    "            outPath + ' ) & \\n')\n",
    "        count+=1\n",
    "scriptFile.close()\n",
    "\n",
    "!bash scanMotifs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Score Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Peak scores as floating point and boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in peak data data\n",
    "summary_frame = pd.read_csv('/home/jenhan/analysis/ncor_analysis/output/group_summary.tsv' , sep='\\t')\n",
    "summary_frame = summary_frame.fillna('0')\n",
    "for col in summary_frame.columns[4:]:\n",
    "    floatValues = []\n",
    "    for val in summary_frame[col].values.astype(str):\n",
    "        if ',' in val:\n",
    "            maxVal = np.max([float(x) for x in val.split(',')])\n",
    "            floatValues.append(maxVal)\n",
    "        else:\n",
    "            floatValues.append(float(val))\n",
    "    summary_frame[col] = floatValues\n",
    "    \n",
    "summary_frame['chr'] = [x.split(':')[0] for x in summary_frame['Position'].values]\n",
    "summary_frame['numFactors'] = [len(x.split(',')) for x in summary_frame['Factors'].values]\n",
    "\n",
    "# drop every peak that appears in the NCoR knockout\n",
    "summary_frame = summary_frame[~summary_frame['Factors'].str.contains('ncor-ko')]\n",
    "\n",
    "summary_frame.index = summary_frame['ID'].values\n",
    "newCols = list(summary_frame.columns.values)[:4] + ['chr', 'numFactors'] + list(summary_frame.columns.values)[4:-2]\n",
    "newCols = [x for x in newCols if not 'ncor-ko' in x]\n",
    "summary_frame = summary_frame[newCols]\n",
    "\n",
    "\n",
    "\n",
    "del summary_frame['Group Number']\n",
    "del summary_frame['numFactors']\n",
    "\n",
    "bool_frame = summary_frame.copy()\n",
    "bool_frame.index = summary_frame.index\n",
    "del bool_frame['Position']\n",
    "del bool_frame['chr']\n",
    "del bool_frame['Factors']\n",
    "del bool_frame['ID']\n",
    "\n",
    "\n",
    "\n",
    "bool_frame['chr'] =summary_frame['chr']\n",
    "bool_frame = bool_frame[['chr'] + list(bool_frame.columns.values[:-1])]\n",
    "\n",
    "\n",
    "kla_cols= ['chr']\n",
    "notx_cols = ['chr']\n",
    "for col in bool_frame.columns:\n",
    "    if 'kla' in col:\n",
    "        kla_cols.append(col)\n",
    "    elif 'notx' in col:\n",
    "        notx_cols.append(col)\n",
    "        \n",
    "bool_frame_kla = bool_frame[kla_cols]\n",
    "bool_frame_kla = bool_frame_kla[bool_frame_kla.sum(axis=1)>0]\n",
    "\n",
    "bool_frame_notx = bool_frame[notx_cols]\n",
    "bool_frame_notx = bool_frame_notx[bool_frame_notx.sum(axis=1)>0]\n",
    "\n",
    "bool_frame.to_pickle('bool_frame.pickle')\n",
    "\n",
    "\n",
    "factors = sorted(list(set([x.split('_')[0] for x in bool_frame.columns if '_' in x])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in GRO, PolII, and H3K27Ac scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in GRO, PolII, and H3K27Ac scores\n",
    "data_frame = pd.read_csv('merged_annotated_peaks.tsv', sep='\\t')\n",
    "data_frame.index=data_frame.ix[:,0].values\n",
    "columns = data_frame.columns.values\n",
    "columns[0] = 'ID'\n",
    "columns = [x.split('/')[-1].split()[0] if '/' in x else x for x in columns]\n",
    "data_frame.columns = columns\n",
    "data_frame['PolII-KLA'] = np.mean(data_frame[['Thio-C57BL6-siCtl-PolII-KLA-Josh', \n",
    "                                               'WT-ThioMac-PolII-KLA-Josh']], axis=1)\n",
    "data_frame['PolII-notx'] = np.mean(data_frame[['Thio-C57BL6-siCtl-PolII-Veh-Josh', \n",
    "                                               'WT-ThioMac-PolII-Veh-Josh']], axis=1)\n",
    "data_frame['H3K27Ac-KLA'] = np.mean(data_frame[['C57BL6-Thio-H3K27Ac-KLA-1h-CR-12-07-06', \n",
    "                                               'C57BL6-Thio-H3K27Ac-KLA-1h-CR-12-07-06']], axis=1)\n",
    "data_frame['H3K27Ac-notx'] = np.mean(data_frame[['C57BL6-Thio-H3K27Ac-notx-CR-12-07-06', \n",
    "                                               'C57BL6-Thio-H3K27Ac-notx-CR-12-07-06']], axis=1)\n",
    "data_frame['Gro-KLA'] = np.mean(data_frame[['ThioMac-GroSeq-KLA-1h_NJS_10-08-13', \n",
    "                                               'ThioMac-GroSeq-KLA-1h_NJS_10-09-01']], axis=1)\n",
    "data_frame['Gro-notx'] = np.mean(data_frame[['ThioMac-GroSeq-notx-1h_NJS_10-08-13', \n",
    "                                               'ThioMac-GroSeq-notx-1h_NJS_10-09-01']], axis=1)\n",
    "data_frame = data_frame[['ID'] + list(data_frame.columns.values[-6:])]\n",
    "summary_frame = summary_frame.merge(data_frame, on='ID')\n",
    "summary_frame.index = summary_frame['ID'].values\n",
    "\n",
    "\n",
    "# remove outlier GRO-seq values\n",
    "summary_frame.loc[summary_frame['Gro-notx'] > 10000, 'Gro-notx' ] = 0\n",
    "summary_frame.loc[summary_frame['Gro-KLA'] > 10000, 'Gro-KLA' ] = 0\n",
    "summary_frame.to_pickle('summary_frame.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Peak Genomic Annotations as Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('merged_annotated_peaks.tsv', sep='\\t')\n",
    "data['Annotation'] = [x.split()[0] for x in data['Annotation'].values]\n",
    "annotationTypes = set(data['Annotation'].values)\n",
    "id_annotation_dict = dict(zip(data.ix[:,0].values, data['Annotation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in motif scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "motif_dir = '/home/jenhan/analysis/ncor_analysis/fimo_motifs/'\n",
    "merged_motif_frame = summary_frame[['ID', 'Factors', 'chr']]\n",
    "merged_motif_frame.index=merged_motif_frame['ID'].values\n",
    "for m in os.listdir(motif_dir):\n",
    "    if '.fimo' in m:\n",
    "        motif_results = './fimo_results/merged_' + m.replace('.fimo','') +'.txt'\n",
    "        fimo_result_frame=pd.read_csv(motif_results, sep='\\t')\n",
    "        motif_name = m.replace('.fimo','')\n",
    "        id_score_dict = {}\n",
    "        ids = fimo_result_frame['sequence name'].values\n",
    "        scores = fimo_result_frame['score'].values\n",
    "        for i in range(len(ids)):\n",
    "            if ids[i] in id_score_dict:\n",
    "                if scores[i] > id_score_dict[ids[i]]:\n",
    "                    id_score_dict[ids[i]] = scores[i]\n",
    "            else:\n",
    "                id_score_dict[ids[i]] = scores[i]\n",
    "        merged_motif_frame[motif_name] = [id_score_dict[x] if x in id_score_dict else 0 for x in merged_motif_frame['ID'].values]\n",
    "\n",
    "# only keep rows where the ID appears in summary_frame\n",
    "merged_motif_frame = merged_motif_frame[merged_motif_frame['ID'].isin(summary_frame['ID'])]\n",
    "\n",
    "# save merged_motif_frame to a pickle\n",
    "merged_motif_frame.to_pickle('motif_frame.pickle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of motif scores peak scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Distributions of peak and motif scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_motif_frame=pd.read_pickle('motif_frame.pickle')\n",
    "summary_frame = pd.read_pickle('summary_frame.pickle')\n",
    "\n",
    "# plot motif positions to make sure that nothing went wrong with the merging\n",
    "positions = [x.split(':')[1] for x in summary_frame['Position'].values]\n",
    "sizes = [int(x.split('-')[1]) - int(x.split('-')[0]) for x in positions]\n",
    "plt.hist(sizes, bins = 20);\n",
    "plt.xlabel('Merged Region Size')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Peak Sizes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot distribution of motif scores\n",
    "sns.set_context('talk', font_scale=0.3)\n",
    "data_dict = {}\n",
    "count = 0\n",
    "sort_list = []\n",
    "for col in merged_motif_frame.columns[3:]:\n",
    "    data_dict[col] = merged_motif_frame[col].values\n",
    "    sort_list.append((col, np.mean(merged_motif_frame[col].values)))\n",
    "sort_list = sorted(sort_list,key=lambda x:x[1])\n",
    "order = [x[0] for x in sort_list]\n",
    "sns.boxplot(pd.DataFrame(data_dict), \n",
    "            fliersize = 1.0,linewidth=1.0,\n",
    "            order = order)\n",
    "plt.xticks(rotation=90)\n",
    "# plt.xticks([])\n",
    "plt.xlabel(\"Motif\")\n",
    "plt.ylabel(\"Log Odds Motif Score\")\n",
    "plt.title(\"Distribution of FIMO Scores for Motifs Appearing in Peaks\")\n",
    "plt.savefig('motifScore_boxplot.pdf')\n",
    "del data_dict\n",
    "sns.set_context('talk', font_scale=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numColors = 16\n",
    "colorDict = dict(zip(range(numColors),sns.color_palette(\"Set1\") + sns.color_palette(\"Set2\") + sns.color_palette(\"colorblind\")))\n",
    "# co clustering on peak scores\n",
    "numRowClusters = 6\n",
    "numColClusters = 4\n",
    "\n",
    "for chrom in sorted(list(set(summary_frame['chr'].values))):\n",
    "    if not \"Un\" in chrom and not \"random\" in chrom:\n",
    "        currentPeakData = summary_frame[summary_frame['chr']== chrom].ix[:,3:]\n",
    "        currentMotifData = merged_motif_frame[merged_motif_frame['chr']== chrom].ix[:,3:]\n",
    "\n",
    "        if currentPeakData.shape[0]> 2 and currentMotifData.shape[0] > 2:\n",
    "            print('merged_' +chrom + ' (' + str(currentPeakData.shape[0]) + ' peaks)')\n",
    "\n",
    "            cg = sns.clustermap(np.log2(currentPeakData+0.0000001), yticklabels=False, cmap='Blues')\n",
    "            plt.close()\n",
    "            reordered_indices = cg.dendrogram_row.reordered_ind\n",
    "            row_linkage = cg.dendrogram_row.linkage\n",
    "            col_linkage = cg.dendrogram_col.linkage\n",
    "            \n",
    "            row_flatCluster = scipy.cluster.hierarchy.fcluster(row_linkage, numRowClusters, criterion=\"maxclust\")\n",
    "            col_flatCluster = scipy.cluster.hierarchy.fcluster(col_linkage, numColClusters, criterion=\"maxclust\")\n",
    "            \n",
    "            row_colors = [colorDict[row_flatCluster[i] -1] for i in range(len(currentPeakData.index))]\n",
    "            col_colors = [colorDict[col_flatCluster[i] -1] for i in range(len(currentPeakData.columns))]\n",
    "            sns.clustermap(np.log2(currentPeakData+0.0000001), \n",
    "                         row_linkage = row_linkage,\n",
    "                         col_linkage = col_linkage,\n",
    "                         row_colors = row_colors,\n",
    "                         cmap=\"Blues\",\n",
    "                         yticklabels = False\n",
    "                         )\n",
    "            plt.title('merged_peakScores_coclustered_' +chrom + ' (' + str(currentPeakData.shape[0]) + ' peaks)')\n",
    "            plt.savefig('merged_peakScores_coclustered_' + chrom +'_clustermap.png')\n",
    "            plt.close()\n",
    "            \n",
    "#             sns.clustermap(currentMotifData, \n",
    "#                          row_linkage = row_linkage,\n",
    "#                          row_colors = row_colors,\n",
    "#                          cmap=\"Greens\",\n",
    "#                          yticklabels = False,\n",
    "#                          xticklabels = False\n",
    "#                          )\n",
    "#             plt.title('merged_motif_peakScoreCoclustered_' +chrom + ' (' + str(currentMotifData.shape[0]) + ' peaks)')\n",
    "#             plt.savefig('merged_motif_peakScoreCoclustered_' + chrom +'_clustermap.png')\n",
    "#             plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding significant motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find significant motifs with significantly different scores depending on binding or no binding of a factor in notx conditions\n",
    "#\n",
    "# use the following tests:\n",
    "# t-test\n",
    "# mann-whitney u-test\n",
    "# Kolmogorov–Smirnov test\n",
    "p_threshold = 0.01\n",
    "\n",
    "ttest_dict = {x:[] for x in summary_frame.columns[4:-6]}\n",
    "mannwhitney_dict = {x:[] for x in summary_frame.columns[4:-6]}\n",
    "ks_dict = {x:[] for x in summary_frame.columns[4:-6]}\n",
    "for f in summary_frame.columns[4:-6]:\n",
    "    print(f)\n",
    "    binding_positions = (summary_frame[f] > 0).values\n",
    "    null_positions = (summary_frame[f] == 0).values\n",
    "    \n",
    "    current_ttest = ttest_dict[f]\n",
    "    current_mwu = mannwhitney_dict[f]\n",
    "    current_ks = ks_dict[f]\n",
    "    \n",
    "    for col in merged_motif_frame.columns[3:]:\n",
    "\n",
    "        binding_scores = merged_motif_frame[col][binding_positions].values\n",
    "        null_scores = merged_motif_frame[col][null_positions].values       \n",
    "\n",
    "        ttest_val, ttest_pval = scipy.stats.ttest_ind(binding_scores,null_scores,equal_var=False)\n",
    "        mwu_stat, mwu_pval = scipy.stats.mannwhitneyu(binding_scores, null_scores)\n",
    "        D, ks_pval = scipy.stats.ks_2samp(binding_scores,null_scores)\n",
    "        \n",
    "        current_ttest.append(ttest_pval)\n",
    "        current_mwu.append(mwu_pval/2.0) # correct for one tailed test\n",
    "        current_ks.append(ks_pval)\n",
    "\n",
    "# convert dictionaries to data frames for plotting\n",
    "ttest_frame = pd.DataFrame(ttest_dict)\n",
    "ttest_frame = ttest_frame.fillna(1)\n",
    "ttest_frame.index = merged_motif_frame.columns[3:]\n",
    "\n",
    "mannwhitney_frame = pd.DataFrame(mannwhitney_dict)\n",
    "mannwhitney_frame =mannwhitney_frame.fillna(1)\n",
    "mannwhitney_frame.index = merged_motif_frame.columns[3:]\n",
    "\n",
    "ks_frame = pd.DataFrame(ks_dict)\n",
    "ks_frame = ks_frame.fillna(1)\n",
    "ks_frame.index = merged_motif_frame.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk',font_scale=0.3)\n",
    "sns.clustermap(-1* np.log10(ttest_frame+0.0000001), cmap='Blues', col_cluster=False)\n",
    "plt.savefig('ttest.pdf')\n",
    "sns.set_context('talk',font_scale=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the correlation between motif scores and peak scores\n",
    "factorTreatments = summary_frame.columns[4:-6].values\n",
    "motifs = merged_motif_frame.columns[4:-6].values\n",
    "pearson_matrix = np.zeros((len(factorTreatments), len(motifs)))\n",
    "spearman_matrix = np.zeros((len(factorTreatments), len(motifs)))\n",
    "for i in range(len(factorTreatments)):\n",
    "    ft = factorTreatments[i]\n",
    "    print(ft)\n",
    "    for j in range(len(motifs)):\n",
    "        m = motifs[j]\n",
    "        peak_scores = summary_frame[ft].values\n",
    "        motif_scores = merged_motif_frame[m].values\n",
    "        pearson,  pearson_p_val= scipy.stats.pearsonr(peak_scores, motif_scores)\n",
    "        spearman, spearman_p_val = scipy.stats.spearmanr(peak_scores, motif_scores)\n",
    "        pearson_matrix[i][j] = pearson\n",
    "        spearman_matrix[i][j] = spearman\n",
    "\n",
    "spearman_frame = pd.DataFrame(spearman_matrix)\n",
    "spearman_frame.index = factorTreatments\n",
    "spearman_frame.columns = motifs\n",
    "\n",
    "pearson_frame = pd.DataFrame(spearman_matrix)\n",
    "pearson_frame.index = factorTreatments\n",
    "pearson_frame.columns = motifs\n",
    "\n",
    "# fill in missing values\n",
    "# pearson_frame = pearson_frame.fillna(0)\n",
    "# spearman_frame = spearman_frame.fillna(0)\n",
    "sns.set_context('talk',font_scale=0.3)\n",
    "sns.clustermap(spearman_frame)\n",
    "plt.savefig('spearman_motifScore_peakScore.pdf')\n",
    "sns.set_context('talk',font_scale=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show how motif scores correlate to one another\n",
    "# plot distribution of motif scores\n",
    "data_dict = {}\n",
    "count = 0\n",
    "sort_list = []\n",
    "motifs = merged_motif_frame.columns[3:]\n",
    "motif_corr_pearson_matrix = np.zeros((len(motifs), len(motifs)))\n",
    "motif_corr_spearman_matrix = np.zeros((len(motifs), len(motifs)))\n",
    "# for every pair of motifs\n",
    "for i in range(len(motifs) -1 ):\n",
    "    for j in range(i+1, len(motifs)):\n",
    "        motif1 = motifs[i]\n",
    "        motif2 = motifs[j]\n",
    "        # get relevant motif scores\n",
    "        motifScores1 = merged_motif_frame[motif1].values\n",
    "        motifScores2 = merged_motif_frame[motif2].values\n",
    "        # calculate spearman and peason correlation\n",
    "        r, p_val_pearson = scipy.stats.pearsonr(motifScores1, motifScores2)\n",
    "        rho, p_val_spearman = scipy.stats.spearmanr(motifScores1, motifScores2)\n",
    "        # fill in position in matrix\n",
    "        motif_corr_pearson_matrix[i][j] = r\n",
    "        motif_corr_spearman_matrix[i][j] = rho\n",
    "\n",
    "# create data frames\n",
    "motif_corr_pearson_frame = pd.DataFrame(motif_corr_pearson_matrix)\n",
    "motif_corr_spearman_frame = pd.DataFrame(motif_corr_spearman_matrix)\n",
    "\n",
    "motif_corr_pearson_frame = motif_corr_pearson_frame.fillna(0)\n",
    "motif_corr_pearson_frame.columns = motifs\n",
    "motif_corr_pearson_frame.index = motifs\n",
    "\n",
    "motif_corr_spearman_frame = motif_corr_spearman_frame.fillna(0)\n",
    "motif_corr_spearman_frame.columns = motifs\n",
    "motif_corr_spearman_frame.index = motifs\n",
    "\n",
    "sns.heatmap(motif_corr_pearson_frame,xticklabels = False, yticklabels = False)\n",
    "plt.title('Motif Pearson Correlation')\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(motif_corr_spearman_frame,xticklabels = False, yticklabels = False)\n",
    "plt.title('Motif Spearman Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Annotations of NCoR Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_frame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('notebook',font_scale=1.0)\n",
    "\n",
    "plt.axis('equal')\n",
    "\n",
    "# for notx only peaks\n",
    "labels = []\n",
    "counts =  []\n",
    "notx_ids = summary_frame[(summary_frame['ncor_notx'] > 0) & (summary_frame['ncor_kla'] == 0)]['ID'].values\n",
    "annotations = [id_annotation_dict[x] for x in notx_ids]\n",
    "for ann in annotationTypes:\n",
    "    labels.append(ann)\n",
    "    counts.append(annotations.count(ann))\n",
    "plt.pie(counts, labels = labels);\n",
    "plt.title('NCoR notx Annotation')\n",
    "plt.show()\n",
    "\n",
    "# for KLA only peaks\n",
    "plt.axis('equal')\n",
    "labels = []\n",
    "counts =  []\n",
    "kla_ids = summary_frame[(summary_frame['ncor_notx'] == 0) & (summary_frame['ncor_kla'] > 0)]['ID'].values\n",
    "annotations = [id_annotation_dict[x] for x in kla_ids]\n",
    "for ann in annotationTypes:\n",
    "    labels.append(ann)\n",
    "    counts.append(annotations.count(ann))\n",
    "plt.pie(counts, labels = labels);\n",
    "plt.title('NCoR KLA Annotation')\n",
    "plt.show()\n",
    "\n",
    "# for shared peaks\n",
    "plt.axis('equal')\n",
    "labels = []\n",
    "counts =  []\n",
    "shared_ids = summary_frame[(summary_frame['ncor_notx'] > 0) & (summary_frame['ncor_kla'] > 0)]['ID'].values\n",
    "annotations = [id_annotation_dict[x] for x in shared_ids]\n",
    "for ann in annotationTypes:\n",
    "    labels.append(ann)\n",
    "    counts.append(annotations.count(ann))\n",
    "plt.pie(counts, labels = labels);\n",
    "plt.title('NCoR Shared Annotation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with marks of active enhancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# factor_groups = set(summary_frame['Factors'].values)\n",
    "numColors = 16\n",
    "colorDict = dict(zip(range(numColors),sns.color_palette(\"Set1\") + sns.color_palette(\"Set2\") + sns.color_palette(\"colorblind\")))\n",
    "\n",
    "\n",
    "factor_groups =['ncor_kla',\n",
    " 'ncor_kla,ncor_notx',\n",
    " 'ncor_kla,ncor_notx,p65_kla',\n",
    " 'ncor_kla,p65_kla',\n",
    " 'ncor_notx',\n",
    " 'p65_kla',\n",
    " ]\n",
    "\n",
    "colorValues = list(colorDict.values())\n",
    "colors = []\n",
    "\n",
    "for i in range(len(factor_groups)):\n",
    "    colors.append(colorValues[i])\n",
    "    colors.append(colorValues[i])\n",
    "\n",
    "p_threshold = 0.05\n",
    "# for Pol II\n",
    "counts = []\n",
    "labels = []\n",
    "pvals = []\n",
    "\n",
    "for cluster in factor_groups:\n",
    "    cluster_name = cluster\n",
    "    ids = summary_frame[summary_frame['Factors'] == cluster_name].index.values\n",
    "    notx_values = summary_frame.ix[ids,'PolII-notx'].values\n",
    "    kla_values = summary_frame.ix[ids,'PolII-KLA'].values\n",
    "    notx_values = np.log2(notx_values +0.0000001)\n",
    "    kla_values = np.log2(kla_values +0.0000001)\n",
    "\n",
    "\n",
    "    if np.sum(notx_values) > 0 or np.sum(kla_values) > 0 :\n",
    "        labels.append(cluster_name +'    NOTX')\n",
    "        labels.append(cluster_name +'    KLA')\n",
    "        stat, p = scipy.stats.ttest_ind(notx_values,kla_values)\n",
    "        counts.append(notx_values)\n",
    "        counts.append(kla_values)\n",
    "        stat, p = scipy.stats.ttest_ind(notx_values,kla_values)\n",
    "        pvals.append(p)\n",
    "box = plt.boxplot(counts, notch=True, patch_artist=True);\n",
    "\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "# annotate plot with p_values\n",
    "ax = plt.gca()\n",
    "for i in range(len(pvals)):\n",
    "    p = pvals[i]\n",
    "    if p < p_threshold: \n",
    "        height = int(np.percentile(counts[2*i] + counts[2*i+1], 75))\n",
    "        ax.arrow(2*i+1, height, 0,-1, linewidth=1.0,head_width=0.0)\n",
    "        ax.arrow(2*i+2, height, 0,-1, linewidth=1.0,head_width=0.0)\n",
    "        ax.arrow(2*i+1,height ,1,0, linewidth=1.0,head_width=0.0)\n",
    "        ax.annotate(\"{:.3f}\".format(p).replace('0.000','<0.001'),xy=(2*i+1,height+0.1))\n",
    "    \n",
    "plt.xticks(range(1,len(labels)+1), labels, rotation =90);\n",
    "plt.ylim([0,15])\n",
    "plt.ylabel('log2 tag counts')\n",
    "plt.title('PolII Tag Counts')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# For GRO-seq\n",
    "counts = []\n",
    "labels = []\n",
    "pvals = []\n",
    "\n",
    "for cluster in factor_groups:\n",
    "    cluster_name = cluster\n",
    "    ids = summary_frame[summary_frame['Factors'] == cluster_name].index.values\n",
    "    notx_values = summary_frame.ix[ids,'Gro-notx'].values\n",
    "    kla_values = summary_frame.ix[ids,'Gro-KLA'].values\n",
    "    notx_values = np.log2(notx_values +0.0000001)\n",
    "    kla_values = np.log2(kla_values +0.0000001)\n",
    "\n",
    "    if np.sum(notx_values) > 0 or np.sum(kla_values) > 0 :\n",
    "        labels.append(cluster_name +'    NOTX')\n",
    "        labels.append(cluster_name +'    KLA')\n",
    "        stat, p = scipy.stats.ttest_ind(notx_values,kla_values)\n",
    "        counts.append(notx_values)\n",
    "        counts.append(kla_values)\n",
    "        stat, p = scipy.stats.ttest_ind(notx_values,kla_values)\n",
    "        pvals.append(p)\n",
    "box = plt.boxplot(counts, notch=True, patch_artist=True);\n",
    "\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "# annotate plot with p_values\n",
    "ax = plt.gca()\n",
    "for i in range(len(pvals)):\n",
    "    p = pvals[i]\n",
    "    if p < p_threshold: \n",
    "        height = int(np.percentile(counts[2*i] + counts[2*i+1], 90))\n",
    "        ax.arrow(2*i+1, height, 0,-1, linewidth=1.0,head_width=0.0)\n",
    "        ax.arrow(2*i+2, height, 0,-1, linewidth=1.0,head_width=0.0)\n",
    "        ax.arrow(2*i+1,height ,1,0, linewidth=1.0,head_width=0.0)\n",
    "        ax.annotate(\"{:.3f}\".format(p).replace('0.000','<0.001'),xy=(2*i+1,height+0.1))\n",
    "        \n",
    "plt.xticks(range(1,len(labels)+1), labels, rotation =90);\n",
    "plt.ylabel('log2 tag counts')\n",
    "plt.title('Gro Tag Counts')\n",
    "plt.ylim([0,15])\n",
    "plt.show()\n",
    "\n",
    "# For H3K27Ac\n",
    "counts = []\n",
    "labels = []\n",
    "pvals = []\n",
    "for cluster in factor_groups:\n",
    "    cluster_name = cluster\n",
    "    ids = summary_frame[summary_frame['Factors'] == cluster_name].index.values\n",
    "    notx_values = summary_frame.ix[ids,'H3K27Ac-notx'].values\n",
    "    kla_values = summary_frame.ix[ids,'H3K27Ac-KLA'].values\n",
    "    notx_values = np.log2(notx_values +0.0000001)\n",
    "    kla_values = np.log2(kla_values +0.0000001)\n",
    "\n",
    "    if np.sum(notx_values) > 0 or np.sum(kla_values) > 0 :\n",
    "        labels.append(cluster_name +'    NOTX')\n",
    "        labels.append(cluster_name +'    KLA')\n",
    "        stat, p = scipy.stats.ttest_ind(notx_values,kla_values)\n",
    "        counts.append(notx_values)\n",
    "        counts.append(kla_values)\n",
    "        stat, p = scipy.stats.ttest_ind(notx_values,kla_values)\n",
    "        pvals.append(p)\n",
    "box = plt.boxplot(counts, notch=True, patch_artist=True);\n",
    "\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "# annotate plot with p_values\n",
    "ax = plt.gca()\n",
    "for i in range(len(pvals)):\n",
    "    p = pvals[i]\n",
    "    if p < p_threshold: \n",
    "        height = int(np.percentile(counts[2*i] + counts[2*i+1], 50))\n",
    "        ax.arrow(2*i+1, height, 0,-1, linewidth=1.0,head_width=0.0)\n",
    "        ax.arrow(2*i+2, height, 0,-1, linewidth=1.0,head_width=0.0)\n",
    "        ax.arrow(2*i+1,height ,1,0, linewidth=1.0,head_width=0.0)\n",
    "        ax.annotate(\"{:.3f}\".format(p).replace('0.000','<0.001'),xy=(2*i+1,height+0.1))\n",
    "plt.xticks(range(1,len(labels)+1), labels, rotation =90);\n",
    "plt.ylim([0,15])\n",
    "plt.ylabel('log2 tag counts')\n",
    "plt.title('H2K27Ac Tag Counts')\n",
    "plt.ylim([0,15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# calculate the difference before and after KLA treatment\n",
    "difference_frame = summary_frame[['ID', 'chr', 'ncor_notx', 'ncor_kla']]\n",
    "difference_frame = difference_frame[difference_frame.sum(axis=1) > 0]\n",
    "difference_frame['Gro_difference'] = summary_frame['Gro-KLA'] - summary_frame['Gro-notx']\n",
    "difference_frame['PolII_difference'] = summary_frame['PolII-KLA'] - summary_frame['PolII-notx']\n",
    "difference_frame['H3K27Ac_difference'] = summary_frame['H3K27Ac-KLA'] - summary_frame['H3K27Ac-notx']\n",
    "\n",
    "# difference_frame = difference_frame[difference_frame['chr']=='chr1']\n",
    "for col in difference_frame.columns[4:]:\n",
    "    difference_frame[col] = [np.log2(x+1) if x > 0 else -1 * np.log2(-1*x +1) for x in difference_frame[col].values]\n",
    "\n",
    "notx_difference_frame = difference_frame[(difference_frame['ncor_notx'] > 0) & (difference_frame['ncor_kla'] == 0)]\n",
    "kla_difference_frame = difference_frame[(difference_frame['ncor_notx'] == 0) & (difference_frame['ncor_kla'] > 0)]\n",
    "shared_difference_frame = difference_frame[(difference_frame['ncor_notx'] > 0) & (difference_frame['ncor_kla'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### for notx peaks\n",
    "separation=50\n",
    "numRowClusters = 4\n",
    "data = notx_difference_frame.ix[:,-3:]\n",
    "\n",
    "cg_notx = sns.clustermap(data,col_cluster=False, yticklabels=False, cmap='Greys')\n",
    "plt.close()\n",
    "\n",
    "cg_pickle_file = open('cg_notx.pickle','wb')\n",
    "pickle.dump(cg_notx,cg_pickle_file)\n",
    "cg_pickle_file.close()\n",
    "\n",
    "### for KLA peaks\n",
    "data = kla_difference_frame.ix[:,-3:]\n",
    "\n",
    "cg_kla = sns.clustermap(data,col_cluster=False, yticklabels=False, cmap='Greys')\n",
    "plt.close()\n",
    "\n",
    "cg_pickle_file = open('cg_kla.pickle','wb')\n",
    "pickle.dump(cg_kla,cg_pickle_file)\n",
    "cg_pickle_file.close()\n",
    "\n",
    "### for shared peaks\n",
    "data = shared_difference_frame.ix[:,-3:]\n",
    "\n",
    "cg_shared = sns.clustermap(data,col_cluster=False, yticklabels=False, cmap='Greys')\n",
    "plt.close()\n",
    "\n",
    "cg_pickle_file = open('cg_shared.pickle','wb')\n",
    "pickle.dump(cg_shared,cg_pickle_file)\n",
    "cg_pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for notx peaks\n",
    "separation=70\n",
    "numRowClusters = 6\n",
    "data = notx_difference_frame.ix[:,-3:]\n",
    "\n",
    "cg_notx = pickle.load(open('cg_notx.pickle','rb'))\n",
    "reordered_indices = cg_notx.dendrogram_row.reordered_ind\n",
    "row_linkage = cg_notx.dendrogram_row.linkage\n",
    "row_flatCluster = scipy.cluster.hierarchy.fcluster(row_linkage, numRowClusters, criterion=\"maxclust\")\n",
    "row_colors = [colorDict[row_flatCluster[i] -1] for i in range(len(data.index))]\n",
    "sns.clustermap(data, \n",
    "             row_linkage = row_linkage,\n",
    "             col_cluster=False,\n",
    "             row_colors = row_colors,\n",
    "             yticklabels = False,\n",
    "             cmap=sns.diverging_palette(265, 10, s=90, l=40, sep=separation, as_cmap=True)\n",
    "             )\n",
    "plt.title('NCoR notx peaks')\n",
    "plt.show()\n",
    "\n",
    "# for KLA peaks\n",
    "data = kla_difference_frame.ix[:,-3:]\n",
    "\n",
    "cg_kla = pickle.load(open('cg_kla.pickle','rb'))\n",
    "\n",
    "reordered_indices = cg_kla.dendrogram_row.reordered_ind\n",
    "row_linkage = cg_kla.dendrogram_row.linkage\n",
    "row_flatCluster = scipy.cluster.hierarchy.fcluster(row_linkage, numRowClusters, criterion=\"maxclust\")\n",
    "row_colors = [colorDict[row_flatCluster[i] -1] for i in range(len(data.index))]\n",
    "\n",
    "sns.clustermap(data, \n",
    "             row_linkage = row_linkage,\n",
    "             col_cluster=False,\n",
    "             row_colors = row_colors,\n",
    "             yticklabels = False,\n",
    "             cmap=sns.diverging_palette(265, 10, s=90, l=40, sep=separation, as_cmap=True)\n",
    "             )\n",
    "plt.title('NCoR KLA peaks')\n",
    "plt.show()\n",
    "\n",
    "# for shared peaks\n",
    "data = shared_difference_frame.ix[:,-3:]\n",
    "\n",
    "cg_shared = pickle.load(open('cg_shared.pickle','rb'))\n",
    "\n",
    "reordered_indices = cg_shared.dendrogram_row.reordered_ind\n",
    "row_linkage = cg_shared.dendrogram_row.linkage\n",
    "row_flatCluster = scipy.cluster.hierarchy.fcluster(row_linkage, numRowClusters, criterion=\"maxclust\")\n",
    "row_colors = [colorDict[row_flatCluster[i] -1] for i in range(len(data.index))]\n",
    "\n",
    "sns.clustermap(data, \n",
    "             row_linkage = row_linkage,\n",
    "             col_cluster=False,\n",
    "             row_colors = row_colors,\n",
    "             yticklabels = False,\n",
    "             cmap=sns.diverging_palette(265, 10, s=90, l=40, sep=separation, as_cmap=True)\n",
    "             )\n",
    "plt.title('NCoR Shared peaks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.palplot(list(colorDict.values()))\n",
    "plt.xticks(range(0,16), range(1,17));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### score motifs for each cluster for each category of peaks ###\n",
    "\n",
    "### for notx peaks\n",
    "cg_notx = pickle.load(open('cg_notx.pickle','rb'))\n",
    "notx_difference_frame['cluster'] = scipy.cluster.hierarchy.fcluster(cg_notx.dendrogram_row.linkage, numRowClusters, criterion=\"maxclust\")\n",
    "\n",
    "# peaks that look like activators\n",
    "ids = notx_difference_frame[notx_difference_frame['cluster'] ==4]['ID'].values\n",
    "scores = merged_motif_frame.ix[ids,:]\n",
    "\n",
    "# plot distribution of motif scores\n",
    "sns.set_context('talk', font_scale=0.3)\n",
    "data_dict = {}\n",
    "count = 0\n",
    "sort_list = []\n",
    "for col in scores.columns[3:]:\n",
    "    data_dict[col] = scores[col].values\n",
    "    sort_list.append((col, np.mean(scores[col].values)))\n",
    "# sort_list = sorted(sort_list,key=lambda x:x[1])\n",
    "sort_list = sorted(sort_list,key=lambda x:x[1])\n",
    "\n",
    "order = [x[0] for x in sort_list]\n",
    "sns.boxplot(pd.DataFrame(data_dict), \n",
    "            fliersize = 1.0,linewidth=1.0,\n",
    "            order = order)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Motif\")\n",
    "plt.ylabel(\"Log Odds Motif Score\")\n",
    "plt.show()\n",
    "\n",
    "sns.clustermap(scores.ix[:,3:],yticklabels=False, xticklabels=True, row_cluster=False)\n",
    "plt.savefig('activator.pdf')\n",
    "# for peaks that look like repressors\n",
    "# ids = notx_difference_frame[notx_difference_frame['cluster'] ==6]['ID'].values\n",
    "# scores = merged_motif_frame.ix[ids,:]\n",
    "\n",
    "\n",
    "\n",
    "### for KLA peaks\n",
    "\n",
    "### for shared peaks\n",
    "sns.set_context('talk', font_scale=1.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Histograms for Marks of Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Peaks and Create Split Peak Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outDirectory = '/home/jenhan/analysis/ncor_analysis/scratch/'\n",
    "! if [ ! -d $outDirectory ]; then mkdir $outDirectory; fi\n",
    "\n",
    "sns.set_context('notebook',font_scale=1.0)\n",
    "\n",
    "\n",
    "# for notx only peaks\n",
    "notx_ids = summary_frame[(summary_frame['ncor_notx'] > 0) & (summary_frame['ncor_kla'] == 0)]['ID'].values\n",
    "# for KLA only peaks\n",
    "kla_ids = summary_frame[(summary_frame['ncor_notx'] == 0) & (summary_frame['ncor_kla'] > 0)]['ID'].values\n",
    "# for shared peaks\n",
    "shared_ids = summary_frame[(summary_frame['ncor_notx'] > 0) & (summary_frame['ncor_kla'] > 0)]['ID'].values\n",
    "# for all notx peaks\n",
    "notxAll_ids = summary_frame[summary_frame['ncor_notx'] > 0]['ID'].values\n",
    "# for all KLA peaks\n",
    "klaAll_ids = summary_frame[summary_frame['ncor_kla'] > 0]['ID'].values\n",
    "\n",
    "### subset into enhancers vs promoters\n",
    "notx_promoter_ids = [x for x in notx_ids if id_annotation_dict[x] == 'promoter-TSS']\n",
    "notx_enhancer_ids = [x for x in notx_ids if id_annotation_dict[x] != 'promoter-TSS']\n",
    "\n",
    "kla_promoter_ids = [x for x in kla_ids if id_annotation_dict[x] == 'promoter-TSS']\n",
    "kla_enhancer_ids = [x for x in kla_ids if id_annotation_dict[x] != 'promoter-TSS']\n",
    "\n",
    "shared_promoter_ids = [x for x in shared_ids if id_annotation_dict[x] == 'promoter-TSS']\n",
    "shared_enhancer_ids = [x for x in shared_ids if id_annotation_dict[x] != 'promoter-TSS']\n",
    "\n",
    "notxAll_promoter_ids = [x for x in notxAll_ids if id_annotation_dict[x] == 'promoter-TSS']\n",
    "notxAll_enhancer_ids = [x for x in notxAll_ids if id_annotation_dict[x] != 'promoter-TSS']\n",
    "\n",
    "klaAll_promoter_ids = [x for x in klaAll_ids if id_annotation_dict[x] == 'promoter-TSS']\n",
    "klaAll_enhancer_ids = [x for x in klaAll_ids if id_annotation_dict[x] != 'promoter-TSS']\n",
    "\n",
    "### generate peak files\n",
    "\n",
    "\n",
    "def genPeakFile(summary_frame, ids, scoreColumn, outpath):\n",
    "    positions = summary_frame.ix[ids,'Position'].values\n",
    "    starts = []\n",
    "    ends = []\n",
    "    chrs = summary_frame.ix[ids,'chr'].values\n",
    "    scores = summary_frame.ix[ids,scoreColumn].values\n",
    "    strands = ['+'] * len(ids)\n",
    "    for x in positions:\n",
    "        tokens = x.split(':')[1].strip().split('-')\n",
    "        starts.append(tokens[0])\n",
    "        ends.append(tokens[1])\n",
    "    out_frame = pd.DataFrame({'#PeakID': ids,\n",
    "                              'chr': chrs,\n",
    "                              'start': starts,\n",
    "                              'end': ends,\n",
    "                              'strand': strands,\n",
    "                              'score': scores})\n",
    "    out_frame = out_frame[['#PeakID', 'chr', 'start', 'end', 'strand', 'score']]\n",
    "    out_frame.to_csv(outpath, index=False, sep='\\t')\n",
    "    \n",
    "genPeakFile(summary_frame, notx_promoter_ids, 'ncor_notx', outDirectory + '/notx_promoters_peaks.tsv')\n",
    "genPeakFile(summary_frame, notx_enhancer_ids, 'ncor_notx', outDirectory + '/notx_enhancers_peaks.tsv')\n",
    "\n",
    "genPeakFile(summary_frame, kla_promoter_ids, 'ncor_kla', outDirectory + '/kla_promoters_peaks.tsv')\n",
    "genPeakFile(summary_frame, kla_enhancer_ids, 'ncor_kla', outDirectory + '/kla_enhancers_peaks.tsv')\n",
    "\n",
    "genPeakFile(summary_frame, shared_promoter_ids, 'ncor_notx', outDirectory + '/shared_promoters_peaks.tsv')\n",
    "genPeakFile(summary_frame, shared_enhancer_ids, 'ncor_notx', outDirectory + '/shared_enhancers_peaks.tsv')\n",
    "\n",
    "genPeakFile(summary_frame, notxAll_promoter_ids, 'ncor_notx', outDirectory + '/notxAll_promoters_peaks.tsv')\n",
    "genPeakFile(summary_frame, notxAll_enhancer_ids, 'ncor_notx', outDirectory + '/notxAll_enhancers_peaks.tsv')\n",
    "\n",
    "genPeakFile(summary_frame, klaAll_promoter_ids, 'ncor_kla', outDirectory + '/klaAll_promoters_peaks.tsv')\n",
    "genPeakFile(summary_frame, klaAll_enhancer_ids, 'ncor_kla', outDirectory + '/klaAll_enhancers_peaks.tsv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for every group of peaks\n",
    "for p in os.listdir(outDirectory):\n",
    "    if not 'histAnnotated' in p and '.tsv' in p:\n",
    "        outpath = outDirectory + '/' + p.replace('_peaks.tsv', '_histAnnotated.tsv')\n",
    "        !annotatePeaks.pl $outDirectory/$p mm10 -hist 20 -size 2000 -d tag_directories_enhancerMarks/*> $outpath \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coverage = np.mean(data[col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotting_frame = None\n",
    "first = True\n",
    "for p in os.listdir(outDirectory):\n",
    "    if 'histAnnotated' in p:\n",
    "        annotation = p.split('_')[1]\n",
    "        peakType = p.split('_')[0]\n",
    "        factor = p.replace('_histAnnotated.tsv', '')\n",
    "        data=pd.read_csv(outDirectory + '/' + p, sep='\\t')\n",
    "        columns = [x for x in data.columns.values if 'Coverage' in x]\n",
    "        columns = [data.columns.values[0]] + columns\n",
    "        data = data[columns]\n",
    "        columns = data.columns.values\n",
    "        columns[0] = 'Position'\n",
    "        newColumns = []\n",
    "        for x in columns:\n",
    "            if '/' in x:\n",
    "                tokens = x.replace('_ChIP','').replace('Veh','notx').split('/')[-1].split('_')[:-2]\n",
    "                nc = '_'.join(tokens[:-1]) + '_' + tokens[-1].split('-')[0]\n",
    "                newColumns.append(nc)\n",
    "            else:\n",
    "                newColumns.append(x)\n",
    "        data.columns = newColumns\n",
    "        # create data frame for making plots\n",
    "        unique_cols = sorted(set(data.columns.values[1:]))\n",
    "        for col in unique_cols:\n",
    "            \n",
    "            positions = data['Position'].values\n",
    "            # average coverage across replicates\n",
    "            if len(data[col].shape) > 1:\n",
    "                coverage = np.mean(data[col], axis=1)\n",
    "            else:\n",
    "                coverage = data[col]\n",
    "            # get metadata\n",
    "            tokens = col.split('_')\n",
    "            cellType = [tokens[0] ] * len(positions)\n",
    "            genotype = [tokens[1]] * len(positions)\n",
    "            signal = [tokens[2]] * len(positions)\n",
    "            treatment = [tokens[3]] * len(positions)\n",
    "            annotations = [annotation] * len(positions)\n",
    "            peakTypes = [peakType] * len(positions)\n",
    "\n",
    "            current_frame = pd.DataFrame({'Position':positions,\n",
    "                                         'Coverage': coverage,\n",
    "                                         'cellType':cellType,\n",
    "                                         'genotype':genotype,\n",
    "                                         'signal':signal,\n",
    "                                         'treatment':treatment,\n",
    "                                         'annotation':annotations,\n",
    "                                         'peakType': peakTypes})\n",
    "            current_frame = current_frame[['Position',\n",
    "                                         'Coverage',\n",
    "                                         'cellType',\n",
    "                                         'genotype',\n",
    "                                         'signal',\n",
    "                                         'treatment',\n",
    "                                         'annotation',\n",
    "                                         'peakType']]\n",
    "            # concatenate data frames\n",
    "            if first == True:\n",
    "                first = False\n",
    "                plotting_frame = current_frame\n",
    "            else:\n",
    "                plotting_frame = pd.concat([plotting_frame, current_frame])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g= sns.factorplot(x='Position', \n",
    "               y='Coverage', \n",
    "               row='signal',\n",
    "               col='annotation',\n",
    "               hue='genotype', \n",
    "               scale=0.5,  \n",
    "               size=10,\n",
    "               margin_titles=True,\n",
    "               col_order = ['enhancers','promoters'],\n",
    "               row_order = ['H3K4me1', 'H3K4me3', 'H3K27Ac', 'PolII', 'Gro'],\n",
    "               sharey=False,\n",
    "               markers='.',\n",
    "               data = plotting_frame[(plotting_frame['peakType']=='notx') & (plotting_frame['treatment']=='notx')])\n",
    "g.set_xticklabels(rotation=90)\n",
    "plt.savefig('notx.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g= sns.factorplot(x='Position', \n",
    "               y='Coverage', \n",
    "               row='signal',\n",
    "               col='annotation',\n",
    "               hue='genotype', \n",
    "               scale=0.5,  \n",
    "               size=10,\n",
    "               margin_titles=True,\n",
    "               sharey=False,\n",
    "               markers='.',\n",
    "               col_order = ['enhancers','promoters'],\n",
    "               row_order = ['H3K4me1', 'H3K4me3', 'H3K27Ac', 'PolII', 'Gro'],\n",
    "               data = plotting_frame[(plotting_frame['peakType']=='kla') & (plotting_frame['treatment']=='KLA')])\n",
    "g.set_xticklabels(rotation=90)\n",
    "plt.savefig('kla.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g= sns.factorplot(x='Position', \n",
    "               y='Coverage', \n",
    "               row='signal',\n",
    "               col='annotation',\n",
    "               hue='genotype', \n",
    "               scale=0.5,  \n",
    "               size=10,\n",
    "               margin_titles=True,\n",
    "               sharey=False,\n",
    "               markers='.',\n",
    "               col_order = ['enhancers','promoters'],\n",
    "               row_order = ['H3K4me1', 'H3K4me3', 'H3K27Ac', 'PolII', 'Gro'],\n",
    "               data = plotting_frame[(plotting_frame['peakType']=='notxAll') & (plotting_frame['treatment']=='notx')])\n",
    "g.set_xticklabels(rotation=90)\n",
    "plt.savefig('notxAll.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g= sns.factorplot(x='Position', \n",
    "               y='Coverage', \n",
    "               row='signal',\n",
    "               col='annotation',\n",
    "               hue='genotype', \n",
    "               scale=0.5,  \n",
    "               size=10,\n",
    "               margin_titles=True,\n",
    "               sharey=False,\n",
    "               markers='.',\n",
    "               col_order = ['enhancers','promoters'],\n",
    "               row_order = ['H3K4me1', 'H3K4me3', 'H3K27Ac', 'PolII', 'Gro'],\n",
    "               data = plotting_frame[(plotting_frame['peakType']=='klaAll') & (plotting_frame['treatment']=='KLA')])\n",
    "g.set_xticklabels(rotation=90)\n",
    "plt.savefig('klaAll.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shared_plotting_frame = plotting_frame[plotting_frame['peakType']=='shared']\n",
    "shared_plotting_frame['genotype-treatment'] = shared_plotting_frame['genotype'] + '_' + shared_plotting_frame['treatment']\n",
    "\n",
    "g= sns.factorplot(x='Position', \n",
    "               y='Coverage', \n",
    "               row='signal',\n",
    "               col='annotation',\n",
    "               hue='genotype-treatment', \n",
    "               scale=0.5,  \n",
    "               size=10,\n",
    "               margin_titles=True,\n",
    "               sharey=False,\n",
    "               markers='.',\n",
    "               col_order = ['enhancers','promoters'],\n",
    "               row_order = ['H3K4me1', 'H3K4me3', 'H3K27Ac', 'PolII', 'Gro'],\n",
    "               data = shared_plotting_frame)\n",
    "g.set_xticklabels(rotation=90)\n",
    "plt.savefig('shared.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g= sns.factorplot(x='Position', \n",
    "               y='Coverage', \n",
    "               row='signal',\n",
    "               col='annotation',\n",
    "               hue='genotype', \n",
    "               scale=0.5,  \n",
    "               size=10,\n",
    "               margin_titles=True,\n",
    "               sharey=False,\n",
    "               markers='.',\n",
    "               col_order = ['enhancers','promoters'],\n",
    "               row_order = ['H3K4me1', 'H3K4me3', 'H3K27Ac', 'PolII', 'Gro'],\n",
    "               data = plotting_frame[(plotting_frame['peakType']=='shared') & (plotting_frame['treatment']=='notx')])\n",
    "g.set_xticklabels(rotation=90)\n",
    "plt.savefig('shared_notx.pdf')\n",
    "g= sns.factorplot(x='Position', \n",
    "               y='Coverage', \n",
    "               row='signal',\n",
    "               col='annotation',\n",
    "               hue='genotype', \n",
    "               scale=0.5,  \n",
    "               size=10,\n",
    "               margin_titles=True,\n",
    "               sharey=False,\n",
    "               markers='.',\n",
    "               col_order = ['enhancers','promoters'],\n",
    "               row_order = ['H3K4me1', 'H3K4me3', 'H3K27Ac', 'PolII', 'Gro'],\n",
    "               data = plotting_frame[(plotting_frame['peakType']=='shared') & (plotting_frame['treatment']=='KLA')])\n",
    "g.set_xticklabels(rotation=90)\n",
    "plt.savefig('shared_kla.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
