{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##header ###\n",
    "__author__ = \"Jenhan Tao\"\n",
    "__license__ = \"BSD\"\n",
    "__email__ = \"jenhantao@gmail.com\"\n",
    "\n",
    "##imports ###\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import itertools\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "##notebook specific configuration ###\n",
    "%matplotlib inline\n",
    "matplotlib.pylab.rcParams['savefig.dpi'] = 200\n",
    "sys.setrecursionlimit(5000)\n",
    "os.chdir('/gpfs/data01/glasslab/home/jtao/analysis/tensorflow_analysis/')\n",
    "sns.set_context('notebook')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_features_frame = pd.read_pickle('/home/jtao/analysis/tensorflow_analysis/positive_features.pickle')\n",
    "\n",
    "negative_features_frame = pd.read_pickle('/home/jtao/analysis/tensorflow_analysis/negative_features.pickle')\n",
    "\n",
    "negative_features_frame = negative_features_frame.ix[:41508, :]\n",
    "\n",
    "labels = np.array([[1,0] for x in range(41508)] + [[0,1] for x in range(41508)])\n",
    "cv_labels = np.array([1 for x in range(41508)] + [0 for x in range(41508)])\n",
    "features = pd.concat([positive_features_frame, negative_features_frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO replace this code block with proper stratified cross validation to create training and test data sets\n",
    "\n",
    "train_features = pd.concat([positive_features_frame.ix[:20754,:], negative_features_frame.ix[:20754,:]])\n",
    "test_features = pd.concat([positive_features_frame.ix[20754:,:], negative_features_frame.ix[20754:,:]])\n",
    "\n",
    "train_labels =  np.array([[1,0] for x in range(20754)] + [[0,1] for x in range(20754)])\n",
    "test_labels =  np.array([[1,0] for x in range(20754)] + [[0,1] for x in range(20754)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Placeholder to hold features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 196])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables to hold weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([196, 2]))\n",
    "b = tf.Variable(tf.zeros([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Placeholder for True labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a new placeholder to input the correct answers:\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definine Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# launch Model in session\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model in one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternatively you can just give the data to the model all at once\n",
    "sess.run(train_step, feed_dict = {x:train_features, y_:train_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783546\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={x: test_features , y_:test_labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.817435\n",
      "accuracy 0.830018\n",
      "accuracy 0.840426\n",
      "accuracy 0.846647\n",
      "accuracy 0.851268\n",
      "accuracy 0.852868\n",
      "accuracy 0.855267\n",
      "accuracy 0.857517\n",
      "accuracy 0.858975\n",
      "accuracy 0.85986\n",
      "overall accuracy 0.862142\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sss = StratifiedShuffleSplit(cv_labels, n_iter=1, test_size=0.2, random_state=0 )\n",
    "for train_index, test_index in sss:\n",
    "    train_features = features.ix[train_index,:]\n",
    "    test_features = features.ix[test_index,:]\n",
    "\n",
    "    train_labels = labels[train_index]\n",
    "    test_labels = labels[test_index]\n",
    "\n",
    "    inner_sss = StratifiedShuffleSplit(train_labels, n_iter=10, test_size=0.2, random_state=0 )\n",
    "    for batch_index, nonbatch_index in inner_sss:\n",
    "        batch_features = train_features.ix[batch_index,:]\n",
    "\n",
    "        batch_labels = train_labels[batch_index]\n",
    "\n",
    "        sess.run(train_step, feed_dict={x: batch_features, y_: batch_labels})\n",
    "        print('accuracy',\n",
    "        sess.run(accuracy, \n",
    "                 feed_dict={x: batch_features , \n",
    "                            y_:batch_labels}\n",
    "                )\n",
    "         )\n",
    "    \n",
    "    print('overall accuracy',\n",
    "        sess.run(accuracy, \n",
    "                 feed_dict={x: test_features , \n",
    "                            y_:test_labels}\n",
    "                )\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate number of features and labels\n",
    "num_features = features.shape[1]\n",
    "num_classes = labels.shape[1]\n",
    "\n",
    "# place holder for holding input data\n",
    "x = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "\n",
    "# add a new placeholder to input the correct answers:\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define layer 1\n",
    "output_length_layer1 = 200\n",
    "w_layer1 = tf.Variable(tf.truncated_normal([num_features, output_length_layer1], \n",
    "                                           stddev=1.0/math.sqrt(num_features)))\n",
    "b_layer1 = tf.Variable(tf.zeros([output_length_layer1]))\n",
    "z_layer1 = tf.matmul(x, w_layer1) + b_layer1\n",
    "a_layer1 = tf.nn.softmax(z_layer1)\n",
    "\n",
    "# drop out layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "dropout_layer = tf.nn.dropout(a_layer1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define layer 2 the output layer\n",
    "output_length_layer2 = num_classes\n",
    "w_layer2 = tf.Variable(tf.truncated_normal([output_length_layer1, output_length_layer2], \n",
    "                       stddev=1.0/math.sqrt(output_length_layer1)))\n",
    "b_layer2 = tf.Variable(tf.zeros([output_length_layer2]))\n",
    "z_layer2 = tf.matmul(dropout_layer, w_layer2) + b_layer2\n",
    "y = tf.nn.softmax(z_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), axis=1))\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current accuracy 0.88509\n",
      "current accuracy 0.886295\n",
      "current accuracy 0.888404\n",
      "current accuracy 0.879066\n",
      "current accuracy 0.89488\n",
      "current accuracy 0.887349\n",
      "current accuracy 0.882982\n",
      "current accuracy 0.889006\n",
      "current accuracy 0.888102\n",
      "current accuracy 0.894729\n",
      "current accuracy 0.892169\n",
      "current accuracy 0.889759\n",
      "current accuracy 0.887199\n",
      "current accuracy 0.892169\n",
      "current accuracy 0.893373\n",
      "current accuracy 0.884639\n",
      "current accuracy 0.890813\n",
      "current accuracy 0.891867\n",
      "current accuracy 0.891867\n",
      "current accuracy 0.887199\n",
      "current accuracy 0.883735\n",
      "current accuracy 0.900602\n",
      "current accuracy 0.882831\n",
      "current accuracy 0.891416\n",
      "current accuracy 0.889006\n",
      "current accuracy 0.898193\n",
      "current accuracy 0.88509\n",
      "current accuracy 0.888404\n",
      "current accuracy 0.893072\n",
      "current accuracy 0.890361\n",
      "current accuracy 0.889307\n",
      "current accuracy 0.886295\n",
      "current accuracy 0.891717\n",
      "current accuracy 0.893825\n",
      "current accuracy 0.892922\n",
      "current accuracy 0.887952\n",
      "current accuracy 0.890211\n",
      "current accuracy 0.891265\n",
      "current accuracy 0.891416\n",
      "current accuracy 0.895181\n",
      "current accuracy 0.89247\n",
      "current accuracy 0.897139\n",
      "current accuracy 0.891867\n",
      "current accuracy 0.894127\n",
      "current accuracy 0.890512\n",
      "current accuracy 0.886596\n",
      "current accuracy 0.890813\n",
      "current accuracy 0.884639\n",
      "current accuracy 0.899849\n",
      "current accuracy 0.889608\n",
      "current accuracy 0.891265\n",
      "current accuracy 0.888404\n",
      "current accuracy 0.890964\n",
      "current accuracy 0.893976\n",
      "current accuracy 0.889759\n",
      "current accuracy 0.888855\n",
      "current accuracy 0.888705\n",
      "current accuracy 0.886446\n",
      "current accuracy 0.899398\n",
      "current accuracy 0.889006\n",
      "current accuracy 0.895633\n",
      "current accuracy 0.89503\n",
      "current accuracy 0.893825\n",
      "current accuracy 0.891114\n",
      "current accuracy 0.893072\n",
      "current accuracy 0.891566\n",
      "current accuracy 0.883584\n",
      "current accuracy 0.88494\n",
      "current accuracy 0.892319\n",
      "current accuracy 0.892621\n",
      "current accuracy 0.886145\n",
      "current accuracy 0.888404\n",
      "current accuracy 0.893976\n",
      "current accuracy 0.895633\n",
      "current accuracy 0.885843\n",
      "current accuracy 0.894127\n",
      "current accuracy 0.890512\n",
      "current accuracy 0.888253\n",
      "current accuracy 0.889458\n",
      "current accuracy 0.893223\n",
      "current accuracy 0.89503\n",
      "current accuracy 0.890512\n",
      "current accuracy 0.893675\n",
      "current accuracy 0.891566\n",
      "current accuracy 0.892319\n",
      "current accuracy 0.890512\n",
      "current accuracy 0.895482\n",
      "current accuracy 0.893675\n",
      "current accuracy 0.895331\n",
      "current accuracy 0.896386\n",
      "current accuracy 0.898946\n",
      "current accuracy 0.895181\n",
      "current accuracy 0.898042\n",
      "current accuracy 0.89759\n",
      "current accuracy 0.889759\n",
      "current accuracy 0.892922\n",
      "current accuracy 0.889307\n",
      "current accuracy 0.901807\n",
      "current accuracy 0.900301\n",
      "current accuracy 0.883735\n",
      "current accuracy 0.893524\n",
      "current accuracy 0.893976\n",
      "current accuracy 0.899548\n",
      "current accuracy 0.895181\n",
      "current accuracy 0.892319\n",
      "current accuracy 0.896837\n",
      "current accuracy 0.893976\n",
      "current accuracy 0.900904\n",
      "current accuracy 0.894127\n",
      "current accuracy 0.892169\n",
      "current accuracy 0.893223\n",
      "current accuracy 0.893976\n",
      "current accuracy 0.900301\n",
      "current accuracy 0.891867\n",
      "current accuracy 0.890361\n",
      "current accuracy 0.899096\n",
      "current accuracy 0.9\n",
      "current accuracy 0.892319\n",
      "current accuracy 0.895633\n",
      "current accuracy 0.89488\n",
      "current accuracy 0.893373\n",
      "current accuracy 0.89488\n",
      "current accuracy 0.893223\n",
      "current accuracy 0.898042\n",
      "current accuracy 0.891867\n",
      "current accuracy 0.891416\n",
      "current accuracy 0.891566\n",
      "current accuracy 0.893072\n",
      "current accuracy 0.894127\n",
      "current accuracy 0.895633\n",
      "current accuracy 0.894127\n",
      "current accuracy 0.89488\n",
      "current accuracy 0.894277\n",
      "current accuracy 0.896084\n",
      "current accuracy 0.891114\n",
      "current accuracy 0.890813\n",
      "current accuracy 0.892319\n",
      "current accuracy 0.892922\n",
      "current accuracy 0.898494\n",
      "current accuracy 0.889608\n",
      "current accuracy 0.890512\n",
      "current accuracy 0.898795\n",
      "current accuracy 0.896837\n",
      "current accuracy 0.898343\n",
      "current accuracy 0.893524\n",
      "current accuracy 0.897892\n",
      "current accuracy 0.891566\n",
      "current accuracy 0.896687\n",
      "current accuracy 0.888705\n",
      "current accuracy 0.893373\n",
      "current accuracy 0.895331\n",
      "current accuracy 0.891867\n",
      "current accuracy 0.895482\n",
      "current accuracy 0.89759\n",
      "current accuracy 0.894428\n",
      "current accuracy 0.893223\n",
      "current accuracy 0.901054\n",
      "current accuracy 0.895934\n",
      "current accuracy 0.889006\n",
      "current accuracy 0.888705\n",
      "current accuracy 0.893072\n",
      "current accuracy 0.895482\n",
      "current accuracy 0.893223\n",
      "current accuracy 0.894729\n",
      "current accuracy 0.895934\n",
      "current accuracy 0.897289\n",
      "current accuracy 0.892018\n",
      "current accuracy 0.89488\n",
      "current accuracy 0.893976\n",
      "current accuracy 0.897741\n",
      "current accuracy 0.893976\n",
      "current accuracy 0.900151\n",
      "current accuracy 0.895331\n",
      "current accuracy 0.891867\n",
      "current accuracy 0.896386\n",
      "current accuracy 0.898795\n",
      "current accuracy 0.893223\n",
      "current accuracy 0.889307\n",
      "current accuracy 0.896386\n",
      "current accuracy 0.900753\n",
      "current accuracy 0.895633\n",
      "current accuracy 0.890964\n",
      "current accuracy 0.898193\n",
      "current accuracy 0.900452\n",
      "current accuracy 0.896084\n",
      "current accuracy 0.89247\n",
      "current accuracy 0.897289\n",
      "current accuracy 0.896687\n",
      "current accuracy 0.898193\n",
      "current accuracy 0.896988\n",
      "current accuracy 0.90241\n",
      "current accuracy 0.894277\n",
      "current accuracy 0.894277\n",
      "current accuracy 0.893675\n",
      "current accuracy 0.897139\n",
      "current accuracy 0.894127\n",
      "current accuracy 0.895331\n",
      "current accuracy 0.891566\n",
      "current accuracy 0.896084\n",
      "current accuracy 0.9\n",
      "accuracy 0.87232\n"
     ]
    }
   ],
   "source": [
    "# neural network training\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sss = StratifiedShuffleSplit(cv_labels, n_iter=1, test_size=0.2, random_state=0 )\n",
    "\n",
    "for train_index, test_index in sss:\n",
    "    train_features = features.ix[train_index,:]\n",
    "    test_features = features.ix[test_index,:]\n",
    "\n",
    "    train_labels = labels[train_index]\n",
    "    test_labels = labels[test_index]\n",
    "\n",
    "    inner_sss = StratifiedShuffleSplit(train_labels, n_iter=200, test_size=0.95, random_state=0 )\n",
    "    for batch_index, nonbatch_index in inner_sss:\n",
    "        batch_features = train_features.ix[batch_index,:]\n",
    "\n",
    "        batch_labels = train_labels[batch_index]\n",
    "\n",
    "        sess.run(train_step, feed_dict={x: batch_features, \n",
    "                                        y_: batch_labels,\n",
    "                                        keep_prob:0.5})\n",
    "        print('current accuracy', sess.run(accuracy, \n",
    "                 feed_dict={x: batch_features , \n",
    "                            y_:batch_labels,\n",
    "                           keep_prob:1.0}\n",
    "                 )\n",
    "          )\n",
    "        \n",
    "    print('accuracy',\n",
    "    sess.run(accuracy, \n",
    "             feed_dict={x: test_features , \n",
    "                        y_:test_labels,\n",
    "                        keep_prob:1.0}\n",
    "             )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.781579\n",
      "accuracy 0.816117\n",
      "accuracy 0.830093\n",
      "accuracy 0.841301\n",
      "accuracy 0.847042\n",
      "accuracy 0.850712\n",
      "accuracy 0.852679\n",
      "accuracy 0.855569\n",
      "accuracy 0.858166\n",
      "accuracy 0.858806\n",
      "overall accuracy 0.860756\n"
     ]
    }
   ],
   "source": [
    "# without dropout\n",
    "# define layer 1 for logistic regression\n",
    "output_length_layer1 = num_classes\n",
    "w_layer1 = tf.Variable(tf.zeros([num_features, output_length_layer1]))\n",
    "b_layer1 = tf.Variable(tf.zeros([output_length_layer1]))\n",
    "z_layer1 = tf.matmul(x, w_layer1) + b_layer1\n",
    "y = tf.nn.softmax(z_layer1)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), axis=1))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sss = StratifiedShuffleSplit(cv_labels, n_iter=1, test_size=0.2, random_state=0 )\n",
    "for train_index, test_index in sss:\n",
    "    train_features = features.ix[train_index,:]\n",
    "    test_features = features.ix[test_index,:]\n",
    "\n",
    "    train_labels = labels[train_index]\n",
    "    test_labels = labels[test_index]\n",
    "\n",
    "    inner_sss = StratifiedShuffleSplit(train_labels, n_iter=10, test_size=0.2, random_state=0 )\n",
    "    for batch_index, nonbatch_index in inner_sss:\n",
    "        batch_features = train_features.ix[batch_index,:]\n",
    "\n",
    "        batch_labels = train_labels[batch_index]\n",
    "\n",
    "        sess.run(train_step, feed_dict={x: batch_features, y_: batch_labels})\n",
    "        print('accuracy',\n",
    "        sess.run(accuracy, \n",
    "                 feed_dict={x: batch_features , \n",
    "                            y_:batch_labels}\n",
    "                )\n",
    "         )\n",
    "    \n",
    "    print('overall accuracy',\n",
    "        sess.run(accuracy, \n",
    "                 feed_dict={x: test_features , \n",
    "                            y_:test_labels}\n",
    "                )\n",
    "         )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'39' on port 6006\n",
      "(You can navigate to http://169.228.63.221:6006)\n",
      "^CTraceback (most recent call last):\n",
      "  File \"/gpfs/data01/glasslab/home/jtao/software/anaconda3/bin/tensorboard\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/gpfs/data01/glasslab/home/jtao/software/anaconda3/lib/python3.5/site-packages/tensorflow/tensorboard/tensorboard.py\", line 151, in main\n",
      "    tb_server.serve_forever()\n",
      "  File \"/gpfs/data01/glasslab/home/jtao/software/anaconda3/lib/python3.5/socketserver.py\", line 237, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/gpfs/data01/glasslab/home/jtao/software/anaconda3/lib/python3.5/selectors.py\", line 367, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir('./logs/'):\n",
    "    os.remove('./logs/' + f)\n",
    "file_writer = tf.summary.FileWriter('./logs/', sess.graph)\n",
    "\n",
    "!tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zeyang's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
