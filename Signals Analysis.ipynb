{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signals Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### header ###\n",
    "__author__ = \"Jenhan Tao\"\n",
    "__license__ = \"BSD\"\n",
    "__email__ = \"jenhantao@gmail.com\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "### imports ###\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import threading\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib_venn\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "matplotlib.pylab.rcParams['savefig.dpi'] = 200\n",
    "sys.setrecursionlimit(3000)\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import scipy\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import tree\n",
    "\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workingDirectory = '/home/jtao/analysis/signals_analysis/'\n",
    "os.chdir(workingDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_sequences_to_array(sequences):\n",
    "    '''\n",
    "    inputs: sequence of nucleotides represented as a string composed of A, C, G, T\n",
    "    outputs: a list of numpy array representations of a sequence with:\n",
    "             A = [1, 0, 0, 0]\n",
    "             C = [0, 1, 0, 0]\n",
    "             G = [0, 0, 1, 0]\n",
    "             T = [0, 0, 0, 1]\n",
    "             \n",
    "    '''\n",
    "    nucleotide_array_dict = {'A': [1, 0, 0, 0],\n",
    "                             'C': [0, 1, 0, 0],\n",
    "                             'G': [0, 0, 1, 0],\n",
    "                             'T': [0, 0, 0, 1],\n",
    "                             'N': [0, 0, 0, 0]}\n",
    "    sequence_array_list = []\n",
    "    for seq in sequences:\n",
    "        seq_array = []\n",
    "        for nuc in seq:\n",
    "            seq_array.append(nucleotide_array_dict[nuc])\n",
    "        seq_array = np.array(seq_array)\n",
    "        sequence_array_list.append(seq_array)\n",
    "    return sequence_array_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fasta(file_path):\n",
    "    '''\n",
    "    reads in a fasta file and returns a list of sequence ids and a list of sequences\n",
    "    inputs: filepath - path to a fasta file\n",
    "    outputs: sequence_list - a list of sequences\n",
    "             id_list - a list of ids\n",
    "    '''\n",
    "    with open(file_path) as f:\n",
    "        data = f.readlines()\n",
    "    id_list = []\n",
    "    sequence_list = []\n",
    "    # loop through each sequence\n",
    "    for line in data:\n",
    "        if '>' in line:\n",
    "            seq_id = line.strip()[1:]\n",
    "            id_list.append(seq_id)\n",
    "        else:\n",
    "            seq = line.strip()\n",
    "            sequence_list.append(seq)\n",
    "    return sequence_list, id_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_motif_file(motifPath, pseudocount):\n",
    "    '''\n",
    "    reads all motif files in a directory \n",
    "    inputs: path to a directory containing homer motif files\n",
    "    outputs: an array of tuples representing each motif\n",
    "    '''\n",
    "    name_metadata_dict = {}\n",
    "    with open(motifPath) as f:\n",
    "        data = f.readlines()\n",
    "    name = '.'.join(motifPath.split('/')[-1].split('.')[:-1])\n",
    "    matrix = []\n",
    "    metadata = data[0].strip()\n",
    "    for line in data[1:]:\n",
    "        tokens = line.strip().split(\"\\t\")\n",
    "        if len(tokens) > 1:\n",
    "            scores = np.array([float(x) for x in tokens])\n",
    "            scores = scores + pseudocount\n",
    "            scores= scores/np.sum(scores)\n",
    "            matrix.append(scores)\n",
    "    return (name,np.array(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_motif_sequence(seq_index,\n",
    "                        sequence_array_list, \n",
    "                        motif_score_dict, \n",
    "                        motif_score_rc_dict, \n",
    "                        motif_size_dict,\n",
    "                        threshold = 0,\n",
    "                        color_dict = None,\n",
    "                        symmetric_motifs = [],\n",
    "                        algorithm_plot = False,\n",
    "                       ):\n",
    "    '''\n",
    "    visualize a single sequence using the highest scoring nonoverlapping motifs\n",
    "    '''\n",
    "    motif_names = sorted(motif_score_dict.keys())\n",
    "    seq_array = sequence_array_list[seq_index]\n",
    "    seq_size = seq_array.shape[0]\n",
    "    # initialize position_node array\n",
    "    position_node_array = [[] for x in range(seq_size)]\n",
    "\n",
    "    # intialize graph\n",
    "    seq_graph = nx.Graph()\n",
    "\n",
    "    # initialize\n",
    "    for motif in motif_names:\n",
    "        motif_size = motif_size_dict[motif]\n",
    "        indices = list(range(len(motif_score_dict[motif][seq_index])))\n",
    "        forward_scores = motif_score_dict[motif][seq_index]\n",
    "        revcomp_scores = motif_score_rc_dict[motif][seq_index]\n",
    "\n",
    "        # identify motif instances using score threshold\n",
    "        filtered_forward_motif_instances = [x for x in zip(indices, forward_scores) if x[1]>threshold]\n",
    "        filtered_revcomp_motif_instances = [x for x in zip(indices, revcomp_scores) if x[1]>threshold]\n",
    "\n",
    "        # create graph node for every forward motif instance\n",
    "        for mi in filtered_forward_motif_instances:\n",
    "            node_id = str(mi[0]) + '_' + motif\n",
    "            seq_graph.add_node(node_id, \n",
    "                               name=motif,\n",
    "                               start=mi[0], \n",
    "                               end = mi[0] + motif_size, \n",
    "                               score=mi[1], \n",
    "                               orientation='+')\n",
    "\n",
    "            # figure out positions motif instance occupies\n",
    "            start_position = mi[0]\n",
    "            end_position=start_position + motif_size\n",
    "\n",
    "            # add node_id to position_node array\n",
    "            for pos in range(start_position, end_position):\n",
    "                position_node_array[pos].append(node_id)\n",
    "\n",
    "        # create graph node for every revcomp motif instance\n",
    "        for mi in filtered_revcomp_motif_instances:\n",
    "            node_id = str(mi[0]) + '_' + motif\n",
    "            seq_graph.add_node(node_id, \n",
    "                               name=motif,\n",
    "                               start=mi[0], \n",
    "                               end = mi[0] + motif_size, \n",
    "                               score=mi[1], \n",
    "                               orientation='-')\n",
    "\n",
    "            # figure out positions motif instance occupies\n",
    "            start_position = mi[0]\n",
    "            end_position=start_position + motif_size\n",
    "\n",
    "            # add node_id to position_node array\n",
    "            for pos in range(start_position, end_position):\n",
    "                position_node_array[pos].append(node_id)\n",
    "\n",
    "    # figure out which edges to create\n",
    "    edges_to_add = set()\n",
    "    for pos in range(len(position_node_array)):\n",
    "        nodes_at_pos = position_node_array[pos]\n",
    "        # make sure edges are ordered alphabetically\n",
    "        # so I don't have to deal with A-B and B-A\n",
    "        nodes_at_pos.sort() \n",
    "        # generate proposed edges\n",
    "        num_nodes = len(nodes_at_pos)\n",
    "        for i in range(num_nodes - 1):\n",
    "            for j in range(i+1, num_nodes):\n",
    "                id_1 = nodes_at_pos[i]\n",
    "                id_2 = nodes_at_pos[j]\n",
    "                edges_to_add.add((id_1,id_2))\n",
    "    seq_graph.add_edges_from(edges_to_add)\n",
    "\n",
    "    # find best motif instances\n",
    "\n",
    "    # loop through nodes and remove motif instances until there are no neighboring motif instances\n",
    "    num_edges = seq_graph.number_of_edges()\n",
    "    num_nodes = seq_graph.number_of_nodes()\n",
    "    \n",
    "    node_counts = [num_nodes]\n",
    "    edge_counts = [num_edges]\n",
    "    motif_instances =[]\n",
    "    while num_edges > 0:\n",
    "        # sort nodes by motif score\n",
    "        sorted_nodes = sorted(seq_graph.nodes(data=True), key=lambda x: x[1]['score'], reverse=True)\n",
    "\n",
    "        top_node = sorted_nodes[0]\n",
    "        top_node_id = top_node[0]\n",
    "\n",
    "        # save motif instance\n",
    "        motif_instances.append(top_node)\n",
    "\n",
    "        # remove node and neighbors from graph\n",
    "        neighbors = seq_graph.neighbors(top_node_id)\n",
    "\n",
    "        seq_graph.remove_node(top_node_id)\n",
    "        seq_graph.remove_nodes_from(neighbors)\n",
    "\n",
    "        num_edges = seq_graph.number_of_edges()\n",
    "        num_nodes = seq_graph.number_of_nodes()\n",
    "\n",
    "        node_counts.append(num_nodes)\n",
    "        edge_counts.append(num_edges)\n",
    "        \n",
    "#         print(num_edges, num_nodes)\n",
    "        \n",
    "    # create list representation of motifs\n",
    "    sorted_motif_instances = sorted(motif_instances, key = lambda x:x[1]['start'])\n",
    "   \n",
    "    if algorithm_plot:\n",
    "        with sns.axes_style('ticks'):\n",
    "            fig, ax1 = plt.subplots()\n",
    "            ax2 = ax1.twinx()\n",
    "            ln1 = ax1.plot(list(range(len(node_counts))), \n",
    "                     node_counts, \n",
    "                     c='red',\n",
    "                     label = 'Motif Instances')\n",
    "\n",
    "            ln2 = ax2.plot(list(range(len(edge_counts))), \n",
    "                     edge_counts, \n",
    "                     c='blue',\n",
    "                     label = 'Motif Overlaps')\n",
    "        \n",
    "            ax1.set_xlabel('# Motifs Selected')\n",
    "            ax1.set_ylabel('# Motif Instances')\n",
    "            ax2.set_ylabel('# Motif Overlaps')\n",
    "            \n",
    "            lns = ln1+ln2\n",
    "            labs = [l.get_label() for l in lns]\n",
    "            ax2.legend(lns, labs, loc=0)\n",
    "            \n",
    "    # visualize loci\n",
    "    if color_dict == None:\n",
    "        color_dict = dict(zip(motif_names,\n",
    "                            sns.color_palette(\"hls\", len(motif_names))\n",
    "                            )\n",
    "                        )\n",
    "    with sns.axes_style('ticks'):\n",
    "        plt.figure(figsize=(16,2))\n",
    "        for mi in sorted_motif_instances:\n",
    "            name = mi[1]['name']\n",
    "            start = mi[1]['start']\n",
    "            end = mi[1]['end']\n",
    "            score = mi[1]['score']\n",
    "            orientation = mi[1]['orientation']\n",
    "\n",
    "            midpoint = start + (end - start)/2\n",
    "\n",
    "            color = color_dict[name]\n",
    "            # plot positions\n",
    "            if name in symmetric_motifs:\n",
    "                plt.plot([start, end], [0,0], c=color)\n",
    "            elif orientation == '+':\n",
    "                plt.arrow(start, 0, end-start, 0, \n",
    "                          color=color, \n",
    "                          width=0.1, \n",
    "                          head_width=1,\n",
    "                          length_includes_head=True)\n",
    "            else:\n",
    "                plt.arrow(end, 0, start-end, 0, \n",
    "                          color=color, \n",
    "                          width=0.1, \n",
    "                          head_width=1,\n",
    "                          length_includes_head=True)\n",
    "    #         plt.plot([start, end], [-1,-1], c=color)\n",
    "            # plot motif score\n",
    "            plt.plot([midpoint, midpoint], [0, score], c=color)\n",
    "            plt.annotate(xy=(midpoint-3.75, 1.5), s=name, size=8, rotation =90, ha='left', va='bottom')\n",
    "        plt.ylim(-1,14)\n",
    "        plt.xlim(0,seq_size)\n",
    "        plt.xlabel('Position')\n",
    "        plt.ylabel('Motif Score')\n",
    "        sns.despine()\n",
    "    \n",
    "    \n",
    "    return sorted_motif_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_motif_sequence(seq_index,\n",
    "                        sequence_array_list, \n",
    "                        motif_score_dict, \n",
    "                        motif_score_rc_dict, \n",
    "                        motif_size_dict,\n",
    "                        threshold = 0,\n",
    "                        symmetric_motifs = [],\n",
    "                       ):\n",
    "    '''\n",
    "    visualize a single sequence using the highest scoring nonoverlapping motifs\n",
    "    '''\n",
    "    motif_names = sorted(motif_score_dict.keys())\n",
    "    seq_array = sequence_array_list[seq_index]\n",
    "    seq_size = seq_array.shape[0]\n",
    "    # initialize position_node array\n",
    "    position_node_array = [[] for x in range(seq_size)]\n",
    "\n",
    "    # intialize graph\n",
    "    seq_graph = nx.Graph()\n",
    "\n",
    "    # initialize\n",
    "    for motif in motif_names:\n",
    "        motif_size = motif_size_dict[motif]\n",
    "        indices = list(range(len(motif_score_dict[motif][seq_index])))\n",
    "        forward_scores = motif_score_dict[motif][seq_index]\n",
    "        revcomp_scores = motif_score_rc_dict[motif][seq_index]\n",
    "\n",
    "        # identify motif instances using score threshold\n",
    "        filtered_forward_motif_instances = [x for x in zip(indices, forward_scores) if x[1]>threshold]\n",
    "        filtered_revcomp_motif_instances = [x for x in zip(indices, revcomp_scores) if x[1]>threshold]\n",
    "\n",
    "        # create graph node for every forward motif instance\n",
    "        for mi in filtered_forward_motif_instances:\n",
    "            node_id = str(mi[0]) + '_' + motif\n",
    "            seq_graph.add_node(node_id, \n",
    "                               name=motif,\n",
    "                               start=mi[0], \n",
    "                               end = mi[0] + motif_size, \n",
    "                               score=mi[1], \n",
    "                               orientation='+')\n",
    "\n",
    "            # figure out positions motif instance occupies\n",
    "            start_position = mi[0]\n",
    "            end_position=start_position + motif_size\n",
    "\n",
    "            # add node_id to position_node array\n",
    "            for pos in range(start_position, end_position):\n",
    "                position_node_array[pos].append(node_id)\n",
    "\n",
    "        # create graph node for every revcomp motif instance\n",
    "        for mi in filtered_revcomp_motif_instances:\n",
    "            node_id = str(mi[0]) + '_' + motif\n",
    "            seq_graph.add_node(node_id, \n",
    "                               name=motif,\n",
    "                               start=mi[0], \n",
    "                               end = mi[0] + motif_size, \n",
    "                               score=mi[1], \n",
    "                               orientation='-')\n",
    "\n",
    "            # figure out positions motif instance occupies\n",
    "            start_position = mi[0]\n",
    "            end_position=start_position + motif_size\n",
    "\n",
    "            # add node_id to position_node array\n",
    "            for pos in range(start_position, end_position):\n",
    "                position_node_array[pos].append(node_id)\n",
    "\n",
    "    # figure out which edges to create\n",
    "    edges_to_add = set()\n",
    "    for pos in range(len(position_node_array)):\n",
    "        nodes_at_pos = position_node_array[pos]\n",
    "        # make sure edges are ordered alphabetically\n",
    "        # so I don't have to deal with A-B and B-A\n",
    "        nodes_at_pos.sort() \n",
    "        # generate proposed edges\n",
    "        num_nodes = len(nodes_at_pos)\n",
    "        for i in range(num_nodes - 1):\n",
    "            for j in range(i+1, num_nodes):\n",
    "                id_1 = nodes_at_pos[i]\n",
    "                id_2 = nodes_at_pos[j]\n",
    "                edges_to_add.add((id_1,id_2))\n",
    "    seq_graph.add_edges_from(edges_to_add)\n",
    "\n",
    "    # find best motif instances\n",
    "\n",
    "    # loop through nodes and remove motif instances until there are no neighboring motif instances\n",
    "    num_edges = seq_graph.number_of_edges()\n",
    "    num_nodes = seq_graph.number_of_nodes()\n",
    "    \n",
    "    node_counts = [num_nodes]\n",
    "    edge_counts = [num_edges]\n",
    "    motif_instances =[]\n",
    "    while num_edges > 0:\n",
    "        # sort nodes by motif score\n",
    "        sorted_nodes = sorted(seq_graph.nodes(data=True), key=lambda x: x[1]['score'], reverse=True)\n",
    "\n",
    "        top_node = sorted_nodes[0]\n",
    "        top_node_id = top_node[0]\n",
    "\n",
    "        # save motif instance\n",
    "        motif_to_save = top_node[1]\n",
    "        if motif_to_save['name'] in symmetric_motifs:\n",
    "            motif_to_save['orientation'] = '|'\n",
    "        motif_instances.append(motif_to_save)\n",
    "\n",
    "        # remove node and neighbors from graph\n",
    "        neighbors = seq_graph.neighbors(top_node_id)\n",
    "\n",
    "        seq_graph.remove_node(top_node_id)\n",
    "        seq_graph.remove_nodes_from(neighbors)\n",
    "\n",
    "        num_edges = seq_graph.number_of_edges()\n",
    "        num_nodes = seq_graph.number_of_nodes()\n",
    "\n",
    "        node_counts.append(num_nodes)\n",
    "        edge_counts.append(num_edges)\n",
    "        \n",
    "       \n",
    "    # create list representation of motifs\n",
    "    sorted_motif_instances = sorted(motif_instances, key = lambda x:x['start'])\n",
    "   \n",
    "    \n",
    "    \n",
    "    return sorted_motif_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_database(prefix, database):\n",
    "    '''\n",
    "    projects a database of sequences and their corresponding motif paths\n",
    "    according to a prefix. \n",
    "    input: prefix - a string representing a motif and its orientation,\n",
    "           database - a dictionary containing lists of motif paths\n",
    "                      corresponding to each sequence\n",
    "                      {seq_id:[motif_sequences...]}\n",
    "    output: returns the projected database\n",
    "    '''\n",
    "    projected_database = {}\n",
    "    for seq_id in database:\n",
    "        projected_paths = []\n",
    "        motif_paths = database[seq_id]\n",
    "        for path in motif_paths:\n",
    "            if prefix in path:\n",
    "                ind = path.index(prefix)\n",
    "                proj_path = path[ind+1:]\n",
    "                if len(proj_path) > 0:\n",
    "                    projected_paths.append(proj_path)\n",
    "#         print(prefix, (motif_paths), projected_paths)\n",
    "        if len(projected_paths) > 0:\n",
    "            projected_database[seq_id] = projected_paths\n",
    "        \n",
    "    return projected_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_frequent_motifs(database, support_level):\n",
    "    '''\n",
    "    Finds motifs in database that exceeds support level. \n",
    "    For each sequence, collapses the counts of all motif paths corresponding to that sequence\n",
    "    \n",
    "    inputs: database - a dictionary containing lists of motif paths\n",
    "                      corresponding to each sequence\n",
    "            support_level - number of times a motif must appear to be counted\n",
    "    outputs: \n",
    "    '''\n",
    "    motif_count_dict = {}\n",
    "    \n",
    "    for seq_id in database:\n",
    "        motifs_in_seq = set()\n",
    "        motif_paths = database[seq_id]\n",
    "        for path in motif_paths:\n",
    "            for motif in path:\n",
    "                motifs_in_seq.add(motif)\n",
    "        for m in motifs_in_seq:\n",
    "            if m in motif_count_dict:\n",
    "                motif_count_dict[m] += 1\n",
    "            else:\n",
    "                motif_count_dict[m] = 1\n",
    "    \n",
    "    frequent_motifs = [(x, motif_count_dict[x]) for x in motif_count_dict if motif_count_dict[x] >= support_level]\n",
    "    sorted_frequent_motifs = sorted(frequent_motifs, key = lambda x:x[1], reverse=True)\n",
    "    to_return = [x[0] for x in sorted_frequent_motifs]\n",
    "#     print(len(database), sorted_frequent_motifs[:10])\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def motif_prefix_span(prefix, database, support_level):\n",
    "    '''\n",
    "    Finds frequents sequences of motifs in a datase of sequences and their corresponding\n",
    "    motif paths\n",
    "    inputs: prefix - a string representing a motif and its orientation\n",
    "            database - a dictionary containing lists of motif paths corresponding to each sequence\n",
    "            support level - number of times a motif must appear to be counted\n",
    "    outputs: a list of frequent patterns\n",
    "    '''\n",
    "#     print('***', prefix, len(database))\n",
    "    if len(database) >= support_level:\n",
    "        frequent_motifs = find_frequent_motifs(database, support_level)\n",
    "    else:\n",
    "        frequent_motifs = []\n",
    "    to_return = []\n",
    "    if len(frequent_motifs) > 0:\n",
    "        for fm in frequent_motifs:\n",
    "            new_pattern = prefix + [fm]\n",
    "            projected_database = project_database(fm, database)\n",
    "            \n",
    "            fm_results = motif_prefix_span(new_pattern, \n",
    "                                           projected_database, \n",
    "                                           support_level)\n",
    "            to_return = to_return +  fm_results \n",
    "\n",
    "            to_return.append(new_pattern)\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_multi_motif_sequence(seq_array, \n",
    "                              forward_score_dict, \n",
    "                              reverse_score_dict, \n",
    "                              motif_size_dict,\n",
    "                              score_threshold = 0,\n",
    "                              distance_threshold = 200,\n",
    "                              symmetric_motifs = []\n",
    "                             ):\n",
    "    '''\n",
    "    '''\n",
    "    motif_names = sorted(forward_score_dict.keys())\n",
    "    seq_size = seq_array.shape[0]\n",
    "    # initialize position_node array\n",
    "    position_node_array = [[] for x in range(seq_size)]\n",
    "\n",
    "    # intialize graph\n",
    "    seq_graph = nx.DiGraph()\n",
    "\n",
    "    # initialize\n",
    "    for motif in motif_names:\n",
    "        motif_size = motif_size_dict[motif]\n",
    "        indices = list(range(len(forward_score_dict[motif])))\n",
    "        forward_scores = forward_score_dict[motif]\n",
    "        revcomp_scores = reverse_score_dict[motif]\n",
    "\n",
    "        # identify motif instances using score score_threshold\n",
    "        filtered_forward_motif_instances = [x for x in zip(indices, forward_scores) if x[1]>score_threshold]\n",
    "        filtered_revcomp_motif_instances = [x for x in zip(indices, revcomp_scores) if x[1]>score_threshold]\n",
    "\n",
    "        # create graph node for every forward motif instance\n",
    "        for mi in filtered_forward_motif_instances:\n",
    "            node_id = str(mi[0]) + ' ' + motif + ' +'\n",
    "            seq_graph.add_node(node_id, \n",
    "                               name=motif,\n",
    "                               start=mi[0], \n",
    "                               end = mi[0] + motif_size, \n",
    "                               score=mi[1], \n",
    "                               orientation='+')\n",
    "\n",
    "            # figure out positions motif instance occupies\n",
    "            start_position = mi[0]\n",
    "            end_position=start_position + motif_size\n",
    "\n",
    "            # add node_id to position_node array\n",
    "            for pos in range(start_position, end_position):\n",
    "                position_node_array[pos].append(node_id)\n",
    "\n",
    "        # create graph node for every revcomp motif instance\n",
    "        for mi in filtered_revcomp_motif_instances:\n",
    "            node_id = str(mi[0]) + ' ' + motif + ' -'\n",
    "            seq_graph.add_node(node_id, \n",
    "                               name=motif,\n",
    "                               start=mi[0], \n",
    "                               end = mi[0] + motif_size, \n",
    "                               score=mi[1], \n",
    "                               orientation='-')\n",
    "\n",
    "            # figure out positions motif instance occupies\n",
    "            start_position = mi[0]\n",
    "            end_position=start_position + motif_size\n",
    "\n",
    "            # add node_id to position_node array\n",
    "            for pos in range(start_position, end_position):\n",
    "                position_node_array[pos].append(node_id)\n",
    "\n",
    "    # add edges\n",
    "    all_nodes = seq_graph.nodes(data=True)\n",
    "    edges_to_add = []\n",
    "    for node in all_nodes:\n",
    "        # find the first nonoverlapping motif(s)\n",
    "        end_pos = node[1]['end']\n",
    "        first_neighbor_pos = end_pos\n",
    "        candidate_neighbors = []\n",
    "        while len(candidate_neighbors) < 1 and first_neighbor_pos < seq_size:\n",
    "            candidate_neighbors = position_node_array[first_neighbor_pos]\n",
    "            first_neighbor_pos += 1\n",
    "            \n",
    "        # find largest motif amongst the first nonoverlapping motif(s)\n",
    "        max_size_end = -1\n",
    "        max_size_start = -1\n",
    "        for n in candidate_neighbors:\n",
    "            neighbor = seq_graph.node[n]\n",
    "            neighbor_end = neighbor['end']\n",
    "            neighbor_start = neighbor['start']\n",
    "            if neighbor_end > max_size_end:\n",
    "                max_size_end = neighbor_end\n",
    "                max_size_start = neighbor_start\n",
    "        # identify all motifs that overlap with the first largest nonoverlapping motif(s)\n",
    "        for pos in range(max_size_start, max_size_end):\n",
    "            candidate_neighbors = candidate_neighbors + position_node_array[pos]\n",
    "        candidate_neighbors = set(candidate_neighbors)\n",
    "        \n",
    "        for n in candidate_neighbors:\n",
    "            neighbor = seq_graph.node[n]\n",
    "            neighbor_start = neighbor['start']\n",
    "            if neighbor_start >= end_pos:\n",
    "                edges_to_add.append((node[0], n))\n",
    "    seq_graph.add_edges_from(edges_to_add)\n",
    "\n",
    "    # creat start node and connect all nodes with 0 incoming edges\n",
    "    start_edges = []\n",
    "    for node_id, in_degree in seq_graph.in_degree_iter():\n",
    "        if in_degree == 0:\n",
    "            start_edges.append(('start', node_id))\n",
    "            \n",
    "    # create end node and connect all nodes with 0 outgoing edges\n",
    "    end_edges = []\n",
    "    for node_id, out_degree in seq_graph.out_degree_iter():\n",
    "        if out_degree == 0:\n",
    "            end_edges.append((node_id, 'end'))\n",
    "    \n",
    "    seq_graph.add_edges_from(start_edges)\n",
    "    seq_graph.add_edges_from(end_edges)\n",
    "    \n",
    "    # generate all paths from start to end node\n",
    "    paths = nx.all_simple_paths(seq_graph, 'start', 'end')\n",
    "    \n",
    "    # add data to list of paths\n",
    "    id_score_dict = nx.get_node_attributes(seq_graph, 'score')\n",
    "    paths_with_data = []\n",
    "    paths_without_data = []\n",
    "    counter = 0\n",
    "    for p in paths:\n",
    "        \n",
    "        if counter > 1000:\n",
    "            print('Too many paths!!!')\n",
    "            return seq_graph, [], [] \n",
    "        counter += 1\n",
    "        \n",
    "        current_p_with_data = []\n",
    "        current_p_without_data = []\n",
    "        for n in p:\n",
    "#             if n == 'start':\n",
    "#                 motif_name = 'start'\n",
    "#                 orientation = '|'\n",
    "#                 score = score_threshold\n",
    "#             elif n == 'end':\n",
    "#                 motif_name = 'end'\n",
    "#                 orientation = '|'\n",
    "#                 score = score_threshold\n",
    "#             else:\n",
    "            # exclude end and start nodes which were created just for creating paths\n",
    "            if not n== 'start' and not n == 'end':\n",
    "                tokens = n.split()\n",
    "                motif_name = tokens[1]\n",
    "                orientation = tokens[2]\n",
    "                score = id_score_dict[n]\n",
    "                \n",
    "                n_with_data = (motif_name, orientation, score)\n",
    "                current_p_with_data.append(n_with_data)\n",
    "                current_p_without_data.append(motif_name + ' ' + orientation)\n",
    "        paths_with_data.append(current_p_with_data)\n",
    "        paths_without_data.append(current_p_without_data)\n",
    "\n",
    "    return seq_graph, paths_with_data, paths_without_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pattern_sequence_table(frequent_patterns, database):\n",
    "    '''\n",
    "    Constructs a matrix summarizing which sequences contains a frequent motif pattern\n",
    "    '''\n",
    "    sorted_ids = sorted(database.keys())\n",
    "    pattern_names = [' * '.join(x) for x in frequent_patterns]\n",
    "    sequence_pattern_table = pd.DataFrame(np.zeros((len(sorted_ids), len(pattern_names))),\n",
    "                                          index = sorted_ids,\n",
    "                                          columns = pattern_names)\n",
    "    for i in range(len(frequent_patterns)):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        pattern = frequent_patterns[i]\n",
    "        pattern_name = pattern_names[i]\n",
    "        for seq_id in sorted_ids:\n",
    "            motif_paths = database[seq_id]\n",
    "            has_pattern = False\n",
    "            for path in motif_paths:\n",
    "                path_iter = iter(path)\n",
    "                has_pattern = all([m in path_iter for m in pattern])\n",
    "                if has_pattern:\n",
    "                    sequence_pattern_table.ix[seq_id, pattern_name] = 1\n",
    "#                     break\n",
    "    return sequence_pattern_table\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Acessible Promoters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in peak data data\n",
    "summary_frame = pd.read_csv('./group_atac_summary.tsv' , sep='\\t')\n",
    "summary_frame = summary_frame.fillna('0')\n",
    "for col in summary_frame.columns[5:]:\n",
    "    floatValues = []\n",
    "    for val in summary_frame[col].values.astype(str):\n",
    "        if ',' in val:\n",
    "            maxVal = np.mean([float(x) for x in val.split(',')])\n",
    "            floatValues.append(maxVal)\n",
    "        else:\n",
    "            floatValues.append(float(val))\n",
    "    summary_frame[col] = floatValues\n",
    "summary_frame.index = summary_frame['chr'] + ':' + (summary_frame['start'] -1).astype(str) + '-' + summary_frame['end'].astype(str)\n",
    "\n",
    "# remove peaks in unknown/random chromosomes\n",
    "summary_frame = summary_frame[~summary_frame['chr'].str.contains('random')]\n",
    "summary_frame = summary_frame[~summary_frame['chr'].str.contains('Un')]\n",
    "\n",
    "columns = summary_frame.columns.values\n",
    "columns = [x.replace('c57bl6_','') for x in columns]\n",
    "summary_frame.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_frame = pd.read_csv('./merged_atac_peaks_filtered_resized.tsv', sep='\\t')\n",
    "merged_frame.index = merged_frame.ix[:,0].values\n",
    "\n",
    "# filter away peaks in unused chromsomes\n",
    "filtered_frame = merged_frame[\n",
    "             ~(merged_frame['chr'].str.contains('chrY')) & \n",
    "             ~(merged_frame['chr'].str.contains('chrM')) &\n",
    "             ~(merged_frame['chr'].str.contains('random')) &\n",
    "             ~(merged_frame['chr'].str.contains('Un'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treatment loop\n",
      "Veh\n",
      "KLA-1h\n",
      "IL4-1h\n",
      "PamCSK-1h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data01/glasslab/home/jtao/software/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGFbeta-1h\n",
      "R848-1h\n",
      "IFNg-1h\n"
     ]
    }
   ],
   "source": [
    "# read in annotated frame\n",
    "annotated_frame = pd.read_csv('./annotated_atac_peaks.tsv', sep='\\t')\n",
    "annotated_frame.index = annotated_frame['Chr'] + ':' + (annotated_frame['Start'] -1).astype(str) + '-' + annotated_frame['End'].astype(str)\n",
    "# annotated_frame.index = annotated_frame['Chr']+':'+(annotated_frame['Start']-1).astype(str)+'-'+annotated_frame['End'].astype(str)\n",
    "# get promoter associated peaks and associated gene names\n",
    "annotated_frame['Annotation'] = [x.split(' ')[0] for x in annotated_frame['Annotation'].astype(str)]\n",
    "\n",
    "columns = list(annotated_frame.columns.values)\n",
    "columns = columns[:4] + ['Annotation', 'Gene Name'] + [x for x in columns[1:] if 'Tag Count' in x]\n",
    "annotated_frame = annotated_frame[columns]\n",
    "columns[0] = 'PeakID'\n",
    "columns = [x.split('/')[-2].split(' ')[0] if '/' in x else x for x in columns]\n",
    "annotated_frame.columns = columns\n",
    "\n",
    "annotated_mean_frame = annotated_frame[[]]\n",
    "\n",
    "treatments = set([x.split('_')[3] for x in annotated_frame.columns if '_' in x])\n",
    "print('treatment loop')\n",
    "for treatment in treatments:\n",
    "    print(treatment)\n",
    "    treatment_cols = [x for x in columns if treatment in x]\n",
    "    annotated_mean_frame[treatment] = annotated_frame[treatment_cols].mean(axis=1).values\n",
    "\n",
    "promoter_ids = annotated_frame[annotated_frame['Annotation'].str.contains('promoter')].index.values\n",
    "annotated_promoter_frame = annotated_mean_frame[annotated_mean_frame.index.isin(promoter_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "promoter_ids = annotated_frame[annotated_frame['Annotation'].str.contains('promoter')].index.values\n",
    "annotated_promoter_frame = annotated_mean_frame[annotated_mean_frame.index.isin(promoter_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_gene_dict = dict(zip(promoter_ids, annotated_frame.ix[promoter_ids,'Gene Name'].values))\n",
    "gene_id_dict = dict(zip(annotated_frame.ix[promoter_ids,'Gene Name'].values, promoter_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Motif Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Motif Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading AP-2_1_merged\n",
      "reading AP-2_2_merged\n",
      "reading ATF4\n",
      "reading Ahr::Arnt\n",
      "reading Arid3a\n",
      "reading Arid3b\n",
      "reading Arid5a\n",
      "reading BARHL2\n"
     ]
    }
   ],
   "source": [
    "motif_score_dict = {}\n",
    "motif_score_rc_dict = {}\n",
    "for f in sorted(os.listdir('./motif_scores')):\n",
    "    motif_name = f.split('.')[0]\n",
    "    if 'rc' in f:\n",
    "        print('reading', motif_name)\n",
    "        motif_score_rc_dict[motif_name] = pickle.load(open('./motif_scores/'+f, 'rb'))\n",
    "    else:\n",
    "        motif_score_dict[motif_name] = pickle.load(open('./motif_scores/'+f, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Motif Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topMotifScore_frame = pd.read_csv('./top_motif_scores/merged_atac_peaks_filtered_resized_motif_scores.tsv', \n",
    "                    sep='\\t',\n",
    "                    index_col= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pseudocount = 0.001\n",
    "motif_file_path = '/gpfs/data01/glasslab/home/jtao/analysis/jaspar_analysis/curated_motifs/'\n",
    "all_motifs = []\n",
    "\n",
    "for m in os.listdir(motif_file_path):\n",
    "    if '.motif' in m:\n",
    "        motif = read_motif_file(motif_file_path + '/' + m, pseudocount)\n",
    "        all_motifs.append(motif)\n",
    "# sort motifs by name\n",
    "all_motifs.sort(key=lambda x:x[0])\n",
    "\n",
    "fasta_path = './merged_atac_peaks_filtered_resized.fasta'\n",
    "\n",
    "sequence_list, id_list = read_fasta(fasta_path)\n",
    "\n",
    "# convert strings to arrays\n",
    "sequence_array_list = convert_sequences_to_array(sequence_list)\n",
    "\n",
    "motif_size_dict = {}\n",
    "for motif in all_motifs:\n",
    "    name = motif[0]\n",
    "    size = motif[1].shape[0]\n",
    "    if '.' in name:\n",
    "        name = '.'.join(name.split('.')[:-1])\n",
    "    motif_size_dict[name] = size\n",
    "\n",
    "motif_names = sorted(motif_size_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Symmetric Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_sequence_to_sample = 100\n",
    "num_seqs = len(sequence_array_list)\n",
    "mean_pearsons = []\n",
    "motif_symmetryPearson_dict = {}\n",
    "for motif in sorted(motif_score_dict.keys()):\n",
    "    \n",
    "    pearsons = []\n",
    "    for i in range(num_sequence_to_sample):\n",
    "        index = np.random.randint(0,num_seqs)\n",
    "\n",
    "        forward_scores = motif_score_dict[motif][index]\n",
    "        reverse_scores = motif_score_rc_dict[motif][index]\n",
    "\n",
    "        pearson, pval = scipy.stats.pearsonr(forward_scores, reverse_scores)\n",
    "        pearsons.append(pearson)\n",
    "    mean_pearson = np.mean(pearsons)\n",
    "    mean_pearsons.append(mean_pearson)\n",
    "    motif_symmetryPearson_dict[motif] = mean_pearson\n",
    "symmetric_motifs = [x for x in motif_symmetryPearson_dict if motif_symmetryPearson_dict[x] > 0.8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Expression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_expression_frame = pd.read_csv('./edgeR_out.tsv', sep='\\t')\n",
    "columns = diff_expression_frame.columns.values\n",
    "columns[0] = 'refseq'\n",
    "columns[7] = 'gene'\n",
    "\n",
    "columns = [x.lower() for x in columns]\n",
    "diff_expression_frame.columns = columns\n",
    "\n",
    "diff_expression_frame = diff_expression_frame.ix[:,['refseq', 'chr', 'start', 'end', 'gene'] + [x for x in diff_expression_frame.columns if 'vs.' in x]]\n",
    "diff_expression_frame['gene'] = [x.split('|')[0] for x in diff_expression_frame['gene'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rpkm_frame = pd.read_csv('./rpkm.tsv', sep='\\t')\n",
    "columns = rpkm_frame.columns.values\n",
    "columns[0] = 'Refseq'\n",
    "columns[7] = 'Gene'\n",
    "rpkm_frame.columns = columns\n",
    "rpkm_frame['All Gene Names'] = rpkm_frame['Gene'].values\n",
    "rpkm_frame['Gene'] = [x.split('|')[0] for x in rpkm_frame['Gene'].values]\n",
    "rpkm_frame.index = rpkm_frame['Gene'].values\n",
    "rpkm_frame.drop('chr', axis=1, inplace=True)\n",
    "rpkm_frame.drop('start', axis=1, inplace=True)\n",
    "rpkm_frame.drop('end', axis=1, inplace=True)\n",
    "rpkm_frame.drop('strand', axis=1, inplace=True)\n",
    "rpkm_frame.drop('Length', axis=1, inplace=True)\n",
    "rpkm_frame.drop('Copies', axis=1, inplace=True)\n",
    "conditions = set(sorted([x.split('/')[-1].split('_')[3] for x in rpkm_frame.columns if 'tag_directories' in x]))\n",
    "rpkm_mean_frame = rpkm_frame[['Refseq', 'Gene', 'All Gene Names']]\n",
    "for condition in conditions:\n",
    "    current_cols = [x for x in rpkm_frame.columns if condition in x]\n",
    "    mean_vals = rpkm_frame[current_cols].mean(axis=1)\n",
    "    rpkm_mean_frame[condition] = mean_vals\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Diff Expressed Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_expressed_genes = diff_expression_frame[\n",
    "                                             (diff_expression_frame['veh-1h vs. ifng-1h adj. p-value'] < 0.05) |\n",
    "                                             (diff_expression_frame['veh-1h vs. kla-1h adj. p-value'] < 0.05) |\n",
    "                                             (diff_expression_frame['ifng-1h vs. kla-1h adj. p-value'] < 0.05)\n",
    "                                            ]['gene'].values\n",
    "\n",
    "\n",
    "\n",
    "# diff_expressed_genes = diff_expression_frame[diff_expression_frame[\n",
    "#         [x for x in diff_expression_frame.columns if 'adj. p-value' in x]].min(axis=1) < 0.05\n",
    "#                                             ]['gene'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numRowClusters = 6\n",
    "colorDict = dict(zip(range(numRowClusters),['red', 'blue', 'yellow', 'orange', 'green', 'magenta', 'grey']))\n",
    "\n",
    "data = rpkm_mean_frame[(rpkm_mean_frame['Gene'].isin(diff_expressed_genes)) &\n",
    "                (rpkm_mean_frame.ix[:,['Veh-1h', 'IFNg-1h', 'KLA-1h']].max(axis=1) >= 16)].ix[:,['Veh-1h', 'IFNg-1h', 'KLA-1h']]\n",
    "\n",
    "\n",
    "cg=sns.clustermap(data,\n",
    "               yticklabels=False,\n",
    "               col_cluster=False,\n",
    "               row_cluster=True,\n",
    "               vmin=-2,\n",
    "               vmax=2,\n",
    "               cmap='coolwarm',\n",
    "               z_score = 0,\n",
    "               metric = 'correlation',\n",
    "               method='centroid'\n",
    "                  \n",
    "              )\n",
    "plt.close()\n",
    "row_linkage = cg.dendrogram_row.linkage\n",
    "\n",
    "row_flatCluster = scipy.cluster.hierarchy.fcluster(row_linkage, numRowClusters, criterion=\"maxclust\")\n",
    "\n",
    "row_colors = [colorDict[row_flatCluster[i] -1] for i in range(len(data.index))]\n",
    "sns.clustermap(data, \n",
    "                row_linkage = row_linkage,\n",
    "                row_colors = row_colors,\n",
    "                yticklabels = False,\n",
    "                col_cluster=False,\n",
    "                vmin=-2,\n",
    "                vmax=2,\n",
    "                cmap='coolwarm',\n",
    "               z_score = 0,\n",
    ")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ['red', 'blue', 'yellow', 'orange', 'green', 'magenta']\n",
    "cluster_name_dict = {1:'IFNg Specific',2:'IFNg Specific',3:'KLA Down',4:'Veh Specific', 5:'IFNg Down', 6:'KLA Specific'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_cluster_dict = dict(zip(data.index.values, row_flatCluster))\n",
    "cluster_genes_dict = {x:[] for x in range(1,numRowClusters+1)}\n",
    "for gene in gene_cluster_dict:\n",
    "    cluster = gene_cluster_dict[gene] \n",
    "    cluster_genes_dict[cluster].append(gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_sequence_array_dict = dict(zip(id_list, sequence_array_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_promoterID_dict = {}\n",
    "promoterID_cluster_dict = {}\n",
    "for cluster in cluster_genes_dict:\n",
    "    cluster_genes = cluster_genes_dict[cluster]\n",
    "    cluster_seq_ids = []\n",
    "    \n",
    "    for g in cluster_genes:\n",
    "        if g in gene_id_dict:\n",
    "            promoter_id = gene_id_dict[g]\n",
    "            cluster_seq_ids.append(promoter_id)\n",
    "            promoterID_cluster_dict[promoter_id] = cluster\n",
    "    if len(cluster_seq_ids) > 50:\n",
    "        cluster_promoterID_dict[cluster] = cluster_seq_ids\n",
    "        print(cluster)\n",
    "        print(len(cluster_genes), len(set(cluster_genes)))\n",
    "        print(len(cluster_seq_ids), len(set(cluster_seq_ids)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Differential ATAC Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_atac_frame = pd.read_csv('./edgeR_atac_out.tsv', sep='\\t')\n",
    "columns = diff_atac_frame.columns.values\n",
    "columns[0] = 'PeakID'\n",
    "diff_atac_frame.columns = columns\n",
    "diff_atac_frame.index = diff_atac_frame['Chr'] + ':' + (diff_atac_frame['Start'] -1).astype(str) + '-' + diff_atac_frame['End'].astype(str)\n",
    "\n",
    "\n",
    "diff_atac_frame = diff_atac_frame.ix[:,['PeakID', 'Chr', 'Start', 'End'] + [x for x in diff_atac_frame.columns if 'vs.' in x]]\n",
    "\n",
    "columns = diff_atac_frame.columns.values\n",
    "columns = [x.lower() for x in columns]\n",
    "diff_atac_frame.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_bound_peaks = diff_atac_frame[\n",
    "                                     (diff_atac_frame['veh vs. ifng-1h adj. p-value'] < 0.05) |\n",
    "                                     (diff_atac_frame['veh vs. kla-1h adj. p-value'] < 0.05) |\n",
    "                                     (diff_atac_frame['ifng-1h vs. kla-1h adj. p-value'] < 0.05)\n",
    "                                    ].index.values\n",
    "\n",
    "\n",
    "\n",
    "# diff_bound_peaks = diff_atac_frame[diff_atac_frame[\n",
    "#         [x for x in diff_atac_frame.columns if 'adj. p-value' in x]].min(axis=1) < 0.05\n",
    "#                                             ].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numRowClusters = 6\n",
    "colorDict = dict(zip(range(numRowClusters),['red', 'blue', 'yellow', 'orange', 'green', 'magenta', 'grey']))\n",
    "promoter_ids = annotated_frame[annotated_frame['Annotation'].str.contains('promoter')].index.values\n",
    "data = annotated_mean_frame[(annotated_mean_frame.index.isin(diff_bound_peaks)) &\n",
    "                            (annotated_mean_frame.ix[:,['Veh', 'IFNg-1h', 'KLA-1h']].max(axis=1) >= 16) &\n",
    "                            (~annotated_mean_frame.index.isin(promoter_ids))\n",
    "                           ].ix[:,['Veh', 'IFNg-1h', 'KLA-1h']]\n",
    "\n",
    "\n",
    "cg=sns.clustermap(data,\n",
    "               yticklabels=False,\n",
    "               col_cluster=False,\n",
    "               row_cluster=True,\n",
    "               vmin=-2,\n",
    "               vmax=2,\n",
    "               cmap='coolwarm',\n",
    "               z_score = 0,\n",
    "               metric = 'correlation',\n",
    "               method='centroid'\n",
    "                  \n",
    "              )\n",
    "plt.close()\n",
    "row_linkage = cg.dendrogram_row.linkage\n",
    "\n",
    "row_flatCluster = scipy.cluster.hierarchy.fcluster(row_linkage, numRowClusters, criterion=\"maxclust\")\n",
    "\n",
    "row_colors = [colorDict[row_flatCluster[i] -1] for i in range(len(data.index))]\n",
    "sns.clustermap(data, \n",
    "                row_linkage = row_linkage,\n",
    "                row_colors = row_colors,\n",
    "                yticklabels = False,\n",
    "                col_cluster=False,\n",
    "                vmin=-2,\n",
    "                vmax=2,\n",
    "                cmap='coolwarm',\n",
    "               z_score = 0,\n",
    ")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enhancerID_cluster_dict = dict(zip(data.index.values, row_flatCluster))\n",
    "cluster_enhancerID_dict = {x:[] for x in range(1,numRowClusters+1)}\n",
    "for eid in enhancerID_cluster_dict:\n",
    "    ec = enhancerID_cluster_dict[eid]\n",
    "    cluster_enhancerID_dict[ec].append(eid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loci Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promoters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# treatments = summary_frame.columns[5:]\n",
    "promoter_ids = annotated_frame[annotated_frame['Annotation'].str.contains('promoter')].index.values\n",
    "treatments = ['ifng-1h', 'kla-1h', 'veh']\n",
    "id_set_list = []\n",
    "labels = []\n",
    "for t in treatments:\n",
    "    id_set_list.append(set(summary_frame[(summary_frame[t] > 0) &\n",
    "                                         (summary_frame.index.isin(promoter_ids))].index.values))\n",
    "    labels.append(t)\n",
    "matplotlib_venn.venn3(id_set_list, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# treatments = summary_frame.columns[5:]\n",
    "promoter_ids = annotated_frame[annotated_frame['Annotation'].str.contains('promoter')].index.values\n",
    "treatments = ['ifng-1h', 'kla-1h', 'veh']\n",
    "\n",
    "id_set_list = []\n",
    "labels = []\n",
    "for t in treatments:\n",
    "    id_set_list.append(set(summary_frame[(summary_frame[t] > 0) &\n",
    "                                         (~summary_frame.index.isin(promoter_ids))].index.values))\n",
    "    labels.append(t)\n",
    "matplotlib_venn.venn3(id_set_list, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Motif Sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_motif_sequence_dict = {}\n",
    "for seq_index in range(len(sequence_array_list)):\n",
    "    \n",
    "    msl = calc_motif_sequence(seq_index,\n",
    "                        sequence_array_list, \n",
    "                        motif_score_dict, \n",
    "                        motif_score_rc_dict, \n",
    "                        motif_size_dict,\n",
    "                        threshold = 0,\n",
    "                        symmetric_motifs = symmetric_motifs,\n",
    "                       )\n",
    "    seq_id = id_list[seq_index]\n",
    "    id_motif_sequence_dict[seq_id] = msl\n",
    "    if seq_index % 100 == 0:\n",
    "        print(seq_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(id_motif_sequence_dict, open('./id_motif_sequence_dict.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_motif_sequence_dict = pickle.load(open('./id_motif_sequence_dict.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif K-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "frequency_list = []\n",
    "cluster_list = []\n",
    "kmer_list = []\n",
    "\n",
    "for key in cluster_promoterID_dict:\n",
    "    cluster_ids = cluster_promoterID_dict[key]\n",
    "    motif_sequence_list = [id_motif_sequence_dict[x] for x in cluster_ids ]\n",
    "    kmer_count_dict = {}\n",
    "    for msl in motif_sequence_list:\n",
    "        for i in range(0, len(msl) - k + 1):\n",
    "            kmer = msl[i:i+k]\n",
    "            kmer_token = ' * '.join([m['name'] + ' ' + m['orientation'] for m in kmer])\n",
    "            if kmer_token in kmer_count_dict:\n",
    "                kmer_count_dict[kmer_token] +=1\n",
    "            else:\n",
    "                kmer_count_dict[kmer_token] = 1\n",
    "    kmer_count_list = [(x,kmer_count_dict[x]) for x in kmer_count_dict]\n",
    "    \n",
    "    num_seqs = len(motif_sequence_list)\n",
    "    frequencies = [x[1]/num_seqs for x in kmer_count_list]\n",
    "    names = [x[0] for x in kmer_count_list]\n",
    "    \n",
    "    kmer_list = kmer_list + names\n",
    "    cluster_list = cluster_list + [key] * len(frequencies)\n",
    "    frequency_list = frequency_list + frequencies\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({'K-mer':kmer_list,\n",
    "                      'Cluster':cluster_list,\n",
    "                      'Frequency':frequency_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame.sort('Frequency', ascending=False, inplace = True)\n",
    "num_kmers_to_show = 50\n",
    "kmers_to_show = set()\n",
    "ordered_kmers = frame['K-mer'].values\n",
    "counter = 0\n",
    "while len(kmers_to_show) < num_kmers_to_show and counter < len(ordered_kmers):\n",
    "    candidate = ordered_kmers[counter]\n",
    "#     if 'ap-1' in candidate and 'cebp' in candidate:\n",
    "    kmers_to_show.add(ordered_kmers[counter])\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data = frame[frame['K-mer'].isin(kmers_to_show)],\n",
    "               x='K-mer',\n",
    "               y = 'Frequency',\n",
    "               hue = 'Cluster',\n",
    "               kind='bar',\n",
    "               hue_order=[1,2,3,4],\n",
    "               size=8)\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(frame['Frequency'])\n",
    "plt.xlabel('Fraction of Promoters in Cluster that Contains Motif K-mer')\n",
    "plt.ylabel('# Motif K-mer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motif skip-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "frequency_list = []\n",
    "cluster_list = []\n",
    "kmer_list = []\n",
    "for key in cluster_promoterID_dict:\n",
    "    print('cluster', key)\n",
    "    cluster_ids = cluster_promoterID_dict[key]\n",
    "    motif_sequence_list = [id_motif_sequence_dict[x] for x in cluster_ids ]\n",
    "    kmer_count_dict = {}\n",
    "    counter = 0\n",
    "    for msl in motif_sequence_list:\n",
    "        for x in range(0,len(msl) - 2):\n",
    "            for y in range(x+1, len(msl) - 1):\n",
    "                for z in range(y+1, len(msl)):\n",
    "                    kmer = [msl[x], msl[y], msl[z]]\n",
    "                    kmer_token = ' * '.join([m['name'] + ' ' + m['orientation'] for m in kmer])\n",
    "                    if kmer_token in kmer_count_dict:\n",
    "                        kmer_count_dict[kmer_token] +=1\n",
    "                    else:\n",
    "                        kmer_count_dict[kmer_token] = 1\n",
    "        counter+=1\n",
    "        if counter %100 ==0:\n",
    "            print(counter)\n",
    "    kmer_count_list = [(x,kmer_count_dict[x]) for x in kmer_count_dict]\n",
    "    \n",
    "    num_seqs = len(motif_sequence_list)\n",
    "    frequencies = [x[1]/num_seqs for x in kmer_count_list]\n",
    "    names = [x[0] for x in kmer_count_list]\n",
    "    \n",
    "    kmer_list = kmer_list + names\n",
    "    cluster_list = cluster_list + [key] * len(frequencies)\n",
    "    frequency_list = frequency_list + frequencies\n",
    "cluster_name_list = [cluster_name_dict[x] for x in cluster_list]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({'K-mer':kmer_list,\n",
    "                      'Cluster':cluster_list,\n",
    "                      'Frequency':frequency_list,\n",
    "                      'Cluster Name':cluster_name_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame.sort('Frequency', ascending=False, inplace = True)\n",
    "num_kmers_to_show = 50\n",
    "kmers_to_show = set()\n",
    "ordered_kmers = frame['K-mer'].values\n",
    "counter = 0\n",
    "while len(kmers_to_show) < num_kmers_to_show and counter < len(ordered_kmers):\n",
    "    candidate = ordered_kmers[counter]\n",
    "    if not 'mzf1' in candidate and not 'nfi' in candidate:\n",
    "        kmers_to_show.add(ordered_kmers[counter])\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data = frame[frame['K-mer'].isin(kmers_to_show)],\n",
    "               x='K-mer',\n",
    "               y = 'Frequency',\n",
    "               hue = 'Cluster Name',\n",
    "               kind='bar',\n",
    "#                hue_order=[1,2,3,4],\n",
    "               size=8)\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(frame['Frequency'])\n",
    "plt.xlabel('Fraction of Promoters in Cluster that Contains Motif K-mer')\n",
    "plt.ylabel('# Motif K-mer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_=plot_motif_sequence(100,\n",
    "                        sequence_array_list, \n",
    "                        motif_score_dict, \n",
    "                        motif_score_rc_dict, \n",
    "                        motif_size_dict,\n",
    "                        threshold = 0,\n",
    "                        color_dict = None,\n",
    "                        symmetric_motifs = symmetric_motifs,\n",
    "                        algorithm_plot = False,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Expressed TFs and Motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in motif gene mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_motif_dict = {}\n",
    "with open('/gpfs/data01/glasslab/home/jtao/analysis/jaspar_analysis/clustered_motifs/motifGene.txt') as f:\n",
    "    data = f.readlines()\n",
    "for line in data:\n",
    "    tokens = line.strip().split()\n",
    "    motif = tokens[0]\n",
    "    genes = tokens[1].split('|')\n",
    "    if motif in motif_size_dict:\n",
    "        for g in genes:\n",
    "            if g in gene_motif_dict:\n",
    "                gene_motif_dict[g.upper()].append(motif)\n",
    "            else:\n",
    "                gene_motif_dict[g.upper()] = [motif]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot # of motifs vs expression threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expression_threshold = 16\n",
    "# thresholds = [1,2,4,8,16,32,64,128]\n",
    "thresholds = range(100)\n",
    "num_motifs = []\n",
    "for expression_threshold in thresholds:\n",
    "    motifs_at_threshold = []\n",
    "    gene_names = rpkm_mean_frame[\n",
    "        rpkm_mean_frame.ix[:,2:].max(axis=1) >= expression_threshold\n",
    "                    ].ix[:,'All Gene Names'].values\n",
    "    for gn in gene_names:\n",
    "        genes = gn.upper().split('|')\n",
    "        for g in genes:\n",
    "            if g in gene_motif_dict:\n",
    "                motifs_at_threshold += gene_motif_dict[g]\n",
    "    motifs_at_threshold = sorted(set(motifs_at_threshold))\n",
    "    num_motifs.append(len(motifs_at_threshold))\n",
    "plt.plot(thresholds, num_motifs) \n",
    "plt.xlabel('Expression Threshold (RPKM)')\n",
    "plt.ylabel('Number of Motifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expression_threshold = 20\n",
    "motifs_to_include = []\n",
    "gene_names = rpkm_mean_frame[\n",
    "    rpkm_mean_frame.ix[:,2:].max(axis=1) >= expression_threshold\n",
    "                ].ix[:,'All Gene Names'].values\n",
    "for gn in gene_names:\n",
    "    genes = gn.upper().split('|')\n",
    "    for g in genes:\n",
    "        if g in gene_motif_dict:\n",
    "            motifs_to_include += gene_motif_dict[g]\n",
    "motifs_to_include = sorted(set(motifs_to_include))\n",
    "print(len(set(motifs_to_include)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in motifs_to_include:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Enriched Motifs with Top Motif Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promoters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# treatments = summary_frame.columns[5:]\n",
    "promoter_ids = annotated_frame[annotated_frame['Annotation'].str.contains('promoter')].index.values\n",
    "treatments = ['ifng-1h', 'kla-1h', 'veh']\n",
    "# motifs = sorted(topMotifScore_frame.columns.values)\n",
    "motifs = motifs_to_include\n",
    "threshold = 0.05\n",
    "\n",
    "treatment_enrichedMotif_promoter_dict = {}\n",
    "for t in treatments:\n",
    "    treatment_enrichedMotif_promoter_dict[t] = []\n",
    "    treatment_indices = summary_frame[(summary_frame[t] > 0) &\n",
    "                                      (summary_frame.index.isin(promoter_ids))].index.values\n",
    "    other_indices = summary_frame[(summary_frame[t] == 0) &\n",
    "                                  (summary_frame.index.isin(promoter_ids))].index.values\n",
    "    for m in motifs:\n",
    "        treatment_scores = topMotifScore_frame.ix[treatment_indices, m].values\n",
    "        other_scores = topMotifScore_frame.ix[other_indices, m].values\n",
    "        is_enriched = np.mean(treatment_scores) > np.mean(other_scores)\n",
    "        stat, pval = scipy.stats.ttest_ind(treatment_scores, other_scores)\n",
    "        if pval < threshold/len(motifs) and is_enriched:\n",
    "            treatment_enrichedMotif_promoter_dict[t].append(m)\n",
    "            print(t, m,pval)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# treatments = summary_frame.columns[5:]\n",
    "promoter_ids = annotated_frame[annotated_frame['Annotation'].str.contains('promoter')].index.values\n",
    "treatments = ['ifng-1h', 'kla-1h', 'veh']\n",
    "# motifs = sorted(topMotifScore_frame.columns.values)\n",
    "motifs = motifs_to_include\n",
    "threshold = 0.05\n",
    "\n",
    "treatment_enrichedMotif_enhancer_dict = {}\n",
    "for t in treatments:\n",
    "    treatment_enrichedMotif_enhancer_dict[t] = []\n",
    "    treatment_indices = summary_frame[(summary_frame[t] > 0) &\n",
    "                                      (~summary_frame.index.isin(promoter_ids))].index.values\n",
    "    other_indices = summary_frame[(summary_frame[t] == 0) &\n",
    "                                  (~summary_frame.index.isin(promoter_ids))].index.values\n",
    "    for m in motifs:\n",
    "        treatment_scores = topMotifScore_frame.ix[treatment_indices, m].values\n",
    "        other_scores = topMotifScore_frame.ix[other_indices, m].values\n",
    "        is_enriched = np.mean(treatment_scores) > np.mean(other_scores)\n",
    "        stat, pval = scipy.stats.ttest_ind(treatment_scores, other_scores)\n",
    "        if pval < threshold/len(motifs) and is_enriched:\n",
    "            treatment_enrichedMotif_enhancer_dict[t].append(m)\n",
    "            print(t, m,pval)\n",
    "            if treatment == 'kla-1h' and m =='Jun-related_1_merged':\n",
    "#                 sns.distplot(treatment_scores, label='KLA')\n",
    "#                 sns.distplot(other_scores, label = 'Other')\n",
    "                plt.boxplot([treatment_scores+0.5, other_scores])\n",
    "                plt.ylabel('Motif Score')\n",
    "                plt.xticks(range(1,3),['KLA', 'Other'])\n",
    "#                 plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_treatments = sorted(treatment_enrichedMotif_enhancer_dict.keys())\n",
    "\n",
    "matplotlib_venn.venn3([set(treatment_enrichedMotif_enhancer_dict[x]) for x in sorted_treatments], set_labels=sorted_treatments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for treatment in treatment_enrichedMotif_promoter_dict:\n",
    "    promoter_motifs = set(treatment_enrichedMotif_promoter_dict[treatment])\n",
    "    enhancer_motifs = set(treatment_enrichedMotif_enhancer_dict[treatment])\n",
    "    matplotlib_venn.venn2([promoter_motifs, enhancer_motifs], set_labels=['promoter', 'enhancer'])\n",
    "    plt.title(treatment)\n",
    "    plt.show()\n",
    "    print(treatment)\n",
    "    print('enhancer specific', enhancer_motifs - promoter_motifs)\n",
    "    print('promoter specific', promoter_motifs - enhancer_motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treatment_enrichedMotif_enhancer_dict.values()\n",
    "enhancer_motifs = set()\n",
    "for t in treatment_enrichedMotif_enhancer_dict:\n",
    "    enhancer_motifs = enhancer_motifs.union(set(treatment_enrichedMotif_enhancer_dict[t]))\n",
    "enhancer_motifs = sorted(enhancer_motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Promoters On Motif Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "promoter_ids = annotated_frame[annotated_frame['Annotation'].str.contains('promoter')].index.values\n",
    "colorDict = dict(zip(range(numRowClusters),['red', 'blue', 'yellow', 'orange', 'green', 'magenta', 'grey']))\n",
    "data = topMotifScore_frame.ix[sorted(promoterID_cluster_dict.keys()), enhancer_motifs]\n",
    "row_colors = [colorDict[promoterID_cluster_dict[i] -1] for i in data.index.values]\n",
    "sns.clustermap(data,\n",
    "               z_score=0,\n",
    "               yticklabels=False,\n",
    "               metric = 'correlation',\n",
    "               method = 'centroid',\n",
    "               vmin = -2,\n",
    "               vmax = 2,\n",
    "               row_colors= row_colors\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Enhancers on Motif Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "promoter_ids = annotated_frame[annotated_frame['Annotation'].str.contains('promoter')].index.values\n",
    "data = topMotifScore_frame.ix[topMotifScore_frame.index.isin(enhancerID_cluster_dict), enhancer_motifs]\n",
    "row_colors = [colorDict[enhancerID_cluster_dict[i] -1] for i in data.index.values]\n",
    "sns.clustermap(data,\n",
    "               z_score=0,\n",
    "               yticklabels=False,\n",
    "               metric = 'correlation',\n",
    "               method = 'centroid',\n",
    "               row_colors = row_colors,\n",
    "               vmin = -2,\n",
    "               vmax = 2,\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# New Motif Sequence Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Refactor motif_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_motifScore_forward_dict = {}\n",
    "for i in range(len(id_list)):\n",
    "    current_id = id_list[i]\n",
    "    current_dict = {}\n",
    "    for motif in motifs_to_include:\n",
    "        if motif in motif_score_dict:\n",
    "            current_dict[motif] = motif_score_dict[motif][i]\n",
    "    id_motifScore_forward_dict[current_id] = current_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_motifScore_reverse_dict = {}\n",
    "for i in range(len(id_list)):\n",
    "    current_id = id_list[i]\n",
    "    current_dict = {}\n",
    "    for motif in motifs_to_include:\n",
    "        if motif in motif_score_rc_dict:\n",
    "            current_dict[motif] = motif_score_rc_dict[motif][i]\n",
    "    id_motifScore_reverse_dict[current_id] = current_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "seq_array = sequence_array_list[index]\n",
    "forward_score_dict = id_motifScore_forward_dict[id_list[index]]\n",
    "reverse_score_dict = id_motifScore_reverse_dict[id_list[index]]\n",
    "graph, paths, paths_nodata = calc_multi_motif_sequence(seq_array, \n",
    "                              forward_score_dict, \n",
    "                              reverse_score_dict, \n",
    "                              motif_size_dict,\n",
    "                              score_threshold = 5,\n",
    "                              distance_threshold = 200,\n",
    "                              symmetric_motifs = symmetric_motifs\n",
    "                             )\n",
    "print(nx.info(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(graph,\n",
    "        node_size=50,\n",
    "        with_labels=True,\n",
    "        font_size = 8,\n",
    "        pos=graphviz_layout(graph, prog = 'dot'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate motif paths for sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promoters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clustered_promoterIDs = list(promoterID_cluster_dict.keys())\n",
    "\n",
    "id_pathList_promoter_dict = {}\n",
    "counter = 0\n",
    "for index in range(len(clustered_promoterIDs)):\n",
    "    if index % 100 ==0: \n",
    "        print(index)\n",
    "    seq_id = clustered_promoterIDs[index]\n",
    "    seq_array = sequence_array_list[index]\n",
    "    forward_score_dict = id_motifScore_forward_dict[seq_id]\n",
    "    reverse_score_dict = id_motifScore_reverse_dict[seq_id]\n",
    "    result = calc_multi_motif_sequence(seq_array, \n",
    "             forward_score_dict, \n",
    "             reverse_score_dict, \n",
    "             motif_size_dict,\n",
    "             score_threshold = 5,\n",
    "             distance_threshold = 200,\n",
    "             symmetric_motifs = symmetric_motifs\n",
    "             )\n",
    "    graph, paths_with_data, paths_without_data = result\n",
    "    if len(paths_without_data) > 1:\n",
    "        id_pathList_promoter_dict[seq_id] = paths_without_data\n",
    "    else:\n",
    "        counter +=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_paths = []\n",
    "for seq_id in id_pathList_promoter_dict:\n",
    "    paths = id_pathList_promoter_dict[seq_id]\n",
    "    num_paths.append(len(paths))\n",
    "    if len(paths) < 5:\n",
    "        print(seq_id)\n",
    "sns.distplot([np.log2(x) for x in num_paths])\n",
    "plt.ylabel('Frequency (KDE)')\n",
    "plt.xlabel('Number of Motif Sequences (log2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clustered_enhancerIDs = list(enhancerID_cluster_dict.keys())\n",
    "\n",
    "id_pathList_enhancer_dict = {}\n",
    "counter = 0\n",
    "for index in range(len(clustered_enhancerIDs)):\n",
    "    if index % 100 ==0: \n",
    "        print(index)\n",
    "    seq_id = clustered_enhancerIDs[index]\n",
    "    seq_array = sequence_array_list[index]\n",
    "    forward_score_dict = id_motifScore_forward_dict[seq_id]\n",
    "    reverse_score_dict = id_motifScore_reverse_dict[seq_id]\n",
    "    result = calc_multi_motif_sequence(seq_array, \n",
    "             forward_score_dict, \n",
    "             reverse_score_dict, \n",
    "             motif_size_dict,\n",
    "             score_threshold = 5,\n",
    "             distance_threshold = 200,\n",
    "             symmetric_motifs = symmetric_motifs\n",
    "             )\n",
    "    graph, paths_with_data, paths_without_data = result\n",
    "    if len(paths_without_data) > 1:\n",
    "        id_pathList_enhancer_dict[seq_id] = paths_without_data\n",
    "    else:\n",
    "        counter +=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_paths = []\n",
    "for seq_id in id_pathList_enhancer_dict:\n",
    "    paths = id_pathList_enhancer_dict[seq_id]\n",
    "    num_paths.append(len(paths))\n",
    "#     if len(paths) < 5:\n",
    "#         print(seq_id)\n",
    "sns.distplot([np.log2(x) for x in num_paths])\n",
    "plt.ylabel('Frequency (KDE)')\n",
    "plt.xlabel('Number of Motif Sequences (log2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Finding Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_support_level = 25\n",
    "\n",
    "frequent_promoter_patterns = motif_prefix_span([], id_pathList_promoter_dict, min_support_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_lengths = []\n",
    "for seq_id in id_pathList_promoter_dict:\n",
    "    paths = id_pathList_promoter_dict[seq_id]\n",
    "    for p in paths:\n",
    "        path_lengths.append(len(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(path_lengths);\n",
    "plt.xlabel('Length of Motif Path')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_pattern(pattern,\n",
    "                 sorted_ids,\n",
    "                 database,\n",
    "                 result_dict,\n",
    "                 ):\n",
    "    pattern_name = ' * '.join(pattern)\n",
    "    has_pattern_list = []\n",
    "    for seq_id in sorted_ids:\n",
    "        motif_paths = database[seq_id]\n",
    "        has_pattern = False\n",
    "        for path in motif_paths:\n",
    "            path_iter = iter(path)\n",
    "            has_pattern = all([m in path_iter for m in pattern])\n",
    "            if has_pattern:\n",
    "                has_pattern_list.append(1)\n",
    "                break\n",
    "    result_dict.ix[pattern_name] = has_pattern_list\n",
    "    print('done searching for', pattern_name)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pattern_sequence_table_pooled(frequent_patterns, \n",
    "                                         database,\n",
    "                                         num_procs = 8):\n",
    "    '''\n",
    "    Constructs a matrix summarizing which sequences contains a frequent motif pattern\n",
    "    '''\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=num_procs)\n",
    "    manager = multiprocessing.Manager()\n",
    "    has_pattern_dict= manager.dict() # {pattern:[seq_has_pattern_1, seq_has_pattern_2]}\n",
    "    \n",
    "    sorted_ids = sorted(database.keys())   \n",
    "\n",
    "    for i in range(len(frequent_patterns)):\n",
    "        pattern = frequent_patterns[i]\n",
    "        pool.apply_async(find_pattern,\n",
    "                         args=(pattern,\n",
    "                               sorted_ids,\n",
    "                               database,\n",
    "                               has_pattern_dict,\n",
    "                               )       \n",
    "                        )\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    has_pattern_dict = dict(has_pattern_dict)\n",
    "    sequence_pattern_table = pd.DataFrame(has_pattern_dict,\n",
    "                                          index = sorted_ids)\n",
    "    return sequence_pattern_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sequence_pattern_promoter_table = create_pattern_sequence_table(frequent_promoter_patterns, id_pathList_promoter_dict)\n",
    "sequence_pattern_promoter_table = create_pattern_sequence_table_pooled(frequent_promoter_patterns, \n",
    "                                                                id_pathList_promoter_dict,\n",
    "                                                                num_procs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_pattern_promoter_table.to_picke('./sequence_pattern_promoter_table.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(sequence_pattern_promoter_table.sum())\n",
    "plt.xlabel('Frequency of Pattern')\n",
    "plt.ylabel('Frequency (KDE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_support_level = 500\n",
    "\n",
    "frequent_enhancer_patterns = motif_prefix_span([], id_pathList_enhancer_dict, min_support_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(frequent_enhancer_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(frequent_enhancer_patterns, open('./frequent_enhancer_patterns.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_lengths = []\n",
    "for seq_id in id_pathList_enhancer_dict:\n",
    "    paths = id_pathList_enhancer_dict[seq_id]\n",
    "    for p in paths:\n",
    "        path_lengths.append(len(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(path_lengths);\n",
    "plt.xlabel('Length of Motif Path')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_pattern_sequence_table(frequent_patterns, database):\n",
    "#     '''\n",
    "#     Constructs a matrix summarizing which sequences contains a frequent motif pattern\n",
    "#     '''\n",
    "#     sorted_ids = sorted(database.keys())\n",
    "#     pattern_names = [' * '.join(x) for x in frequent_patterns]\n",
    "#     sequence_pattern_table = pd.DataFrame(np.zeros((len(sorted_ids), len(pattern_names))),\n",
    "#                                           index = sorted_ids,\n",
    "#                                           columns = pattern_names)\n",
    "#     for i in range(len(frequent_patterns)):\n",
    "#         if i % 10 == 0:\n",
    "#             print(i)\n",
    "#         pattern = frequent_patterns[i]\n",
    "#         pattern_name = pattern_names[i]\n",
    "#         for seq_id in sorted_ids:\n",
    "#             motif_paths = database[seq_id]\n",
    "#             has_pattern = False\n",
    "#             for path in motif_paths:\n",
    "#                 path_iter = iter(path)\n",
    "#                 has_pattern = all([m in path_iter for m in pattern])\n",
    "#                 if has_pattern:\n",
    "#                     sequence_pattern_table.ix[seq_id, pattern_name] = 1\n",
    "#     return sequence_pattern_table\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence_pattern_enhancer_table = create_pattern_sequence_table(frequent_enhancer_patterns, id_pathList_enhancer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_pattern_enhancer_table = create_pattern_sequence_table_pooled(frequent_enhancer_patterns, \n",
    "                                                                       id_pathList_enhancer_dict,\n",
    "                                                                       num_procs = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(sequence_pattern_enhancer_table.sum())\n",
    "plt.xlabel('Frequency of Pattern')\n",
    "plt.ylabel('Frequency (KDE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promoters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini',\n",
    "                                 max_depth=5, \n",
    "#                                  min_samples_split=50,\n",
    "#                                  min_samples_leaf=50,\n",
    "                                 )\n",
    "labels = [promoterID_cluster_dict[x] for x in sequence_pattern_promoter_table.index.values]\n",
    "\n",
    "\n",
    "clf.fit(sequence_pattern_promoter_table, \n",
    "        labels\n",
    "        )\n",
    "\n",
    "clf.score(sequence_pattern_promoter_table, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf, \n",
    "                     out_file='tree_promoter.dot',\n",
    "                     feature_names = sequence_pattern_promoter_table.columns.values)\n",
    "\n",
    "!dot -Tpng tree_promoter.dot -o tree_promoter.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                 max_depth=6, \n",
    "#                                  min_samples_split=50,\n",
    "#                                  min_samples_leaf=50,\n",
    "                                 )\n",
    "labels = [enhancerID_cluster_dict[x] for x in sequence_pattern_enhancer_table.index.values]\n",
    "\n",
    "\n",
    "clf.fit(sequence_pattern_enhancer_table, \n",
    "        labels\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(clf.score(sequence_pattern_enhancer_table, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf, \n",
    "                     out_file='tree_enhancer.dot',\n",
    "                     feature_names = sequence_pattern_enhancer_table.columns.values)\n",
    "\n",
    "!dot -Tpng tree_enhancer.dot -o tree_enhancer.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
