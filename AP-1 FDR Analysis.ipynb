{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AP-1 FDR Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### header ###\n",
    "__author__ = \"Jenhan Tao\"\n",
    "__license__ = \"BSD\"\n",
    "__email__ = \"jenhantao@gmail.com\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "### imports ###\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle\n",
    "matplotlib.pylab.rcParams['savefig.dpi'] = 200\n",
    "sys.setrecursionlimit(3000)\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workingDirectory = '/home/jtao/analysis/ap1_fdr_analysis/'\n",
    "if not os.path.isdir(workingDirectory):\n",
    "    os.mkdir(workingDirectory)\n",
    "os.chdir(workingDirectory)\n",
    "peakDirectory = '/home/jtao/analysis/ap1_fdr_analysis/peak_files/'\n",
    "tagDirPath = '/home/jtao/analysis/cobinding_motif_analysis/tag_directories_ap1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file directories\n",
    "\n",
    "os.chdir(workingDirectory)\n",
    "\n",
    "# read in and parse name mapping file and create a DataFrame representation\n",
    "\n",
    "strains = []\n",
    "cellTypes = []\n",
    "experiments = []\n",
    "factors = []\n",
    "treatments = []\n",
    "owners = []\n",
    "dates = []\n",
    "sampleNames = []\n",
    "\n",
    "for sample in sorted(os.listdir(tagDirPath)):\n",
    "    metaDataTokens = sample.strip().split(\"_\")\n",
    "    \n",
    "    sampleNames.append(sample)\n",
    "    \n",
    "    # grab metadata from string tokens\n",
    "    strain = metaDataTokens[0]\n",
    "    cellType = metaDataTokens[1]\n",
    "    experiment = metaDataTokens[2]\n",
    "    factor = metaDataTokens[3]\n",
    "    treatment = metaDataTokens[4]\n",
    "    owner = metaDataTokens[5]\n",
    "    date = metaDataTokens[6]\n",
    "    \n",
    "    # append to overall lists\n",
    "    strains.append(strain)\n",
    "    cellTypes.append(cellType)\n",
    "    experiments.append(experiment)\n",
    "    factors.append(factor)\n",
    "    treatments.append(treatment)\n",
    "    owners.append(owner)\n",
    "    dates.append(date)\n",
    "    \n",
    "metadata_frame = pd.DataFrame([strains, \n",
    "                                  cellTypes, \n",
    "                                  experiments, \n",
    "                                  factors, treatments, \n",
    "                                  owners, \n",
    "                                  dates, \n",
    "                                  sampleNames]).transpose()\n",
    "metadata_frame.columns = ['strain', \n",
    "                         'cellType', \n",
    "                         'experiment', \n",
    "                         'factor', \n",
    "                         'treatment', \n",
    "                         'owner', \n",
    "                         'date', \n",
    "                         'sampleName']\n",
    "\n",
    "simpleTreatments = []\n",
    "for t in list(metadata_frame['treatment'].values):\n",
    "    st = t.split('-')[0]\n",
    "    simpleTreatments.append(st)\n",
    "metadata_frame['simpleTreatment'] = simpleTreatments\n",
    "\n",
    "### read in log files ###\n",
    "\n",
    "# create data frame summarizing mapping quality logs\n",
    "_sampleNames = []\n",
    "_totalReads = []\n",
    "_unpairedReads = []\n",
    "_unmappedReads = []\n",
    "_uniquelyMappedReads = []\n",
    "_multiMappedReads = []\n",
    "_tagsPerPosition = []\n",
    "for sample in [x for x in sorted(os.listdir(tagDirPath)) if not 'nput' in x and not 'p65' in x and not 'cebp' in x]:\n",
    "    logFile = [x for x in os.listdir(tagDirPath + '/' + sample) if '.log'in x][0] # find mapping log file\n",
    "    \n",
    "    with open(tagDirPath + '/' + sample + '/' + logFile) as f:\n",
    "        data = f.readlines()\n",
    "            \n",
    "    totalReads = float(data[0].split()[0])\n",
    "    unpairedReads = float(data[1].split()[0])\n",
    "    unmappedReads = float(data[2].split()[0])\n",
    "    uniquelyMappedReads = float(data[3].split()[0])\n",
    "    multiMappedReads = float(data[4].split()[0])\n",
    "\n",
    "    _sampleNames.append(sample)\n",
    "    _totalReads.append(totalReads)\n",
    "    _unpairedReads.append(unpairedReads)\n",
    "    _unmappedReads.append(unmappedReads)\n",
    "    _uniquelyMappedReads.append(uniquelyMappedReads)\n",
    "    _multiMappedReads.append(multiMappedReads)\n",
    "\n",
    "for tagdir in os.listdir(tagDirPath):\n",
    "    with open(tagDirPath + '/' + tagdir + '/tagInfo.txt') as f:\n",
    "        data = f.readlines()\n",
    "        tpp = float(data[5].strip().split('=')[1])\n",
    "        _tagsPerPosition.append(tpp)\n",
    "mappingStats_frame = pd.DataFrame([_sampleNames,\n",
    "                                   _totalReads, \n",
    "                                   _unpairedReads, \n",
    "                                   _unmappedReads, \n",
    "                                   _uniquelyMappedReads, \n",
    "                                   _multiMappedReads,\n",
    "                                   _tagsPerPosition]).transpose()\n",
    "mappingStats_frame.columns = ['sampleName',\n",
    "                              'totalReads', \n",
    "                              'unpairedReads', \n",
    "                              'unmappedReads', \n",
    "                              'uniquelyMappedReads', \n",
    "                              'multiMappedReads',\n",
    "                              'tagsPerPosition']\n",
    "\n",
    "# calculate fractions from read counts\n",
    "mappingStats_frame['uniquelyMappedFraction'] = mappingStats_frame['uniquelyMappedReads'] / mappingStats_frame['totalReads']\n",
    "mappingStats_frame['mappedFraction'] = (mappingStats_frame['uniquelyMappedReads'] + mappingStats_frame['multiMappedReads']) / mappingStats_frame['totalReads']\n",
    "\n",
    "\n",
    "\n",
    "summary_frame = metadata_frame.merge(mappingStats_frame, on='sampleName')\n",
    "summary_frame.index  = pd.MultiIndex.from_arrays([list(summary_frame['strain'].values), list(summary_frame['factor'].values), list(summary_frame['simpleTreatment'].values)])\n",
    "mapping_summary_frame = summary_frame.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter samples according to threshold for the fraction of uniquely mapped reads\n",
    "mappedFractionThreshold = 0.0\n",
    "uniquelyMappedReadThreshold = 1000000\n",
    "\n",
    "filtered_summary_frame = mapping_summary_frame.copy()\n",
    "# filter on fraction of mapped reads\n",
    "filtered_summary_frame = filtered_summary_frame[filtered_summary_frame['mappedFraction'] >= mappedFractionThreshold]\n",
    "# filter on total mapped reads\n",
    "filtered_summary_frame = filtered_summary_frame[filtered_summary_frame['uniquelyMappedReads'] >= uniquelyMappedReadThreshold]\n",
    "\n",
    "# get samples that were discarded\n",
    "discardedSampleNames = [x for x in summary_frame['sampleName'].values if not x in filtered_summary_frame['sampleName'].values]\n",
    "discarded_summary_frame = summary_frame[summary_frame['sampleName'].isin(discardedSampleNames)]\n",
    "print(\"Number of Samples:\", summary_frame.shape[0])\n",
    "print(\"Number of discarded samples:\",discarded_summary_frame.shape[0])\n",
    "print(\"Number of Samples remaining after filtering:\", filtered_summary_frame.shape[0])\n",
    "\n",
    "# generate simplified name for naming output files\n",
    "factorTreatment_count_dict = {} #{factor-treatment:count}\n",
    "simplifiedNames = []\n",
    "for simpleNameRoot in list((filtered_summary_frame['strain'] \n",
    "                            + '_' + filtered_summary_frame['factor'] \n",
    "                            + '_' + filtered_summary_frame[\"simpleTreatment\"]\n",
    "                            + '_' + filtered_summary_frame['date']).values):\n",
    "    if not simpleNameRoot in factorTreatment_count_dict:\n",
    "        factorTreatment_count_dict[simpleNameRoot] = 1\n",
    "    else:\n",
    "        factorTreatment_count_dict[simpleNameRoot] += 1\n",
    "    simplifiedName = (simpleNameRoot + '_' + str(factorTreatment_count_dict[simpleNameRoot])).lower()\n",
    "    simplifiedNames.append(simplifiedName)\n",
    "\n",
    "filtered_summary_frame[\"simplifiedName\"] = simplifiedNames\n",
    "\n",
    "originalName_simpleName_dict = dict(zip(filtered_summary_frame['sampleName'].values,\n",
    "                                       filtered_summary_frame['simplifiedName'].values))\n",
    "simpleName_originalName_dict = dict(zip(filtered_summary_frame['simplifiedName'].values,\n",
    "                                       filtered_summary_frame['sampleName'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%capture \n",
    "# suppress output - this can be saved to a variable (like a log file)\n",
    "\n",
    "### call peaks ###\n",
    "# iterate through each individual file\n",
    "if not os.path.exists(peakDirectory):\n",
    "    os.makedirs(peakDirectory)\n",
    "\n",
    "# make peak files with simplified names\n",
    "# filteredSamples = list(filtered_mappingStats_frame['sampleName'].values)\n",
    "scriptFile = open('./peakCalling_homer.sh', 'w')\n",
    "\n",
    "\n",
    "for tagDir in filtered_summary_frame['sampleName'].values:\n",
    "    # call peaks only for experiments that passed thresholding\n",
    "    metaDataTokens = tagDir.split(\"_\")\n",
    "    treatment = metaDataTokens[4]\n",
    "\n",
    "    peakFileName = originalName_simpleName_dict[tagDir] + \"_default_peaks.tsv\"\n",
    "\n",
    "    if \"veh\" in treatment.lower():\n",
    "        inputDir = '/home/jtao/analysis/ap1_analysis/input_data/C57Bl6_Thiomac_ChIP_Input_Veh_GJF_15-03-20'\n",
    "    elif \"kla\" in treatment.lower():\n",
    "        inputDir = '/home/jtao/analysis/ap1_analysis/input_data/C57Bl6_Thiomac_ChIP_Input_KLA-1h_GJF_15-03-20'\n",
    "    \n",
    "    scriptFile.write('findPeaks ' + tagDirPath + '/' + tagDir + \n",
    "                 ' -i ' + inputDir\n",
    "                 + ' -style factor -size 200 -norm 1e6 > ' + \n",
    "                 peakDirectory +'/' + peakFileName + ' &\\n')\n",
    "scriptFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm ./peak_files/*\n",
    "chmod a+x ./*sh\n",
    "bash ./peakCalling_homer.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy IDR Peak files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d ./idr_peak_files ]; then mkdir ./idr_peak_files; else rm ./idr_peak_files/*; fi\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/peak_files/c57bl6* ./idr_peak_files/\n",
    "rm ./idr_peak_files/*p65*\n",
    "rm ./idr_peak_files/*cebp*\n",
    "for i in ./idr_peak_files/*;\n",
    "    do mv $i ${i/_peaks.tsv/_idr_peaks.tsv};\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter away peaks that have less than 16 normalized tags\n",
    "# rename peak files to remove redundant information\n",
    "chroms = ['chr1',\n",
    " 'chr10',\n",
    " 'chr11',\n",
    " 'chr12',\n",
    " 'chr13',\n",
    " 'chr14',\n",
    " 'chr15',\n",
    " 'chr16',\n",
    " 'chr17',\n",
    " 'chr18',\n",
    " 'chr19',\n",
    " 'chr2',\n",
    " 'chr3',\n",
    " 'chr4',\n",
    " 'chr5',\n",
    " 'chr6',\n",
    " 'chr7',\n",
    " 'chr8',\n",
    " 'chr9',\n",
    " 'chrX']\n",
    "seen_conditions = set()\n",
    "peakDirectory = './peak_files/'\n",
    "filtered_peak_directory = './filtered_peak_files/'\n",
    "if not os.path.isdir(filtered_peak_directory):\n",
    "    os.mkdir(filtered_peak_directory)\n",
    "for f in os.listdir(peakDirectory):\n",
    "    print(f)\n",
    "    tokens = f.split('_')\n",
    "    condition = tokens[0] +'_'+ tokens[1] + '_' + tokens[2]\n",
    "    \n",
    "    if condition in seen_conditions:\n",
    "        new_name = filtered_peak_directory+'/'+condition + '_rep2_peaks.tsv' \n",
    "    else:\n",
    "        new_name = filtered_peak_directory+'/'+condition + '_rep1_peaks.tsv' \n",
    "        seen_conditions.add(condition)\n",
    "    current_frame = pd.read_csv(peakDirectory + '/' + f, sep = '\\t', skiprows=39)\n",
    "    filtered_frame = current_frame[(current_frame['chr'].isin(chroms)) &\n",
    "                                  (current_frame['Normalized Tag Count'] >= 1)]\n",
    "    filtered_frame.to_csv(new_name, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter away peaks that have less than 16 normalized tags\n",
    "# rename peak files to remove redundant information\n",
    "chroms = ['chr1',\n",
    " 'chr10',\n",
    " 'chr11',\n",
    " 'chr12',\n",
    " 'chr13',\n",
    " 'chr14',\n",
    " 'chr15',\n",
    " 'chr16',\n",
    " 'chr17',\n",
    " 'chr18',\n",
    " 'chr19',\n",
    " 'chr2',\n",
    " 'chr3',\n",
    " 'chr4',\n",
    " 'chr5',\n",
    " 'chr6',\n",
    " 'chr7',\n",
    " 'chr8',\n",
    " 'chr9',\n",
    " 'chrX']\n",
    "seen_conditions = set()\n",
    "filtered_peak_directory = './filtered_idr_peak_files/'\n",
    "if not os.path.isdir(filtered_peak_directory):\n",
    "    os.mkdir(filtered_peak_directory)\n",
    "peakDirectory = './idr_peak_files/'\n",
    "for f in os.listdir(peakDirectory):\n",
    "    print(f)\n",
    "    tokens = f.split('_')\n",
    "    condition = tokens[0] +'_'+ tokens[1] + '_' + tokens[2]\n",
    "    new_name = filtered_peak_directory+'/'+condition + '_idr_peaks.tsv' \n",
    "    current_frame = pd.read_csv(peakDirectory + '/' + f, sep = '\\t')\n",
    "    filtered_frame = current_frame[current_frame['chr'].isin(chroms)]\n",
    "    filtered_frame.to_csv(new_name, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to BED Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# individual replicates\n",
    "if [ ! -d ./bed_files ]; then mkdir ./bed_files/; else rm ./bed_files/*; fi\n",
    "\n",
    "for i in ./filtered_peak_files/*tsv;\n",
    "    do echo $i;\n",
    "    outpath=./bed_files/${i##*/}\n",
    "    outpath=${outpath/_peaks.tsv/.bed}\n",
    "    echo $outpath\n",
    "    pos2bed.pl $i > ./tmp\n",
    "    tail -n +2 ./tmp > $outpath\n",
    "done\n",
    "\n",
    "# idr peaks\n",
    "for i in ./filtered_idr_peak_files/*tsv;\n",
    "    do echo $i;\n",
    "    outpath=./bed_files/${i##*/}\n",
    "    outpath=${outpath/_peaks.tsv/.bed}\n",
    "    echo $outpath\n",
    "    pos2bed.pl $i > ./tmp\n",
    "    tail -n +2 ./tmp > $outpath\n",
    "done\n",
    "rm tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d ./fasta_files ]; then mkdir ./fasta_files/; else rm ./fasta_files/*; fi\n",
    "\n",
    "for i in ./bed_files/*bed; \n",
    "    do echo $i;\n",
    "    outpath=./fasta_files/${i##*/}\n",
    "    outpath=${outpath/.bed/.fasta}\n",
    "    /gpfs/data01/glasslab/home/jtao/code/tba/extract_sequences.py $i mm10 $outpath\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm ./make_background.sh\n",
    "script_path=\"./make_background.sh\"\n",
    "if [ ! -d ./background/ ]; then mkdir ./background/ ; fi\n",
    "for i in ./bed_files/*bed;\n",
    "do \n",
    "    factor=${i##*/};\n",
    "    factor=${factor%.bed};\n",
    "\n",
    "    fasta_path=\"./background/${factor}_background.fasta\"\n",
    "    bed_path=\"./background/${factor}_background.bed\"\n",
    "    if [ ! -f $fasta_path ];\n",
    "    then\n",
    "    echo \"/home/jtao/code/tba/generate_background_coordinates.py $i ./background/ -genome mm10\";\n",
    "    echo \"mv ./background/background.bed $bed_path\";\n",
    "    echo \"mv ./background/background.fasta $fasta_path\";\n",
    "    echo \"/home/jtao/code/tba/generate_background_coordinates.py $i ./background/ -genome mm10\" >> $script_path;\n",
    "    echo \"mv ./background/background.bed $bed_path\" >> $script_path;\n",
    "    echo \"mv ./background/background.fasta $fasta_path\" >> $script_path;\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm ./background/*\n",
    "chmod a+x ./*sh\n",
    "bash ./make_background.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "positive_seq_dir=\"./fasta_files/\"\n",
    "negative_seq_dir=\"./background/\"\n",
    "out_dir=\"./tba_output/\"\n",
    "script_path='./calculate_features.sh'\n",
    "motif_dir='./jaspar_2016_curated_homerFormat/'\n",
    "if [ -f $script_path ]; then rm $script_path; else touch $script_path; fi\n",
    "if [ ! -d $out_dir ]; then mkdir $out_dir; fi\n",
    "\n",
    "for positive_seq_path in $positive_seq_dir/*;\n",
    "    do factor=${positive_seq_path##./*/};\n",
    "    factor=${factor%.fasta};\n",
    "\n",
    "    negative_seq_path=${negative_seq_dir}/${factor}_background.fasta;\n",
    "    echo \"python /home/jtao/code/tba/create_features.py $positive_seq_path $negative_seq_path $out_dir ${motif_dir}/* -num_proc 28\" >>$script_path\n",
    "    echo \"mv $out_dir/labels.txt $out_dir/${factor}_labels.txt\" >> $script_path\n",
    "    echo \"mv $out_dir/standardized_features.tsv $out_dir/${factor}_standardized_features.tsv\" >> $script_path\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
