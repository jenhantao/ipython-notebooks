{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AP-1 FDR Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### header ###\n",
    "__author__ = \"Jenhan Tao\"\n",
    "__license__ = \"BSD\"\n",
    "__email__ = \"jenhantao@gmail.com\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "### imports ###\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle\n",
    "matplotlib.pylab.rcParams['savefig.dpi'] = 200\n",
    "sys.setrecursionlimit(3000)\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workingDirectory = '/home/jtao/analysis/ap1_fdr_analysis/'\n",
    "if not os.path.isdir(workingDirectory):\n",
    "    os.mkdir(workingDirectory)\n",
    "os.chdir(workingDirectory)\n",
    "peakDirectory = '/home/jtao/analysis/ap1_fdr_analysis/peak_files/'\n",
    "tagDirPath = '/home/jtao/analysis/cobinding_motif_analysis/tag_directories_ap1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data01/glasslab/home/jtao/software/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:118: FutureWarning: sort(....) is deprecated, use sort_index(.....)\n"
     ]
    }
   ],
   "source": [
    "# file directories\n",
    "\n",
    "os.chdir(workingDirectory)\n",
    "\n",
    "# read in and parse name mapping file and create a DataFrame representation\n",
    "\n",
    "strains = []\n",
    "cellTypes = []\n",
    "experiments = []\n",
    "factors = []\n",
    "treatments = []\n",
    "owners = []\n",
    "dates = []\n",
    "sampleNames = []\n",
    "\n",
    "for sample in sorted(os.listdir(tagDirPath)):\n",
    "    metaDataTokens = sample.strip().split(\"_\")\n",
    "    \n",
    "    sampleNames.append(sample)\n",
    "    \n",
    "    # grab metadata from string tokens\n",
    "    strain = metaDataTokens[0]\n",
    "    cellType = metaDataTokens[1]\n",
    "    experiment = metaDataTokens[2]\n",
    "    factor = metaDataTokens[3]\n",
    "    treatment = metaDataTokens[4]\n",
    "    owner = metaDataTokens[5]\n",
    "    date = metaDataTokens[6]\n",
    "    \n",
    "    # append to overall lists\n",
    "    strains.append(strain)\n",
    "    cellTypes.append(cellType)\n",
    "    experiments.append(experiment)\n",
    "    factors.append(factor)\n",
    "    treatments.append(treatment)\n",
    "    owners.append(owner)\n",
    "    dates.append(date)\n",
    "    \n",
    "metadata_frame = pd.DataFrame([strains, \n",
    "                                  cellTypes, \n",
    "                                  experiments, \n",
    "                                  factors, treatments, \n",
    "                                  owners, \n",
    "                                  dates, \n",
    "                                  sampleNames]).transpose()\n",
    "metadata_frame.columns = ['strain', \n",
    "                         'cellType', \n",
    "                         'experiment', \n",
    "                         'factor', \n",
    "                         'treatment', \n",
    "                         'owner', \n",
    "                         'date', \n",
    "                         'sampleName']\n",
    "\n",
    "simpleTreatments = []\n",
    "for t in list(metadata_frame['treatment'].values):\n",
    "    st = t.split('-')[0]\n",
    "    simpleTreatments.append(st)\n",
    "metadata_frame['simpleTreatment'] = simpleTreatments\n",
    "\n",
    "### read in log files ###\n",
    "\n",
    "# create data frame summarizing mapping quality logs\n",
    "_sampleNames = []\n",
    "_totalReads = []\n",
    "_unpairedReads = []\n",
    "_unmappedReads = []\n",
    "_uniquelyMappedReads = []\n",
    "_multiMappedReads = []\n",
    "_tagsPerPosition = []\n",
    "for sample in [x for x in sorted(os.listdir(tagDirPath)) if not 'nput' in x and not 'p65' in x and not 'cebp' in x]:\n",
    "    logFile = [x for x in os.listdir(tagDirPath + '/' + sample) if '.log'in x][0] # find mapping log file\n",
    "    \n",
    "    with open(tagDirPath + '/' + sample + '/' + logFile) as f:\n",
    "        data = f.readlines()\n",
    "            \n",
    "    totalReads = float(data[0].split()[0])\n",
    "    unpairedReads = float(data[1].split()[0])\n",
    "    unmappedReads = float(data[2].split()[0])\n",
    "    uniquelyMappedReads = float(data[3].split()[0])\n",
    "    multiMappedReads = float(data[4].split()[0])\n",
    "\n",
    "    _sampleNames.append(sample)\n",
    "    _totalReads.append(totalReads)\n",
    "    _unpairedReads.append(unpairedReads)\n",
    "    _unmappedReads.append(unmappedReads)\n",
    "    _uniquelyMappedReads.append(uniquelyMappedReads)\n",
    "    _multiMappedReads.append(multiMappedReads)\n",
    "\n",
    "for tagdir in os.listdir(tagDirPath):\n",
    "    with open(tagDirPath + '/' + tagdir + '/tagInfo.txt') as f:\n",
    "        data = f.readlines()\n",
    "        tpp = float(data[5].strip().split('=')[1])\n",
    "        _tagsPerPosition.append(tpp)\n",
    "mappingStats_frame = pd.DataFrame([_sampleNames,\n",
    "                                   _totalReads, \n",
    "                                   _unpairedReads, \n",
    "                                   _unmappedReads, \n",
    "                                   _uniquelyMappedReads, \n",
    "                                   _multiMappedReads,\n",
    "                                   _tagsPerPosition]).transpose()\n",
    "mappingStats_frame.columns = ['sampleName',\n",
    "                              'totalReads', \n",
    "                              'unpairedReads', \n",
    "                              'unmappedReads', \n",
    "                              'uniquelyMappedReads', \n",
    "                              'multiMappedReads',\n",
    "                              'tagsPerPosition']\n",
    "\n",
    "# calculate fractions from read counts\n",
    "mappingStats_frame['uniquelyMappedFraction'] = mappingStats_frame['uniquelyMappedReads'] / mappingStats_frame['totalReads']\n",
    "mappingStats_frame['mappedFraction'] = (mappingStats_frame['uniquelyMappedReads'] + mappingStats_frame['multiMappedReads']) / mappingStats_frame['totalReads']\n",
    "\n",
    "\n",
    "\n",
    "summary_frame = metadata_frame.merge(mappingStats_frame, on='sampleName')\n",
    "summary_frame.index  = pd.MultiIndex.from_arrays([list(summary_frame['strain'].values), list(summary_frame['factor'].values), list(summary_frame['simpleTreatment'].values)])\n",
    "mapping_summary_frame = summary_frame.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 36\n",
      "Number of discarded samples: 0\n",
      "Number of Samples remaining after filtering: 36\n"
     ]
    }
   ],
   "source": [
    "# filter samples according to threshold for the fraction of uniquely mapped reads\n",
    "mappedFractionThreshold = 0.0\n",
    "uniquelyMappedReadThreshold = 1000000\n",
    "\n",
    "filtered_summary_frame = mapping_summary_frame.copy()\n",
    "# filter on fraction of mapped reads\n",
    "filtered_summary_frame = filtered_summary_frame[filtered_summary_frame['mappedFraction'] >= mappedFractionThreshold]\n",
    "# filter on total mapped reads\n",
    "filtered_summary_frame = filtered_summary_frame[filtered_summary_frame['uniquelyMappedReads'] >= uniquelyMappedReadThreshold]\n",
    "\n",
    "# get samples that were discarded\n",
    "discardedSampleNames = [x for x in summary_frame['sampleName'].values if not x in filtered_summary_frame['sampleName'].values]\n",
    "discarded_summary_frame = summary_frame[summary_frame['sampleName'].isin(discardedSampleNames)]\n",
    "print(\"Number of Samples:\", summary_frame.shape[0])\n",
    "print(\"Number of discarded samples:\",discarded_summary_frame.shape[0])\n",
    "print(\"Number of Samples remaining after filtering:\", filtered_summary_frame.shape[0])\n",
    "\n",
    "# generate simplified name for naming output files\n",
    "factorTreatment_count_dict = {} #{factor-treatment:count}\n",
    "simplifiedNames = []\n",
    "for simpleNameRoot in list((filtered_summary_frame['strain'] \n",
    "                            + '_' + filtered_summary_frame['factor'] \n",
    "                            + '_' + filtered_summary_frame[\"simpleTreatment\"]\n",
    "                            + '_' + filtered_summary_frame['date']).values):\n",
    "    if not simpleNameRoot in factorTreatment_count_dict:\n",
    "        factorTreatment_count_dict[simpleNameRoot] = 1\n",
    "    else:\n",
    "        factorTreatment_count_dict[simpleNameRoot] += 1\n",
    "    simplifiedName = (simpleNameRoot + '_' + str(factorTreatment_count_dict[simpleNameRoot])).lower()\n",
    "    simplifiedNames.append(simplifiedName)\n",
    "\n",
    "filtered_summary_frame[\"simplifiedName\"] = simplifiedNames\n",
    "\n",
    "originalName_simpleName_dict = dict(zip(filtered_summary_frame['sampleName'].values,\n",
    "                                       filtered_summary_frame['simplifiedName'].values))\n",
    "simpleName_originalName_dict = dict(zip(filtered_summary_frame['simplifiedName'].values,\n",
    "                                       filtered_summary_frame['sampleName'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%capture \n",
    "# suppress output - this can be saved to a variable (like a log file)\n",
    "\n",
    "### call peaks ###\n",
    "# iterate through each individual file\n",
    "if not os.path.exists(peakDirectory):\n",
    "    os.makedirs(peakDirectory)\n",
    "\n",
    "# make peak files with simplified names\n",
    "# filteredSamples = list(filtered_mappingStats_frame['sampleName'].values)\n",
    "scriptFile = open('./peakCalling_homer.sh', 'w')\n",
    "\n",
    "\n",
    "for tagDir in filtered_summary_frame['sampleName'].values:\n",
    "    # call peaks only for experiments that passed thresholding\n",
    "    metaDataTokens = tagDir.split(\"_\")\n",
    "    treatment = metaDataTokens[4]\n",
    "\n",
    "    peakFileName = originalName_simpleName_dict[tagDir] + \"_default_peaks.tsv\"\n",
    "\n",
    "    if \"veh\" in treatment.lower():\n",
    "        inputDir = '/home/jtao/analysis/ap1_analysis/input_data/C57Bl6_Thiomac_ChIP_Input_Veh_GJF_15-03-20'\n",
    "    elif \"kla\" in treatment.lower():\n",
    "        inputDir = '/home/jtao/analysis/ap1_analysis/input_data/C57Bl6_Thiomac_ChIP_Input_KLA-1h_GJF_15-03-20'\n",
    "    \n",
    "    scriptFile.write('findPeaks ' + tagDirPath + '/' + tagDir + \n",
    "                 ' -i ' + inputDir\n",
    "                 + ' -style factor -size 200 -norm 1e6 > ' + \n",
    "                 peakDirectory +'/' + peakFileName + ' &\\n')\n",
    "scriptFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm ./peak_files/*\n",
    "chmod a+x ./*sh\n",
    "bash ./peakCalling_homer.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c57bl6_atf3_kla_16-04-21_1_default_peaks.tsv\n",
      "c57bl6_jund_kla_16-04-21_1_default_peaks.tsv\n",
      "c57bl6_cjun_veh_16-04-21_1_default_peaks.tsv\n",
      "c57bl6_fos_kla_14-03-17_1_default_peaks.tsv\n",
      "c57bl6_fra2_veh_14-03-17_1_default_peaks.tsv\n",
      "c57bl6_atf3_kla_16-08-16_1_default_peaks.tsv\n",
      "c57bl6_jund_veh_16-07-23_1_default_peaks.tsv\n",
      "c57bl6_fos_kla_15-02-06_1_default_peaks.tsv\n",
      "c57bl6_jund_kla_15-11-18_1_default_peaks.tsv\n",
      "c57bl6_pu1_kla_11-05-12_1_default_peaks.tsv\n",
      "c57bl6_atf3_veh_16-07-23_1_default_peaks.tsv\n",
      "c57bl6_fos_veh_14-03-17_1_default_peaks.tsv\n",
      "c57bl6_cjun_veh_16-06-14_1_default_peaks.tsv\n",
      "c57bl6_jund_veh_16-04-21_1_default_peaks.tsv\n",
      "c57bl6_cjun_kla_16-04-21_1_default_peaks.tsv\n",
      "c57bl6_junb_kla_14-03-17_1_default_peaks.tsv\n",
      "c57bl6_fra2_kla_16-04-21_1_default_peaks.tsv\n",
      "c57bl6_junb_kla_15-02-06_1_default_peaks.tsv\n",
      "c57bl6_junb_veh_15-02-06_1_default_peaks.tsv\n",
      "c57bl6_pu1_veh_11-05-12_1_default_peaks.tsv\n",
      "c57bl6_fos_veh_15-02-06_1_default_peaks.tsv\n",
      "c57bl6_pu1_veh_16-06-14_1_default_peaks.tsv\n",
      "c57bl6_fra2_kla_16-08-16_1_default_peaks.tsv\n",
      "c57bl6_atf3_veh_16-04-21_1_default_peaks.tsv\n",
      "c57bl6_fra2_veh_16-04-21_1_default_peaks.tsv\n",
      "c57bl6_junb_veh_16-04-21_1_default_peaks.tsv\n",
      "c57bl6_pu1_kla_12-01-14_1_default_peaks.tsv\n",
      "c57bl6_cjun_kla_15-11-18_1_default_peaks.tsv\n"
     ]
    }
   ],
   "source": [
    "# filter away peaks that have less than 16 normalized tags\n",
    "# rename peak files to remove redundant information\n",
    "chroms = ['chr1',\n",
    " 'chr10',\n",
    " 'chr11',\n",
    " 'chr12',\n",
    " 'chr13',\n",
    " 'chr14',\n",
    " 'chr15',\n",
    " 'chr16',\n",
    " 'chr17',\n",
    " 'chr18',\n",
    " 'chr19',\n",
    " 'chr2',\n",
    " 'chr3',\n",
    " 'chr4',\n",
    " 'chr5',\n",
    " 'chr6',\n",
    " 'chr7',\n",
    " 'chr8',\n",
    " 'chr9',\n",
    " 'chrX']\n",
    "seen_conditions = set()\n",
    "filtered_peak_directory = './filtered_peak_files/'\n",
    "if not os.path.isdir(filtered_peak_directory):\n",
    "    os.mkdir(filtered_peak_directory)\n",
    "for f in os.listdir(peakDirectory):\n",
    "    print(f)\n",
    "    tokens = f.split('_')\n",
    "    condition = tokens[0] +'_'+ tokens[1] + '_' + tokens[2]\n",
    "    \n",
    "    if condition in seen_conditions:\n",
    "        new_name = filtered_peak_directory+'/'+condition + '_rep2_peaks.tsv' \n",
    "    else:\n",
    "        new_name = filtered_peak_directory+'/'+condition + '_rep1_peaks.tsv' \n",
    "        seen_conditions.add(condition)\n",
    "    current_frame = pd.read_csv(peakDirectory + '/' + f, sep = '\\t', skiprows=39)\n",
    "    filtered_frame = current_frame[(current_frame['chr'].isin(chroms)) &\n",
    "                                  (current_frame['Normalized Tag Count'] >= 1)]\n",
    "    filtered_frame.to_csv(new_name, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy IDR Peak files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d ./idr_peak_files ]; then mkdir ./idr_peak_files; else rm ./idr_peak_files/*; fi\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/peak_files/c57bl6* ./idr_peak_files/\n",
    "rm ./idr_peak_files/*p65*\n",
    "rm ./idr_peak_files/*cebp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c57bl6_atf3_kla_peaks.tsv  c57bl6_fos_veh_peaks.tsv   c57bl6_jund_kla_peaks.tsv\r\n",
      "c57bl6_atf3_veh_peaks.tsv  c57bl6_fra2_kla_peaks.tsv  c57bl6_jund_veh_peaks.tsv\r\n",
      "c57bl6_cjun_kla_peaks.tsv  c57bl6_fra2_veh_peaks.tsv  c57bl6_pu1_kla_peaks.tsv\r\n",
      "c57bl6_cjun_veh_peaks.tsv  c57bl6_junb_kla_peaks.tsv  c57bl6_pu1_veh_peaks.tsv\r\n",
      "c57bl6_fos_kla_peaks.tsv   c57bl6_junb_veh_peaks.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./idr_peak_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c57bl6_atf3_kla_rep1_peaks.tsv\tc57bl6_fra2_veh_rep1_peaks.tsv\r\n",
      "c57bl6_atf3_kla_rep2_peaks.tsv\tc57bl6_fra2_veh_rep2_peaks.tsv\r\n",
      "c57bl6_atf3_veh_rep1_peaks.tsv\tc57bl6_junb_kla_rep1_peaks.tsv\r\n",
      "c57bl6_atf3_veh_rep2_peaks.tsv\tc57bl6_junb_kla_rep2_peaks.tsv\r\n",
      "c57bl6_cjun_kla_rep1_peaks.tsv\tc57bl6_junb_veh_rep1_peaks.tsv\r\n",
      "c57bl6_cjun_kla_rep2_peaks.tsv\tc57bl6_junb_veh_rep2_peaks.tsv\r\n",
      "c57bl6_cjun_veh_rep1_peaks.tsv\tc57bl6_jund_kla_rep1_peaks.tsv\r\n",
      "c57bl6_cjun_veh_rep2_peaks.tsv\tc57bl6_jund_kla_rep2_peaks.tsv\r\n",
      "c57bl6_fos_kla_rep1_peaks.tsv\tc57bl6_jund_veh_rep1_peaks.tsv\r\n",
      "c57bl6_fos_kla_rep2_peaks.tsv\tc57bl6_jund_veh_rep2_peaks.tsv\r\n",
      "c57bl6_fos_veh_rep1_peaks.tsv\tc57bl6_pu1_kla_rep1_peaks.tsv\r\n",
      "c57bl6_fos_veh_rep2_peaks.tsv\tc57bl6_pu1_kla_rep2_peaks.tsv\r\n",
      "c57bl6_fra2_kla_rep1_peaks.tsv\tc57bl6_pu1_veh_rep1_peaks.tsv\r\n",
      "c57bl6_fra2_kla_rep2_peaks.tsv\tc57bl6_pu1_veh_rep2_peaks.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./filtered_peak_files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Backgrounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Motif Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idr_f in os.listdir('./idr_peak_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
