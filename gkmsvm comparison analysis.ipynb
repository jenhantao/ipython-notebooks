{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gkmsvm comparison analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/gpfs/data01/glasslab/home/jtao/perl5/bin:/gpfs/data01/glasslab/home/jtao/software/anaconda3/bin:/home/jtao/software/bin:/usr/local/sbin:/usr/sbin:/usr/bin:/usr/local/bin:/usr/bin:/gpfs/data01/glasslab/home/jtao/software/homer/bin:/gpfs/data01/glasslab/home/jtao/software/weblogo:/home/jtao/code/seq_merge_pipe:/home/vlink/mouse_strains/marge/shifting:/bioinformatics/glassutils/scripts:/bioinformatics/software/meme/bin:/home/jtao/software/lsgkm/bin\n"
     ]
    }
   ],
   "source": [
    "### header ###\n",
    "__author__ = \"Jenhan Tao\"\n",
    "__license__ = \"BSD\"\n",
    "__email__ = \"jenhantao@gmail.com\"\n",
    "\n",
    "### imports ###\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib\n",
    "import itertools\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "import matplotlib_venn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from random import shuffle\n",
    "\n",
    "### notebook specific configuration ###\n",
    "%matplotlib inline\n",
    "matplotlib.pylab.rcParams['savefig.dpi'] = 200\n",
    "sys.setrecursionlimit(5000)\n",
    "os.chdir('/gpfs/data01/glasslab/home/jtao/analysis/method_comparison_analysis/')\n",
    "sns.set_context('notebook')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env PATH=/gpfs/data01/glasslab/home/jtao/perl5/bin:/gpfs/data01/glasslab/home/jtao/software/anaconda3/bin:/home/jtao/software/bin:/usr/local/sbin:/usr/sbin:/usr/bin:/usr/local/bin:/usr/bin:/gpfs/data01/glasslab/home/jtao/software/homer/bin:/gpfs/data01/glasslab/home/jtao/software/weblogo:/home/jtao/code/seq_merge_pipe:/home/vlink/mouse_strains/marge/shifting:/bioinformatics/glassutils/scripts:/bioinformatics/software/meme/bin:/home/jtao/software/lsgkm/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into GC content matched training and test data\n",
    "def get_GC_matched_split(features, labels, test_size, tolerance = 0.01):\n",
    "    '''\n",
    "    feature: 2D array (samples x features)\n",
    "    labels: 1D boolean array (samples x)\n",
    "    test_size: fraction of data to test on\n",
    "    tolerance: max difference in GC content between True and False labelled samples\n",
    "    '''\n",
    "    global _id_sequence_dict\n",
    "    \n",
    "    ### match GC content of samples labelled True with those labelled False by thowing out False samples\n",
    "    # retrieve sequences using index of labels\n",
    "    index_label_tuples = tuple(zip(labels.index.values, labels.values))\n",
    "    \n",
    "    true_sequences = [_id_sequence_dict[x[0]] for x in index_label_tuples if x[1]]\n",
    "    true_ids = [x[0] for x in index_label_tuples if x[1]]\n",
    "    \n",
    "    false_sequences = [_id_sequence_dict[x[0]] for x in index_label_tuples if not x[1]]\n",
    "    false_ids = [x[0] for x in index_label_tuples if not x[1]]\n",
    "    \n",
    "    # calculate GC content of True samples\n",
    "    true_gc_count = 0\n",
    "    true_length = 0\n",
    "    for s in true_sequences:\n",
    "        true_gc_count += s.count('G')\n",
    "        true_gc_count += s.count('C')\n",
    "        true_length += len(s)\n",
    "    true_gc_content = true_gc_count/(true_length+0.0000001)\n",
    "    \n",
    "    # calcuate GC content of False samples\n",
    "    false_gc_count = 0\n",
    "    false_length = 0\n",
    "    for s in false_sequences:\n",
    "        false_gc_count += s.count('G')\n",
    "        false_gc_count += s.count('C')\n",
    "        false_length += len(s)\n",
    "    false_gc_content = false_gc_count/(false_length+0.0000001)\n",
    "    \n",
    "    while abs(true_gc_content - false_gc_content) > tolerance:\n",
    "        # remove false GC sequences until GC content matches tolerance\n",
    "        selected_seq = False\n",
    "        \n",
    "        while not selected_seq:\n",
    "            rand_index = np.random.randint(len(false_sequences))\n",
    "            current_seq = false_sequences[rand_index]\n",
    "            current_gc_count = current_seq.count('G')+ current_seq.count('C')\n",
    "            current_length = len(current_seq)\n",
    "            current_gc = current_gc_count/current_length\n",
    "            if true_gc_content > false_gc_content:\n",
    "                # remove sequences that would increase overall GC content of False sequences\n",
    "                if current_gc < false_gc_content:\n",
    "                    selected_seq = True\n",
    "            else:\n",
    "                # remove sequences that would decrease overall GC content of False sequences\n",
    "                if current_gc > false_gc_content:\n",
    "                    selected_seq = True\n",
    "        false_gc_count -= current_gc_count\n",
    "        false_length -= current_length\n",
    "        false_gc_content = false_gc_count/false_length\n",
    "        \n",
    "        false_sequences.pop(rand_index)\n",
    "        false_ids.pop(rand_index)\n",
    "    \n",
    "    filtered_ids = true_ids + false_ids\n",
    "    filtered_features = features[features.index.isin(filtered_ids)]\n",
    "    filtered_labels = labels[labels.index.isin(filtered_ids)]\n",
    "\n",
    "    if test_size <= 0.5:\n",
    "        training_indices, test_indices = next(iter(\n",
    "                sklearn.cross_validation.StratifiedKFold(filtered_labels, int(1/test_size), shuffle=True)))\n",
    "    else:\n",
    "        test_indices, training_indices = next(\n",
    "            iter(sklearn.cross_validation.StratifiedKFold(filtered_labels, int(1/(1-test_size)), shuffle=True)))\n",
    "    training_ids = [filtered_ids[i] for i in training_indices]\n",
    "    test_ids = [filtered_ids[i] for i in test_indices]\n",
    "    \n",
    "    training_features = filtered_features[filtered_features.index.isin(training_ids)]\n",
    "    test_features = filtered_features[filtered_features.index.isin(test_ids)]\n",
    "    training_labels = filtered_labels[filtered_labels.index.isin(training_ids)]\n",
    "    test_labels = filtered_labels[filtered_labels.index.isin(test_ids)]\n",
    "    \n",
    "    return training_features, test_features, training_labels, test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy New Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_score_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_sequence_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_strand_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_start_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/motif_end_frame_C57BL6J.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/summary_frame.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/annotation_frame.pickle ./\n",
    "cp /gpfs/data01/glasslab/home/jtao/analysis/cobinding_motif_analysis/peak_sequences/C57BL6J.fa ./\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Score Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "motif_score_frame=pd.read_pickle('motif_score_frame_C57BL6J.pickle')\n",
    "motif_sequence_frame = pd.read_pickle('motif_sequence_frame_C57BL6J.pickle')\n",
    "motif_strand_frame = pd.read_pickle('motif_strand_frame_C57BL6J.pickle')\n",
    "motif_start_frame = pd.read_pickle('motif_start_frame_C57BL6J.pickle')\n",
    "motif_end_frame = pd.read_pickle('motif_end_frame_C57BL6J.pickle')\n",
    "summary_frame = pd.read_pickle('summary_frame.pickle')\n",
    "annotation_frame = pd.read_pickle('annotation_frame.pickle')\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standardized_motif_frame = pd.DataFrame(scaler.fit_transform(motif_score_frame.ix[:,3:]))\n",
    "standardized_motif_frame.columns = motif_score_frame.columns.values[3:]\n",
    "standardized_motif_frame.index = motif_score_frame.index.values\n",
    "\n",
    "_factors = sorted(list(set([x.split('_')[1] for x in summary_frame.columns if '_' in x])))\n",
    "_factors.remove('atac')\n",
    "\n",
    "### read in sequences as dictionary {peakID: sequence}\n",
    "with open('./C57BL6J.fa') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "_id_sequence_dict = {}\n",
    "for line in data:\n",
    "    if line[0] == '>':\n",
    "        sequenceName = line.strip()[1:]\n",
    "    else:\n",
    "        _id_sequence_dict[sequenceName] = line.strip().upper()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### work with just intergenic peaks for now ###\n",
    "intergenic_ids = annotation_frame[annotation_frame['Annotation'] == 'Intergenic'].index.values\n",
    "intergenic_motif_score_frame = motif_score_frame[motif_score_frame.index.isin(intergenic_ids)]\n",
    "intergenic_motif_sequence_frame = motif_sequence_frame[motif_sequence_frame.index.isin(intergenic_ids)]\n",
    "intergenic_motif_start_frame = motif_start_frame[motif_start_frame.index.isin(intergenic_ids)]\n",
    "intergenic_motif_end_frame = motif_end_frame[motif_end_frame.index.isin(intergenic_ids)]\n",
    "intergenic_summary_frame = summary_frame[summary_frame.index.isin(intergenic_ids)]\n",
    "intergenic_annotation_frame = annotation_frame[annotation_frame.index.isin(intergenic_ids)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap1_members=['atf3', 'cjun', 'fos', 'junb', 'jund']\n",
    "contains_ap1 = summary_frame[['c57bl6_'+x+'_veh' for x in ap1_members]].sum(axis=1)>0\n",
    "contains_ap1_tuples = tuple(zip(contains_ap1.index.values, contains_ap1.values, summary_frame['Factors'].values))\n",
    "summary_frame['Factors'] = [x[2] + ',c57bl6_ap-1_veh' if x[1] == True else x[2] for x in contains_ap1_tuples]\n",
    "\n",
    "contains_ap1 = summary_frame[['c57bl6_'+x+'_kla' for x in ap1_members]].sum(axis=1)>0\n",
    "contains_ap1_tuples = tuple(zip(contains_ap1.index.values, contains_ap1.values, summary_frame['Factors'].values))\n",
    "summary_frame['Factors'] = [x[2] + ',c57bl6_ap-1_kla' if x[1] == True else x[2] for x in contains_ap1_tuples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Different Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap1_members = ['atf3','cjun', 'fos', 'junb','jund']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numIterations = 5\n",
    "test_size = 0.5\n",
    "\n",
    "factors = ['atf3','cjun', 'fos', 'junb','jund', 'cebpa', 'pu1', 'atac','p65']\n",
    "\n",
    "\n",
    "# c57bl6_indices = summary_frame[summary_frame['Factors'].str.contains('c57bl6')].index.values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on Motif Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atf3_veh roc: 0.837198169311 precision: 0.712985973723 numTestPositives: 11100\n",
      "cjun_veh roc: 0.812323043374 precision: 0.468716810787 numTestPositives: 6318\n",
      "fos_veh roc: 0.859480132635 precision: 0.358471519701 numTestPositives: 1049\n",
      "junb_veh roc: 0.680489196816 precision: 0.0212806273238 numTestPositives: 265\n",
      "jund_veh roc: 0.808010335973 precision: 0.564164526088 numTestPositives: 9007\n",
      "atf3_kla roc: 0.830425025031 precision: 0.799720942187 numTestPositives: 17162\n",
      "cjun_kla roc: 0.806497223241 precision: 0.478950516004 numTestPositives: 8111\n",
      "fos_kla roc: 0.832273657484 precision: 0.662315720192 numTestPositives: 10694\n",
      "junb_kla roc: 0.827744766943 precision: 0.476897078391 numTestPositives: 7026\n",
      "jund_kla roc: 0.819025770433 precision: 0.713672525514 numTestPositives: 15048\n"
     ]
    }
   ],
   "source": [
    "### for all peaks in vehicle for all motifs\n",
    "factor_auc_dict_lr = {}\n",
    "factor_precision_dict_lr = {}\n",
    "factor_coeff_dict = {}\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        c57bl6_indices = summary_frame[summary_frame[['c57bl6_' + x + '_' + treatment for x in factors]].sum(axis=1) > 0].index.values  \n",
    "        features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)]\n",
    "        labels = summary_frame[summary_frame.index.isin(c57bl6_indices)]['Factors'].str.contains('c57bl6_' + monomer + '_' + treatment)\n",
    "        \n",
    "        if np.sum(labels) >= 100:\n",
    "            all_aucs = []\n",
    "            all_precisions = []\n",
    "            all_coeficients = []\n",
    "            for i in range(numIterations):  \n",
    "\n",
    "                # split data into training and test sets\n",
    "                training_features, test_features, training_labels, test_labels = get_GC_matched_split(\n",
    "                    features, labels, test_size = test_size, tolerance = 0.01)\n",
    "\n",
    "                #  Run classifier\n",
    "                lr_classifier = sklearn.linear_model.LogisticRegression(penalty='l1', n_jobs=-1)\n",
    "\n",
    "                lr_classifier.fit(training_features, training_labels)\n",
    "                # retrieve probabilities\n",
    "                probas_lr = lr_classifier.predict_proba(test_features)\n",
    "\n",
    "                # score predictions\n",
    "                current_roc_auc = sklearn.metrics.roc_auc_score(test_labels, probas_lr[:, 1])\n",
    "                current_precision = sklearn.metrics.average_precision_score(test_labels, probas_lr[:, 1])\n",
    "                current_coefficients = lr_classifier.coef_.flatten()\n",
    "                \n",
    "                all_coeficients.append(current_coefficients)\n",
    "                all_aucs.append(current_roc_auc)\n",
    "                all_precisions.append(current_precision)\n",
    "\n",
    "            # average scoring metrics across iterations\n",
    "            mean_roc_auc = np.mean(all_aucs)\n",
    "            mean_precision = np.mean(all_precisions)\n",
    "            mean_coefficients = np.mean(all_coeficients, axis=0) # average coefficients \n",
    "\n",
    "            print(monomer + '_' + treatment,\n",
    "                  'roc:', mean_roc_auc, \n",
    "                  'precision:', mean_precision, \n",
    "                  'numTestPositives:', np.sum(test_labels)\n",
    "                 )\n",
    "            factor_coeff_dict[monomer + '_' + treatment] = mean_coefficients\n",
    "            factor_auc_dict_lr[monomer + '_' + treatment]= all_aucs\n",
    "            factor_precision_dict_lr[monomer + '_' + treatment]= all_precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on AP-1 Motif Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atf3_veh roc: 0.711787583751 precision: 0.637931757196 numTestPositives: 11026\n",
      "cjun_veh roc: 0.723658166232 precision: 0.496315500838 numTestPositives: 6318\n",
      "fos_veh roc: 0.642339524359 precision: 0.281640776137 numTestPositives: 983\n",
      "junb_veh roc: 0.638571887718 precision: 0.172585453724 numTestPositives: 260\n",
      "jund_veh roc: 0.699381863747 precision: 0.546864876178 numTestPositives: 9032\n",
      "atf3_kla roc: 0.704110850712 precision: 0.731318073155 numTestPositives: 17375\n",
      "cjun_kla roc: 0.692280806969 precision: 0.464549817676 numTestPositives: 8164\n",
      "fos_kla roc: 0.764707637143 precision: 0.650317394266 numTestPositives: 10815\n",
      "junb_kla roc: 0.726181347832 precision: 0.469460080117 numTestPositives: 7047\n",
      "jund_kla roc: 0.698968880291 precision: 0.649040359423 numTestPositives: 14896\n"
     ]
    }
   ],
   "source": [
    "### for all peaks in vehicle for AP-1 motif\n",
    "factor_auc_dict_lrAP1only = {}\n",
    "factor_precision_dict_lrAP1only = {}\n",
    "treatment = 'veh'\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        c57bl6_indices = summary_frame[summary_frame[['c57bl6_' + x + '_' + treatment for x in factors]].sum(axis=1) > 0].index.values  \n",
    "    #     features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)][['ap-1', 'atf7_batf3_creb5']]\n",
    "        features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)][['ap-1']]\n",
    "\n",
    "        labels = summary_frame[summary_frame.index.isin(c57bl6_indices)]['Factors'].str.contains('c57bl6_' + monomer + '_' + treatment)\n",
    "\n",
    "        if np.sum(labels) >= 100:\n",
    "            all_aucs = []\n",
    "            all_precisions = []\n",
    "            for i in range(numIterations):  \n",
    "\n",
    "                # split data into training and test sets\n",
    "                training_features, test_features, training_labels, test_labels = get_GC_matched_split(\n",
    "                    features, labels, test_size = test_size, tolerance = 0.01)\n",
    "\n",
    "                #  Run classifier\n",
    "                lr_classifier = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "\n",
    "                lr_classifier.fit(training_features, training_labels)\n",
    "                # retrieve probabilities\n",
    "                probas_lr = lr_classifier.predict_proba(test_features)\n",
    "\n",
    "                # score predictions\n",
    "                current_roc_auc = sklearn.metrics.roc_auc_score(test_labels, probas_lr[:, 1], average = None)\n",
    "                current_precision = sklearn.metrics.average_precision_score(test_labels, probas_lr[:, 1], average = None)\n",
    "\n",
    "                all_aucs.append(current_roc_auc)\n",
    "                all_precisions.append(current_precision)\n",
    "\n",
    "\n",
    "            # average scoring metrics across iterations\n",
    "            mean_roc_auc = np.mean(all_aucs)\n",
    "            mean_precision = np.mean(all_precisions)\n",
    "\n",
    "            print(monomer + '_' + treatment,\n",
    "                  'roc:', mean_roc_auc, \n",
    "                  'precision:', mean_precision,\n",
    "                  'numTestPositives:', np.sum(test_labels)\n",
    "                 )\n",
    "            factor_auc_dict_lrAP1only[monomer + '_' + treatment]= all_aucs\n",
    "            factor_precision_dict_lrAP1only[monomer + '_' + treatment]= all_precisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atf3_veh roc: 0.837505307879 precision: 0.713452848425 numTestPositives: 11020\n",
      "cjun_veh roc: 0.809917668905 precision: 0.459388380279 numTestPositives: 6241\n",
      "fos_veh roc: 0.847759202921 precision: 0.315529084799 numTestPositives: 1001\n",
      "junb_veh roc: 0.629946365358 precision: 0.0180997706455 numTestPositives: 256\n",
      "jund_veh roc: 0.806552625361 precision: 0.559261094807 numTestPositives: 9006\n",
      "atf3_kla roc: 0.832533854528 precision: 0.801472253939 numTestPositives: 17265\n",
      "cjun_kla roc: 0.804874945532 precision: 0.475940264853 numTestPositives: 8012\n",
      "fos_kla roc: 0.831056627817 precision: 0.658968043094 numTestPositives: 10733\n",
      "junb_kla roc: 0.826204832005 precision: 0.470891940884 numTestPositives: 7009\n",
      "jund_kla roc: 0.817715701684 precision: 0.710813899156 numTestPositives: 15035\n"
     ]
    }
   ],
   "source": [
    "### for all peaks in vehicle for all motifs with balanced training data\n",
    "factor_auc_dict_lrBalanced = {}\n",
    "factor_precision_dict_lrBalanced = {}\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        c57bl6_indices = summary_frame[summary_frame[['c57bl6_' + x + '_' + treatment for x in factors]].sum(axis=1) > 0].index.values  \n",
    "        features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)]\n",
    "\n",
    "        labels = summary_frame[summary_frame.index.isin(c57bl6_indices)]['Factors'].str.contains('c57bl6_' + monomer + '_' + treatment)\n",
    "\n",
    "        if np.sum(labels) > 100:\n",
    "            all_precisions = []\n",
    "            all_aucs = []\n",
    "\n",
    "            for i in range(numIterations):    \n",
    "                # split data into training and test sets\n",
    "                training_features, test_features, training_labels, test_labels = get_GC_matched_split(\n",
    "                    features, labels, test_size = test_size, tolerance = 0.01)\n",
    "                id_label_tuples = list(zip(training_labels.index.values, training_labels.values))\n",
    "                id_label_dict = dict(zip(training_labels.index.values, training_labels.values))\n",
    "                true_ids = [x[0] for x in id_label_tuples if x[1] == True]\n",
    "                false_ids= [x[0] for x in id_label_tuples if x[1] == False]\n",
    "                # randomly select as many False IDs randomly as True IDs\n",
    "                shuffle(false_ids)\n",
    "                selected_false_ids = false_ids[:len(true_ids)]\n",
    "\n",
    "                balanced_training_ids = true_ids + selected_false_ids\n",
    "\n",
    "                balanced_training_features = training_features[training_features.index.isin(balanced_training_ids)]\n",
    "                balanced_training_labels = pd.Series([id_label_dict[x] for x in balanced_training_features.index.values],\n",
    "                                                     index= balanced_training_features.index.values)\n",
    "\n",
    "\n",
    "\n",
    "                #  Run classifier\n",
    "                lr_classifier = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "\n",
    "                lr_classifier.fit(balanced_training_features, balanced_training_labels)\n",
    "                # retrieve probabilities\n",
    "                probas_lr = lr_classifier.predict_proba(test_features)\n",
    "\n",
    "                # score predictions\n",
    "                current_roc_auc = sklearn.metrics.roc_auc_score(test_labels, probas_lr[:, 1], average=None)\n",
    "                current_precision = sklearn.metrics.average_precision_score(test_labels, probas_lr[:, 1], average = None)\n",
    "\n",
    "                all_aucs.append(current_roc_auc)\n",
    "                all_precisions.append(current_precision)\n",
    "\n",
    "            # average scoring metrics across iterations\n",
    "            mean_roc_auc = np.mean(all_aucs)\n",
    "            mean_precision = np.mean(all_precisions)\n",
    "\n",
    "            print(monomer + '_' + treatment,\n",
    "                  'roc:', mean_roc_auc, \n",
    "                  'precision:', mean_precision,\n",
    "                  'numTestPositives:', np.sum(test_labels)\n",
    "                 )\n",
    "            factor_auc_dict_lrBalanced[monomer + '_' + treatment]= all_aucs\n",
    "            factor_precision_dict_lrBalanced[monomer + '_' + treatment]= all_precisions\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on Top Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficient_frame = pd.DataFrame(factor_coeff_dict)\n",
    "coefficient_frame.index = standardized_motif_frame.columns.values\n",
    "# transform_coffcients into z-scores\n",
    "scaler = preprocessing.StandardScaler()\n",
    "coefficients_standardized_frame = pd.DataFrame(scaler.fit_transform(coefficient_frame))\n",
    "coefficients_standardized_frame.index = coefficient_frame.index.values\n",
    "coefficients_standardized_frame.columns = coefficient_frame.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atf3_veh numMotifs 15 roc: 0.82087271024 precision: 0.69716266686 numTestPositives: 11013\n",
      "cjun_veh numMotifs 18 roc: 0.796126140187 precision: 0.460166262546 numTestPositives: 6353\n",
      "fos_veh numMotifs 37 roc: 0.869091333207 precision: 0.363580724454 numTestPositives: 970\n",
      "junb_veh numMotifs 54 roc: 0.735768701168 precision: 0.030679278677 numTestPositives: 259\n",
      "jund_veh numMotifs 19 roc: 0.783227634592 precision: 0.547773332296 numTestPositives: 9094\n",
      "atf3_kla numMotifs 18 roc: 0.799503203966 precision: 0.772595319392 numTestPositives: 17277\n",
      "cjun_kla numMotifs 18 roc: 0.774806640827 precision: 0.443933312429 numTestPositives: 8035\n",
      "fos_kla numMotifs 12 roc: 0.801616703764 precision: 0.617958467924 numTestPositives: 10677\n",
      "junb_kla numMotifs 34 roc: 0.812137632466 precision: 0.46202848449 numTestPositives: 7018\n",
      "jund_kla numMotifs 16 roc: 0.77503804008 precision: 0.666367819932 numTestPositives: 15021\n"
     ]
    }
   ],
   "source": [
    "### for all peaks in vehicle for top motifs\n",
    "factor_precision_dict_lrTop = {}\n",
    "factor_auc_dict_lrTop = {}\n",
    "weight_threshold = 1.0\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        c57bl6_indices = summary_frame[summary_frame[['c57bl6_' + x + '_' + treatment for x in factors]].sum(axis=1) > 0].index.values  \n",
    "        top_motifs = coefficients_standardized_frame[coefficients_standardized_frame[monomer + '_' + treatment].abs() > weight_threshold].index.values\n",
    "        features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)][top_motifs]\n",
    "\n",
    "        labels = summary_frame[summary_frame.index.isin(c57bl6_indices)]['Factors'].str.contains('c57bl6_' + monomer + '_' + treatment)\n",
    "\n",
    "        if np.sum(labels) >= 100:\n",
    "            all_aucs = []\n",
    "            all_precisions = []\n",
    "            for i in range(numIterations):  \n",
    "\n",
    "                # split data into training and test sets\n",
    "                training_features, test_features, training_labels, test_labels = get_GC_matched_split(\n",
    "                    features, labels, test_size = test_size, tolerance = 0.01)\n",
    "\n",
    "                #  Run classifier\n",
    "                lr_classifier = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "\n",
    "                lr_classifier.fit(training_features, training_labels)\n",
    "                # retrieve probabilities\n",
    "                probas_lr = lr_classifier.predict_proba(test_features)\n",
    "\n",
    "                # score predictions\n",
    "                current_roc_auc = sklearn.metrics.roc_auc_score(test_labels, probas_lr[:, 1], average = None)\n",
    "                current_precision = sklearn.metrics.average_precision_score(test_labels, probas_lr[:, 1], average = None)\n",
    "\n",
    "                all_aucs.append(current_roc_auc)\n",
    "                all_precisions.append(current_precision)\n",
    "\n",
    "\n",
    "            # average scoring metrics across iterations\n",
    "            mean_roc_auc = np.mean(all_aucs)\n",
    "            mean_precision = np.mean(all_precisions)\n",
    "\n",
    "            print(monomer + '_' + treatment,\n",
    "                  'numMotifs', len(top_motifs),\n",
    "                  'roc:', mean_roc_auc, \n",
    "                  'precision:', mean_precision,\n",
    "                  'numTestPositives:', np.sum(test_labels)\n",
    "                 )\n",
    "            factor_auc_dict_lrTop[monomer + '_' + treatment]= all_aucs\n",
    "            factor_precision_dict_lrTop[monomer + '_' + treatment]= all_precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gkmSVM (Gapped K-mer SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!if [ ! -d ./gkmsvm_files ]; then mkdir ./gkmsvm_files; fi\n",
    "! rm ./gkmsvm_files/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atf3_veh\n",
      "cjun_veh\n"
     ]
    }
   ],
   "source": [
    "### for all peaks in vehicle using gapped k-mers on balanced data\n",
    "### write script\n",
    "factor_auc_dict_gkmSVM = {}\n",
    "factor_precision_dict_gkmSVM = {}\n",
    "\n",
    "\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    script_file = open('gkmsvm_' + treatment + '_balanced.sh', 'w')\n",
    "    for monomer in ap1_members:\n",
    "        c57bl6_indices = summary_frame[summary_frame[['c57bl6_' + x + '_' + treatment for x in factors]].sum(axis=1) > 0].index.values  \n",
    "        features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)]\n",
    "\n",
    "        labels = summary_frame[summary_frame.index.isin(c57bl6_indices)]['Factors'].str.contains('c57bl6_' + monomer + '_' + treatment)\n",
    "\n",
    "        if np.sum(labels) > 100:\n",
    "            print(monomer + '_' + treatment)\n",
    "            all_aucs = []\n",
    "            all_precisions = []\n",
    "            for iteration in range(numIterations):  \n",
    "                # split data into training and test sets\n",
    "                training_features, test_features, training_labels, test_labels = get_GC_matched_split(\n",
    "                    features, labels, test_size = test_size, tolerance = 0.01)\n",
    "\n",
    "                # create fasta files for positive and negative sequences\n",
    "                training_positive_path = './gkmsvm_files/' + monomer + '_' + treatment+ '_training_positive_balanced_' +str(iteration) + '.fa'\n",
    "                training_negative_path = './gkmsvm_files/' + monomer + '_' + treatment+ '_training_negative_balanced_' +str(iteration) + '.fa'\n",
    "                training_shortNegative_path = './gkmsvm_files/' + monomer + '_' + treatment+ '_training_shortNegative_balanced_' +str(iteration) + '.fa'\n",
    "\n",
    "\n",
    "                training_positive_file = open(training_positive_path,'w' )\n",
    "                training_negative_file = open(training_negative_path,'w' )\n",
    "                training_shortNegative_file = open(training_shortNegative_path,'w' )\n",
    "                test_path = './gkmsvm_files/' + monomer + '_' + treatment+ '_test_balanced_' + str(iteration) + '.fa'\n",
    "\n",
    "                test_file = open(test_path,'w')\n",
    "\n",
    "                numPositiveSeqs = np.sum(training_labels)\n",
    "                count=0\n",
    "                for i in range(len(training_labels)):\n",
    "                    index = training_labels.index[i]\n",
    "                    label = training_labels[i]\n",
    "                    seq = _id_sequence_dict[index]\n",
    "\n",
    "                    if label == True:\n",
    "                        training_positive_file.write('>' + index + '\\n')\n",
    "                        training_positive_file.write(seq + '\\n')\n",
    "                    else:\n",
    "                        if count < numPositiveSeqs:\n",
    "                            training_shortNegative_file.write('>' + index + '\\n')\n",
    "                            training_shortNegative_file.write(seq + '\\n')\n",
    "                        training_negative_file.write('>' + index + '\\n')\n",
    "                        training_negative_file.write(seq + '\\n')\n",
    "                        count+=1\n",
    "\n",
    "                for i in range(len(test_labels)):\n",
    "                    index = test_labels.index[i]\n",
    "                    label = test_labels[i]\n",
    "                    seq = _id_sequence_dict[index]\n",
    "                    test_file.write('>' + index + '\\n')\n",
    "                    test_file.write(seq + '\\n')\n",
    "\n",
    "                training_positive_file.close()\n",
    "                training_negative_file.close()\n",
    "                training_shortNegative_file.close()\n",
    "                test_file.close()\n",
    "\n",
    "                #  Run classifier\n",
    "                model_prefix = './gkmsvm_files/' + monomer + '_' + treatment + '_' +str(iteration) + '_balanced'\n",
    "                model_path = model_prefix + '.model.txt'\n",
    "                results_path = model_prefix + '_results.txt'\n",
    "\n",
    "                script_file.write('(gkmtrain '+ training_positive_path + ' ' + training_shortNegative_path + ' ' + model_prefix +\n",
    "                          ' -T 16 -m 64000;')\n",
    "                if iteration == (numIterations - 1):\n",
    "                    script_file.write('gkmpredict '+ test_path + ' ' + model_path + ' ' +  results_path + ' -T 4)\\n')\n",
    "                else:\n",
    "                    script_file.write('gkmpredict '+ test_path + ' ' + model_path + ' ' +  results_path + ' -T 4)&\\n')\n",
    "                \n",
    "\n",
    "    script_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod a+x ./gkmsvm_veh_balanced.sh \n",
    "./gkmsvm_veh_balanced.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod a+x ./gkmsvm_kla_balanced.sh \n",
    "./gkmsvm_kla_balanced.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### for all peaks in vehicle using gapped k-mers on balanced data\n",
    "### read performance\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        c57bl6_indices = summary_frame[summary_frame[['c57bl6_' + x + '_' + treatment for x in factors]].sum(axis=1) > 0].index.values  \n",
    "        features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)]\n",
    "\n",
    "        labels = summary_frame[summary_frame.index.isin(c57bl6_indices)]['Factors'].str.contains('c57bl6_' + monomer + '_' + treatment)\n",
    "\n",
    "        if np.sum(labels) > 100:\n",
    "            print(monomer + '_' + treatment)\n",
    "            all_aucs = []\n",
    "            all_precisions = []\n",
    "            for iteration in range(numIterations):  \n",
    "                model_prefix = './gkmsvm_files/' + monomer  + '_' + treatment+ '_' +str(iteration) + '_balanced'\n",
    "                results_path = model_prefix + '_results.txt'\n",
    "\n",
    "\n",
    "                index_score_dict = {} #{peakID: gkmSVM score}\n",
    "                with open(results_path) as f:\n",
    "                    data = f.readlines()\n",
    "                for line in data:\n",
    "                    tokens=line.strip().split()\n",
    "                    score = float(tokens[1])\n",
    "                    index = tokens[0]\n",
    "                    index_score_dict[index] = score\n",
    "                # define true labels\n",
    "                index_label_dict = dict(zip(labels.index.values, labels.values))\n",
    "\n",
    "                sorted_indices = sorted(index_score_dict.keys())\n",
    "\n",
    "                sorted_scores = np.array([index_score_dict[x] for x in sorted_indices])\n",
    "                test_labels = np.array([index_label_dict[x] for x in sorted_indices])\n",
    "\n",
    "                min_score = np.min(sorted_scores)\n",
    "                if min_score < 0:\n",
    "                    normalized_scores = sorted_scores + abs(min_score)\n",
    "                normalized_scores = normalized_scores/np.max(normalized_scores)\n",
    "\n",
    "                # score predictions          \n",
    "                current_roc_auc = sklearn.metrics.roc_auc_score(test_labels, normalized_scores, average = None)\n",
    "                current_precision = sklearn.metrics.average_precision_score(test_labels, normalized_scores, average = None)\n",
    "                all_precisions.append(current_precision)\n",
    "                all_aucs.append(current_roc_auc)\n",
    "\n",
    "            # average scoring metrics \n",
    "\n",
    "            mean_roc_auc = np.mean(all_aucs) \n",
    "            mean_precision = np.mean(all_precisions)\n",
    "\n",
    "            factor_auc_dict_gkmSVM[monomer + '_' + treatment]= all_aucs\n",
    "            factor_precision_dict_gkmSVM[monomer + '_' + treatment]= all_precisions\n",
    "\n",
    "            print(monomer + '_' + treatment,\n",
    "                  'roc:', mean_roc_auc, \n",
    "                  'precision:', mean_precision,\n",
    "                  'numTestPositives:', np.sum(test_labels)\n",
    "                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### for all peaks in vehicle using gapped k-mers on unbalanced data\n",
    "### write script\n",
    "\n",
    "factor_auc_dict_unbalancedgkmSVM = {}\n",
    "factor_precision_dict_unbalancedgkmSVM = {}\n",
    "for treatment in ['veh', 'kla']:\n",
    "    script_file = open('gkmsvm_' + treatment +'_unbalanced.sh', 'w')\n",
    "    for monomer in ap1_members:\n",
    "        c57bl6_indices = summary_frame[summary_frame[['c57bl6_' + x + '_' + treatment for x in factors]].sum(axis=1) > 0].index.values  \n",
    "        features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)]\n",
    "        labels = summary_frame[summary_frame.index.isin(c57bl6_indices)]['Factors'].str.contains('c57bl6_' + monomer + '_' + treatment)\n",
    "\n",
    "        if np.sum(labels) > 100:\n",
    "            all_aucs = []\n",
    "            all_precisions = []\n",
    "\n",
    "            for iteration in range(numIterations):    \n",
    "    #         for iteration in [0]:\n",
    "                # split data into training and test sets\n",
    "                # !!!features are not used - calculated so get GC matched split will operate!!!\n",
    "                training_features, test_features, training_labels, test_labels = get_GC_matched_split(\n",
    "                    features, labels, test_size = test_size, tolerance = 0.01)\n",
    "\n",
    "                # create fasta files for positive and negative sequences\n",
    "                training_positive_path = './gkmsvm_files/' + monomer + '_' + treatment + '_training_positive_unbalanced_' +str(iteration) + '.fa'\n",
    "                training_negative_path = './gkmsvm_files/' + monomer + '_' + treatment + '_training_negative_unbalanced_' +str(iteration) + '.fa'\n",
    "\n",
    "                training_positive_file = open(training_positive_path,'w' )\n",
    "                training_negative_file = open(training_negative_path,'w' )\n",
    "                test_path = './gkmsvm_files/' + monomer  + '_' + treatment + '_test_' + str(iteration) + '.fa'\n",
    "\n",
    "                test_file = open(test_path,'w')\n",
    "\n",
    "                numPositiveSeqs = np.sum(training_labels)\n",
    "                count=0\n",
    "                for i in range(len(training_labels)):\n",
    "                    index = training_labels.index[i]\n",
    "                    label = training_labels[i]\n",
    "                    seq = _id_sequence_dict[index]\n",
    "                    if label == True:\n",
    "                        training_positive_file.write('>' + index + '\\n')\n",
    "                        training_positive_file.write(seq + '\\n')\n",
    "                    else:\n",
    "                        training_negative_file.write('>' + index + '\\n')\n",
    "                        training_negative_file.write(seq + '\\n')\n",
    "                        count+=1\n",
    "\n",
    "                for i in range(len(test_labels)):\n",
    "                    index = test_labels.index[i]\n",
    "                    label = test_labels[i]\n",
    "                    seq = _id_sequence_dict[index]\n",
    "                    test_file.write('>' + index + '\\n')\n",
    "                    test_file.write(seq + '\\n')\n",
    "\n",
    "                training_positive_file.close()\n",
    "                training_negative_file.close()\n",
    "\n",
    "                test_file.close()\n",
    "\n",
    "                #  Run classifier\n",
    "                model_prefix = './gkmsvm_files/' + monomer + '_' + treatment + '_' +str(iteration) + '_unbalanced'\n",
    "                model_path = model_prefix + '.model.txt'\n",
    "                results_path = model_prefix + '_results.txt'\n",
    "\n",
    "                script_file.write('(gkmtrain '+ training_positive_path + ' ' + training_negative_path + ' ' + model_prefix +\n",
    "                          ' -T 16 -m 64000;')\n",
    "                if iteration == (numIterations - 1):\n",
    "                    script_file.write('gkmpredict '+ test_path + ' ' + model_path + ' ' +  results_path + ' -T 4)\\n')\n",
    "                else:\n",
    "                    script_file.write('gkmpredict '+ test_path + ' ' + model_path + ' ' +  results_path + ' -T 4)&\\n')\n",
    "\n",
    "    script_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod a+x ./gkmsvm_veh_unbalanced.sh \n",
    "./gkmsvm_veh_unbalanced.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod a+x ./gkmsvm_kla_unbalanced.sh\n",
    "./gkmsvm_kla_unbalanced.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### for all peaks in vehicle using gapped k-mers on balanced data\n",
    "### read performance\n",
    "for treatment in ['veh', 'kla']:\n",
    "    for monomer in ap1_members:\n",
    "        c57bl6_indices = summary_frame[summary_frame[['c57bl6_' + x + '_' + treatment for x in factors]].sum(axis=1) > 0].index.values  \n",
    "        features = standardized_motif_frame[standardized_motif_frame.index.isin(c57bl6_indices)]\n",
    "\n",
    "        labels = summary_frame[summary_frame.index.isin(c57bl6_indices)]['Factors'].str.contains('c57bl6_' + monomer + '_' + treatment)\n",
    "\n",
    "        if np.sum(labels) > 100:\n",
    "            print(monomer + '_' + treatment)\n",
    "            all_aucs = []\n",
    "            all_precisions = []\n",
    "            for iteration in range(numIterations):  \n",
    "                model_prefix = './gkmsvm_files/' + monomer + '_' + treatment + '_' +str(iteration) + '_unbalanced'\n",
    "                results_path = model_prefix + '_results.txt'\n",
    "\n",
    "\n",
    "                index_score_dict = {} #{peakID: gkmSVM score}\n",
    "                with open(results_path) as f:\n",
    "                    data = f.readlines()\n",
    "                for line in data:\n",
    "                    tokens=line.strip().split()\n",
    "                    score = float(tokens[1])\n",
    "                    index = tokens[0]\n",
    "                    index_score_dict[index] = score\n",
    "                # define true labels\n",
    "                index_label_dict = dict(zip(labels.index.values, labels.values))\n",
    "\n",
    "                sorted_indices = sorted(index_score_dict.keys())\n",
    "\n",
    "                sorted_scores = np.array([index_score_dict[x] for x in sorted_indices])\n",
    "                test_labels = np.array([index_label_dict[x] for x in sorted_indices])\n",
    "\n",
    "                min_score = np.min(sorted_scores)\n",
    "                if min_score < 0:\n",
    "                    normalized_scores = sorted_scores + abs(min_score)\n",
    "                normalized_scores = normalized_scores/np.max(normalized_scores)\n",
    "\n",
    "                # score predictions          \n",
    "                current_roc_auc = sklearn.metrics.roc_auc_score(test_labels, normalized_scores, average = None)\n",
    "                current_precision = sklearn.metrics.average_precision_score(test_labels, normalized_scores, average = None)\n",
    "                all_precisions.append(current_precision)\n",
    "                all_aucs.append(current_roc_auc)\n",
    "\n",
    "            # average scoring metrics \n",
    "\n",
    "            mean_roc_auc = np.mean(all_aucs) \n",
    "            mean_precision = np.mean(all_precisions)\n",
    "\n",
    "            factor_auc_dict_unbalancedgkmSVM[monomer + '_' + treatment]= all_aucs\n",
    "            factor_precision_dict_unbalancedgkmSVM[monomer + '_' + treatment]= all_precisions\n",
    "\n",
    "            print(monomer + '_' + treatment,\n",
    "                  'roc:', mean_roc_auc, \n",
    "                  'precision:', mean_precision,\n",
    "                  'numTestPositives:', np.sum(test_labels)\n",
    "                 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monomers = []\n",
    "aucs = []\n",
    "feature_set = []\n",
    "for monomer in sorted(factor_auc_dict_lr.keys()):\n",
    "        \n",
    "    monomers = monomers + numIterations * [monomer]\n",
    "    aucs = aucs + factor_auc_dict_unbalancedgkmSVM[monomer]\n",
    "    feature_set = feature_set + numIterations * ['gkmSVM Unbalanced']\n",
    "    \n",
    "    monomers = monomers + numIterations * [monomer]\n",
    "    aucs = aucs + factor_auc_dict_gkmSVM[monomer]\n",
    "    feature_set = feature_set + numIterations * ['gkmSVM Balanced']\n",
    "    \n",
    "    monomers = monomers + numIterations * [monomer]\n",
    "    aucs = aucs + factor_auc_dict_lr[monomer]\n",
    "    feature_set = feature_set + numIterations * ['LR All Motifs Unbalanced']\n",
    "    \n",
    "    monomers = monomers + numIterations * [monomer]\n",
    "    aucs = aucs + factor_auc_dict_lrAP1only[monomer]\n",
    "    feature_set = feature_set + numIterations * ['LR AP-1 Only Unbalanced']\n",
    "    \n",
    "    monomers = monomers + numIterations * [monomer]\n",
    "    aucs = aucs + factor_auc_dict_lrTop[monomer]\n",
    "    feature_set = feature_set + numIterations * ['LR Top Motifs Unbalanced']\n",
    "    \n",
    "    monomers = monomers + numIterations * [monomer]\n",
    "    aucs = aucs + factor_auc_dict_lrBalanced[monomer]\n",
    "    feature_set = feature_set + numIterations * ['LR All Motifs Balanced']\n",
    "\n",
    "    \n",
    "data = pd.DataFrame({'Factor':monomers,\n",
    "                     'AUC':aucs,\n",
    "                     'Feature Set': feature_set\n",
    "                     })\n",
    "\n",
    "# Vehicle plot\n",
    "# sort monomers according to ascending AUC with all motifs\n",
    "for treatment in ['veh', 'kla']:\n",
    "    factor_auc_tuples = [(x, np.mean(factor_auc_dict_lr[x])) for x in factor_auc_dict_lr if treatment in x]\n",
    "\n",
    "    sorted_monomers = [y[0] for y in sorted(factor_auc_tuples, key=lambda x:x[1])]\n",
    "\n",
    "    with sns.axes_style('ticks'):\n",
    "        plottingFrame = sns.factorplot(data = data[data['Factor'].str.contains(treatment)],\n",
    "                                    x='Factor',\n",
    "                                    y='AUC',\n",
    "                                    order = sorted_monomers,\n",
    "                                    palette='Set1',\n",
    "                                    size=6,\n",
    "                                    hue='Feature Set',\n",
    "                                    kind = 'point', \n",
    "                                    markers = '.', s='0.01')\n",
    "        sns.despine()\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('aucROC')\n",
    "        plt.xlabel('AP-1 Monomer')\n",
    "        plt.ylim(0.5,1)\n",
    "        plt.title('Classifier Performance')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monomers = []\n",
    "aucs = []\n",
    "feature_set = []\n",
    "for factor in sorted(factor_auc_dict_lr.keys()):\n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    aucs = aucs + factor_auc_dict_lr[factor]\n",
    "    feature_set = feature_set + numIterations * ['LR All Motifs']\n",
    "    \n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    aucs = aucs + factor_auc_dict_unbalancedgkmSVM[factor]\n",
    "    feature_set = feature_set + numIterations * ['gkmSVM']\n",
    "    \n",
    "data = pd.DataFrame({'Factor':monomers,\n",
    "                     'AUC':aucs,\n",
    "                     'Feature Set': feature_set\n",
    "                     })\n",
    "\n",
    "# vehicle plot\n",
    "\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    factor_auc_tuples = [(x, np.mean(factor_auc_dict_lr[x])) for x in factor_auc_dict_lr if treatment in x]\n",
    "    sorted_monomers = [y[0] for y in sorted(factor_auc_tuples, key=lambda x:x[1])]\n",
    "    with sns.axes_style('ticks'):\n",
    "        plottingFrame = sns.factorplot(data = data[data['Factor'].str.contains(treatment)],\n",
    "                                    x='Factor',\n",
    "                                    y='AUC',\n",
    "                                    order = sorted_monomers,\n",
    "                                    palette='Set1',\n",
    "                                    size=6,\n",
    "                                    hue='Feature Set',\n",
    "                                    kind = 'point', \n",
    "                                    markers = '.', s='0.01')\n",
    "        sns.despine()\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('aucROC')\n",
    "        plt.xlabel('AP-1 Monomer')\n",
    "        plt.ylim(0.5,1)\n",
    "        plt.title('Classifier Performance')\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monomers = []\n",
    "precisions = []\n",
    "feature_set = []\n",
    "for factor in sorted(factor_precision_dict_lr.keys()):\n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    precisions = precisions + factor_precision_dict_lr[factor]\n",
    "    feature_set = feature_set + numIterations * ['LR All Motifs Unbalanced']\n",
    "\n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    precisions = precisions + factor_precision_dict_lrAP1only[factor]\n",
    "    feature_set = feature_set + numIterations * ['LR AP-1 Motif Unbalanced']\n",
    "    \n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    precisions = precisions + factor_precision_dict_lrBalanced[factor]\n",
    "    feature_set = feature_set + numIterations * ['LR All Motifs Balanced']\n",
    "    \n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    precisions = precisions + factor_precision_dict_lrTop[factor]\n",
    "    feature_set = feature_set + numIterations * ['LR Top Motifs']\n",
    "    \n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    precisions = precisions + factor_precision_dict_gkmSVM[factor]\n",
    "    feature_set = feature_set + numIterations * ['gkmSVM Balanced']\n",
    "    \n",
    "    monomers = monomers + numIterations * [factor]\n",
    "    precisions = precisions + factor_precision_dict_unbalancedgkmSVM[factor]\n",
    "    feature_set = feature_set + numIterations * ['gkmSVM Unbalanced']\n",
    "    \n",
    "data = pd.DataFrame({'Factor':monomers,\n",
    "                     'Precision Score':precisions,\n",
    "                     'Feature Set': feature_set\n",
    "                     })\n",
    "\n",
    "for treatment in ['veh', 'kla']:\n",
    "    # sort monomers according to ascending precision with all motifs\n",
    "    factor_precision_tuples = [(x, np.mean(factor_precision_dict_lr[x])) for x in factor_precision_dict_lr if treatment in x]\n",
    "\n",
    "    sorted_monomers = [y[0] for y in sorted(factor_precision_tuples, key=lambda x:x[1])]\n",
    "\n",
    "    with sns.axes_style('ticks'):\n",
    "        plottingFrame = sns.factorplot(data = data[data['Factor'].str.contains(treatment)],\n",
    "                                    x='Factor',\n",
    "                                    y='Precision Score',\n",
    "                                    order = sorted_monomers,\n",
    "                                    palette='Set1',\n",
    "                                    size=6,\n",
    "                                    hue='Feature Set',\n",
    "                                    kind = 'point', \n",
    "                                    markers = '.', s='0.01')\n",
    "        sns.despine()\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('Precision Score')\n",
    "        plt.xlabel('AP-1 Monomer')\n",
    "        plt.title('Classifier Performance')\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
